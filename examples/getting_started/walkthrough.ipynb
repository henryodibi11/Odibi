{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ODIBI Getting Started - Complete Walkthrough\n",
    "\n",
    "**Welcome to ODIBI!** This notebook will teach you everything you need to know to build data pipelines.\n",
    "\n",
    "## What You'll Learn:\n",
    "\n",
    "1. ‚úÖ Basic pipeline (read ‚Üí write)\n",
    "2. ‚úÖ Transform functions (custom logic)\n",
    "3. ‚úÖ SQL transforms\n",
    "4. ‚úÖ Multi-source pipelines (joins)\n",
    "5. ‚úÖ Debugging techniques\n",
    "6. ‚úÖ Error handling\n",
    "\n",
    "## Prerequisites:\n",
    "\n",
    "- ODIBI installed: `pip install -e d:/odibi`\n",
    "- This notebook in `examples/getting_started/`\n",
    "- Sample data in `data/` folder\n",
    "\n",
    "Let's get started! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Working directory: c:\\Users\\hodibi\\OneDrive - Ingredion\\Desktop\\Repos\\Odibi\\examples\\getting_started\n",
      "üì¶ Project root: c:\\Users\\hodibi\\OneDrive - Ingredion\\Desktop\\Repos\\Odibi\n"
     ]
    }
   ],
   "source": [
    "# Setup: Add project root to path and change to examples directory\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Change to examples directory\n",
    "os.chdir(Path.cwd() / 'examples' / 'getting_started' if 'getting_started' not in str(Path.cwd()) else Path.cwd())\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent.parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"üìÅ Working directory: {Path.cwd()}\")\n",
    "print(f\"üì¶ Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful!\n",
      "üìù Registered transforms: ['calculate_revenue', 'filter_by_category', 'enrich_with_customer_data', 'aggregate_by_product']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\odibi\\odibi\\config.py:40: UserWarning: Field name \"validate\" in \"BaseConnectionConfig\" shadows an attribute in parent \"BaseModel\"\n",
      "  class BaseConnectionConfig(BaseModel):\n",
      "d:\\odibi\\odibi\\config.py:156: UserWarning: Field name \"validate\" in \"NodeConfig\" shadows an attribute in parent \"BaseModel\"\n",
      "  class NodeConfig(BaseModel):\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from odibi.pipeline import Pipeline\n",
    "from odibi.config import PipelineConfig, ProjectConfig\n",
    "from odibi.connections import LocalConnection\n",
    "from odibi.registry import FunctionRegistry\n",
    "\n",
    "# Import our transform functions\n",
    "import transforms  # ‚Üê This registers all @transform functions\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(f\"üìù Registered transforms: {FunctionRegistry.list_functions()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Explore the Sample Data\n",
    "\n",
    "Let's see what data we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Sales Data:\n",
      "  Rows: 10\n",
      "  Columns: ['id', 'date', 'product', 'category', 'quantity', 'price', 'customer_id']\n",
      "\n",
      "Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>product</th>\n",
       "      <th>category</th>\n",
       "      <th>quantity</th>\n",
       "      <th>price</th>\n",
       "      <th>customer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>Widget A</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>5</td>\n",
       "      <td>29.99</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>Widget B</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>3</td>\n",
       "      <td>49.99</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Gadget X</td>\n",
       "      <td>Home</td>\n",
       "      <td>2</td>\n",
       "      <td>15.50</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Widget A</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>1</td>\n",
       "      <td>29.99</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>Tool Y</td>\n",
       "      <td>Tools</td>\n",
       "      <td>4</td>\n",
       "      <td>12.00</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date   product     category  quantity  price  customer_id\n",
       "0   1  2024-01-01  Widget A  Electronics         5  29.99          101\n",
       "1   2  2024-01-01  Widget B  Electronics         3  49.99          102\n",
       "2   3  2024-01-02  Gadget X         Home         2  15.50          103\n",
       "3   4  2024-01-02  Widget A  Electronics         1  29.99          101\n",
       "4   5  2024-01-03    Tool Y        Tools         4  12.00          104"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load sample sales data\n",
    "sales_df = pd.read_csv('data/sales.csv')\n",
    "\n",
    "print(\"üìä Sales Data:\")\n",
    "print(f\"  Rows: {len(sales_df)}\")\n",
    "print(f\"  Columns: {list(sales_df.columns)}\")\n",
    "print(\"\\nSample:\")\n",
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• Customer Data:\n",
      "  Rows: 7\n",
      "  Columns: ['customer_id', 'name', 'region', 'tier']\n",
      "\n",
      "Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>name</th>\n",
       "      <th>region</th>\n",
       "      <th>tier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>Alice Smith</td>\n",
       "      <td>North</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Bob Johnson</td>\n",
       "      <td>South</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>Carol White</td>\n",
       "      <td>East</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>David Brown</td>\n",
       "      <td>West</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>Eve Davis</td>\n",
       "      <td>North</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id         name region    tier\n",
       "0          101  Alice Smith  North    Gold\n",
       "1          102  Bob Johnson  South  Silver\n",
       "2          103  Carol White   East    Gold\n",
       "3          104  David Brown   West  Bronze\n",
       "4          105    Eve Davis  North  Silver"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load customer data\n",
    "customers_df = pd.read_csv('data/customers.csv')\n",
    "\n",
    "print(\"üë• Customer Data:\")\n",
    "print(f\"  Rows: {len(customers_df)}\")\n",
    "print(f\"  Columns: {list(customers_df.columns)}\")\n",
    "print(\"\\nSample:\")\n",
    "customers_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Simple Pipeline (Read ‚Üí Write)\n",
    "\n",
    "**Goal:** Load CSV, save as Parquet\n",
    "\n",
    "**Pipeline:** `pipelines/simple.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Pipeline Config:\n",
      "description: Load CSV and save as Parquet\n",
      "nodes:\n",
      "- description: Load sales data from CSV\n",
      "  name: load_sales\n",
      "  read:\n",
      "    connection: local_data\n",
      "    format: csv\n",
      "    path: sales.csv\n",
      "- depends_on:\n",
      "  - load_sales\n",
      "  description: Save sales data as Parquet\n",
      "  name: save_parquet\n",
      "  write:\n",
      "    connection: local_output\n",
      "    format: parquet\n",
      "    mode: overwrite\n",
      "    path: sales.parquet\n",
      "pipeline: simple_etl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the simple pipeline config\n",
    "with open('pipelines/simple.yaml') as f:\n",
    "    pipeline_yaml = yaml.safe_load(f)\n",
    "\n",
    "print(\"üìã Pipeline Config:\")\n",
    "print(yaml.dump(pipeline_yaml, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pipeline: simple_etl\n",
      "üì¶ Nodes: ['load_sales', 'save_parquet']\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline config from YAML\n",
    "pipeline_config = PipelineConfig(**pipeline_yaml)\n",
    "\n",
    "print(f\"‚úÖ Pipeline: {pipeline_config.pipeline}\")\n",
    "print(f\"üì¶ Nodes: {[node.name for node in pipeline_config.nodes]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîå Connections configured:\n",
      "  - local_data: data\n",
      "  - local_output: output\n"
     ]
    }
   ],
   "source": [
    "# Setup connections\n",
    "connections = {\n",
    "    \"local_data\": LocalConnection(base_path=\"./data\"),\n",
    "    \"local_output\": LocalConnection(base_path=\"./output\")\n",
    "}\n",
    "\n",
    "print(\"üîå Connections configured:\")\n",
    "for name, conn in connections.items():\n",
    "    print(f\"  - {name}: {conn.base_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Validation:\n",
      "  Valid: True\n",
      "  Execution order: ['load_sales', 'save_parquet']\n",
      "\n",
      "‚ñ∂Ô∏è Running pipeline...\n",
      "\n",
      "\n",
      "‚úÖ Pipeline Results:\n",
      "  Completed: ['load_sales', 'save_parquet']\n",
      "  Failed: []\n",
      "  Duration: 0.3377s\n"
     ]
    }
   ],
   "source": [
    "# Create and run pipeline\n",
    "pipeline = Pipeline(pipeline_config, connections=connections)\n",
    "\n",
    "# Validate first\n",
    "validation = pipeline.validate()\n",
    "print(\"üîç Validation:\")\n",
    "print(f\"  Valid: {validation['valid']}\")\n",
    "print(f\"  Execution order: {validation['execution_order']}\")\n",
    "\n",
    "# Run pipeline\n",
    "print(\"\\n‚ñ∂Ô∏è Running pipeline...\\n\")\n",
    "results = pipeline.run()\n",
    "\n",
    "print(\"\\n‚úÖ Pipeline Results:\")\n",
    "print(f\"  Completed: {results.completed}\")\n",
    "print(f\"  Failed: {results.failed}\")\n",
    "print(f\"  Duration: {results.duration:.4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Output file created: output\\sales.parquet\n",
      "   Size: 4601 bytes\n",
      "   Rows: 10\n",
      "\n",
      "üìä First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>product</th>\n",
       "      <th>category</th>\n",
       "      <th>quantity</th>\n",
       "      <th>price</th>\n",
       "      <th>customer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>Widget A</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>5</td>\n",
       "      <td>29.99</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>Widget B</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>3</td>\n",
       "      <td>49.99</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Gadget X</td>\n",
       "      <td>Home</td>\n",
       "      <td>2</td>\n",
       "      <td>15.50</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Widget A</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>1</td>\n",
       "      <td>29.99</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>Tool Y</td>\n",
       "      <td>Tools</td>\n",
       "      <td>4</td>\n",
       "      <td>12.00</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date   product     category  quantity  price  customer_id\n",
       "0   1  2024-01-01  Widget A  Electronics         5  29.99          101\n",
       "1   2  2024-01-01  Widget B  Electronics         3  49.99          102\n",
       "2   3  2024-01-02  Gadget X         Home         2  15.50          103\n",
       "3   4  2024-01-02  Widget A  Electronics         1  29.99          101\n",
       "4   5  2024-01-03    Tool Y        Tools         4  12.00          104"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Verify output file was created\n",
    "import os\n",
    "\n",
    "output_file = Path('output/sales.parquet')\n",
    "if output_file.exists():\n",
    "    print(f\"‚úÖ Output file created: {output_file}\")\n",
    "    print(f\"   Size: {output_file.stat().st_size} bytes\")\n",
    "    \n",
    "    # Load and verify\n",
    "    saved_df = pd.read_parquet(output_file)\n",
    "    print(f\"   Rows: {len(saved_df)}\")\n",
    "    print(\"\\nüìä First few rows:\")\n",
    "    display(saved_df.head())\n",
    "else:\n",
    "    print(\"‚ùå Output file not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üéâ Success!** You just ran your first ODIBI pipeline!\n",
    "\n",
    "**What happened:**\n",
    "1. Loaded `pipelines/simple.yaml`\n",
    "2. Validated with Pydantic\n",
    "3. Created Pipeline with connections\n",
    "4. Executed: load_sales ‚Üí save_parquet\n",
    "5. Saved output to `output/sales.parquet`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Transform Pipeline (With Custom Functions)\n",
    "\n",
    "**Goal:** Load data, calculate revenue, filter by category, save\n",
    "\n",
    "**Pipeline:** `pipelines/transform.yaml`\n",
    "\n",
    "**Uses:** Custom `@transform` functions from `transforms.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Transform Pipeline:\n",
      "  Pipeline: transform_etl\n",
      "  Nodes: ['load_sales', 'add_revenue', 'electronics_only', 'save_electronics']\n"
     ]
    }
   ],
   "source": [
    "# Load transform pipeline\n",
    "with open('pipelines/transform.yaml') as f:\n",
    "    pipeline_yaml = yaml.safe_load(f)\n",
    "\n",
    "print(\"üìã Transform Pipeline:\")\n",
    "print(f\"  Pipeline: {pipeline_yaml['pipeline']}\")\n",
    "print(f\"  Nodes: {[node['name'] for node in pipeline_yaml['nodes']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß add_revenue:\n",
      "  Function: calculate_revenue\n",
      "  Params: {'source': 'load_sales'}\n",
      "\n",
      "üîß electronics_only:\n",
      "  Function: filter_by_category\n",
      "  Params: {'source': 'add_revenue', 'category': 'Electronics'}\n"
     ]
    }
   ],
   "source": [
    "# See the transform functions being used\n",
    "for node in pipeline_yaml['nodes']:\n",
    "    if 'transform' in node:\n",
    "        print(f\"\\nüîß {node['name']}:\")\n",
    "        for step in node['transform']['steps']:\n",
    "            if isinstance(step, dict) and 'function' in step:\n",
    "                print(f\"  Function: {step['function']}\")\n",
    "                print(f\"  Params: {step['params']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂Ô∏è Running transform pipeline...\n",
      "\n",
      "\n",
      "‚úÖ Results:\n",
      "  Completed: ['load_sales', 'add_revenue', 'electronics_only', 'save_electronics']\n",
      "  Failed: []\n",
      "  Duration: 0.0461s\n"
     ]
    }
   ],
   "source": [
    "# Create and run pipeline\n",
    "pipeline_config = PipelineConfig(**pipeline_yaml)\n",
    "pipeline = Pipeline(pipeline_config, connections=connections)\n",
    "\n",
    "print(\"‚ñ∂Ô∏è Running transform pipeline...\\n\")\n",
    "results = pipeline.run()\n",
    "\n",
    "print(\"\\n‚úÖ Results:\")\n",
    "print(f\"  Completed: {results.completed}\")\n",
    "print(f\"  Failed: {results.failed}\")\n",
    "print(f\"  Duration: {results.duration:.4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Electronics Sales Output:\n",
      "  Rows: 5\n",
      "  Columns: ['id', 'date', 'product', 'category', 'quantity', 'price', 'customer_id', 'revenue']\n",
      "\n",
      "üí∞ Revenue calculated and filtered:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>product</th>\n",
       "      <th>category</th>\n",
       "      <th>quantity</th>\n",
       "      <th>price</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>Widget A</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>5</td>\n",
       "      <td>29.99</td>\n",
       "      <td>101</td>\n",
       "      <td>149.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>Widget B</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>3</td>\n",
       "      <td>49.99</td>\n",
       "      <td>102</td>\n",
       "      <td>149.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Widget A</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>1</td>\n",
       "      <td>29.99</td>\n",
       "      <td>101</td>\n",
       "      <td>29.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>Widget B</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>2</td>\n",
       "      <td>49.99</td>\n",
       "      <td>102</td>\n",
       "      <td>99.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>Widget A</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>3</td>\n",
       "      <td>29.99</td>\n",
       "      <td>107</td>\n",
       "      <td>89.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date   product     category  quantity  price  customer_id  \\\n",
       "0   1  2024-01-01  Widget A  Electronics         5  29.99          101   \n",
       "1   2  2024-01-01  Widget B  Electronics         3  49.99          102   \n",
       "2   4  2024-01-02  Widget A  Electronics         1  29.99          101   \n",
       "3   7  2024-01-04  Widget B  Electronics         2  49.99          102   \n",
       "4   9  2024-01-05  Widget A  Electronics         3  29.99          107   \n",
       "\n",
       "   revenue  \n",
       "0   149.95  \n",
       "1   149.97  \n",
       "2    29.99  \n",
       "3    99.98  \n",
       "4    89.97  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the output\n",
    "electronics_df = pd.read_csv('output/electronics_sales.csv')\n",
    "\n",
    "print(\"üìä Electronics Sales Output:\")\n",
    "print(f\"  Rows: {len(electronics_df)}\")\n",
    "print(f\"  Columns: {list(electronics_df.columns)}\")\n",
    "print(\"\\nüí∞ Revenue calculated and filtered:\")\n",
    "electronics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What happened:**\n",
    "1. Loaded sales data\n",
    "2. **Added revenue column** using `calculate_revenue()` function\n",
    "3. **Filtered for Electronics** using `filter_by_category()` function\n",
    "4. Saved results\n",
    "\n",
    "**Key insight:** Transform functions are just Python functions with `@transform` decorator!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4: Advanced Pipeline (SQL, Joins, Parallel)\n",
    "\n",
    "**Goal:** Join sales with customers, aggregate by product\n",
    "\n",
    "**Features:**\n",
    "- Multiple data sources\n",
    "- SQL transforms\n",
    "- Function transforms\n",
    "- Parallel writes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Pipeline: advanced_etl\n",
      "üì¶ Nodes (7):\n",
      "  - load_sales\n",
      "  - load_customers\n",
      "  - sales_with_revenue ‚Üê ['load_sales']\n",
      "  - enriched_sales ‚Üê ['sales_with_revenue', 'load_customers']\n",
      "  - product_summary ‚Üê ['enriched_sales']\n",
      "  - save_enriched ‚Üê ['enriched_sales']\n",
      "  - save_summary ‚Üê ['product_summary']\n"
     ]
    }
   ],
   "source": [
    "# Load advanced pipeline\n",
    "with open('pipelines/advanced.yaml') as f:\n",
    "    pipeline_yaml = yaml.safe_load(f)\n",
    "\n",
    "pipeline_config = PipelineConfig(**pipeline_yaml)\n",
    "\n",
    "print(f\"üìã Pipeline: {pipeline_config.pipeline}\")\n",
    "print(f\"üì¶ Nodes ({len(pipeline_config.nodes)}):\")\n",
    "for node in pipeline_config.nodes:\n",
    "    deps = f\" ‚Üê {node.depends_on}\" if node.depends_on else \"\"\n",
    "    print(f\"  - {node.name}{deps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the dependency graph\n",
    "pipeline = Pipeline(pipeline_config, connections=connections)\n",
    "\n",
    "print(\"üîÄ Dependency Graph:\\n\")\n",
    "print(pipeline.visualize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See execution layers (what can run in parallel)\n",
    "layers = pipeline.get_execution_layers()\n",
    "\n",
    "print(\"‚ö° Execution Layers (nodes in same layer can run in parallel):\\n\")\n",
    "for i, layer in enumerate(layers, 1):\n",
    "    print(f\"  Layer {i}: {layer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the pipeline\n",
    "print(\"‚ñ∂Ô∏è Running advanced pipeline...\\n\")\n",
    "results = pipeline.run()\n",
    "\n",
    "print(\"\\n‚úÖ Results:\")\n",
    "print(f\"  Completed: {results.completed}\")\n",
    "print(f\"  Failed: {results.failed}\")\n",
    "print(f\"  Duration: {results.duration:.4f}s\")\n",
    "\n",
    "print(\"\\nüìù Node Details:\")\n",
    "for node_name in results.completed:\n",
    "    node_result = results.get_node_result(node_name)\n",
    "    print(f\"  {node_name}: {node_result.duration:.4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check enriched output\n",
    "enriched_df = pd.read_csv('output/enriched_sales.csv')\n",
    "\n",
    "print(\"üìä Enriched Sales (with customer data):\")\n",
    "print(f\"  Rows: {len(enriched_df)}\")\n",
    "print(f\"  Columns: {list(enriched_df.columns)}\")\n",
    "print(\"\\nSample (notice customer name, region, tier):\")\n",
    "enriched_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check product summary\n",
    "summary_df = pd.read_csv('output/product_summary.csv')\n",
    "\n",
    "print(\"üìà Product Summary (aggregated):\")\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üéâ Advanced pipeline complete!**\n",
    "\n",
    "**What happened:**\n",
    "1. Loaded **2 data sources** (sales + customers)\n",
    "2. Used **SQL** to calculate revenue\n",
    "3. **Joined** sales with customer data\n",
    "4. **Aggregated** by product\n",
    "5. Saved **2 outputs** (could run in parallel!)\n",
    "\n",
    "**Notice:**\n",
    "- `save_enriched` and `save_summary` are in Layer 4 (same layer)\n",
    "- They could run in parallel (feature not implemented yet)\n",
    "- Dependencies automatically handled!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5: Debugging - Run Single Nodes\n",
    "\n",
    "**Problem:** You want to test one transform without running the whole pipeline.\n",
    "\n",
    "**Solution:** `pipeline.run_node()` with mock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the aggregate_by_product function in isolation\n",
    "\n",
    "# Create mock data\n",
    "mock_sales = pd.DataFrame({\n",
    "    'product': ['Widget A', 'Widget A', 'Widget B', 'Widget B'],\n",
    "    'quantity': [5, 3, 2, 4],\n",
    "    'revenue': [100, 60, 80, 160]\n",
    "})\n",
    "\n",
    "print(\"üß™ Testing single node with mock data:\\n\")\n",
    "print(\"Input:\")\n",
    "print(mock_sales)\n",
    "\n",
    "# Run just the aggregate node\n",
    "result = pipeline.run_node(\n",
    "    \"product_summary\",\n",
    "    mock_data={\"enriched_sales\": mock_sales}\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Node executed: {result.success}\")\n",
    "print(f\"‚è± Duration: {result.duration:.4f}s\")\n",
    "\n",
    "print(\"\\nOutput:\")\n",
    "pipeline.context.get(\"product_summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Great for debugging!**\n",
    "- Test transforms without loading real data\n",
    "- Iterate quickly\n",
    "- Debug failures in isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Error Handling\n",
    "\n",
    "**What happens when things go wrong?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with an error\n",
    "from odibi.config import NodeConfig, ReadConfig, TransformConfig\n",
    "\n",
    "# Clear registry and add a failing function\n",
    "FunctionRegistry._functions.clear()\n",
    "FunctionRegistry._signatures.clear()\n",
    "\n",
    "from odibi import transform\n",
    "\n",
    "@transform\n",
    "def failing_transform(context, source: str):\n",
    "    \"\"\"This will fail on purpose.\"\"\"\n",
    "    df = context.get(source)\n",
    "    raise ValueError(\"Intentional failure for demo!\")\n",
    "\n",
    "# Create pipeline with error\n",
    "error_pipeline_config = PipelineConfig(\n",
    "    pipeline=\"error_demo\",\n",
    "    nodes=[\n",
    "        NodeConfig(\n",
    "            name=\"load\",\n",
    "            read=ReadConfig(connection=\"local_data\", format=\"csv\", path=\"sales.csv\")\n",
    "        ),\n",
    "        NodeConfig(\n",
    "            name=\"fail_node\",\n",
    "            depends_on=[\"load\"],\n",
    "            transform=TransformConfig(\n",
    "                steps=[{\"function\": \"failing_transform\", \"params\": {\"source\": \"load\"}}]\n",
    "            )\n",
    "        ),\n",
    "        NodeConfig(\n",
    "            name=\"dependent\",\n",
    "            depends_on=[\"fail_node\"],\n",
    "            transform=TransformConfig(\n",
    "                steps=[\"SELECT * FROM fail_node\"]\n",
    "            )\n",
    "        ),\n",
    "        NodeConfig(\n",
    "            name=\"independent\",\n",
    "            read=ReadConfig(connection=\"local_data\", format=\"csv\", path=\"customers.csv\")\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "error_pipeline = Pipeline(error_pipeline_config, connections=connections)\n",
    "\n",
    "print(\"‚ñ∂Ô∏è Running pipeline with intentional error...\\n\")\n",
    "results = error_pipeline.run()\n",
    "\n",
    "print(\"\\nüìä Results:\")\n",
    "print(f\"  ‚úÖ Completed: {results.completed}\")\n",
    "print(f\"  ‚ùå Failed: {results.failed}\")\n",
    "print(f\"  ‚è≠ Skipped: {results.skipped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get error details\n",
    "if results.failed:\n",
    "    failed_node = results.failed[0]\n",
    "    node_result = results.get_node_result(failed_node)\n",
    "    \n",
    "    print(f\"‚ùå Node '{failed_node}' failed:\\n\")\n",
    "    print(f\"Error: {node_result.error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error Handling:**\n",
    "- ‚úÖ `load` completed (ran first)\n",
    "- ‚ùå `fail_node` failed (intentional error)\n",
    "- ‚è≠ `dependent` skipped (dependency failed)\n",
    "- ‚úÖ `independent` completed (no dependency on failed node)\n",
    "\n",
    "**Philosophy:** \n",
    "- Don't fail fast\n",
    "- Skip dependents of failed nodes\n",
    "- Continue with independent nodes\n",
    "- Collect all errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 7: Inspect the Context\n",
    "\n",
    "**The Context** is how data passes between nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-import transforms to register them again\n",
    "import importlib\n",
    "importlib.reload(transforms)\n",
    "\n",
    "# Run the transform pipeline again\n",
    "with open('pipelines/transform.yaml') as f:\n",
    "    pipeline_yaml = yaml.safe_load(f)\n",
    "\n",
    "pipeline_config = PipelineConfig(**pipeline_yaml)\n",
    "pipeline = Pipeline(pipeline_config, connections=connections)\n",
    "results = pipeline.run()\n",
    "\n",
    "print(\"üì¶ After pipeline execution, context contains:\\n\")\n",
    "print(f\"  Registered DataFrames: {pipeline.context.list_names()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access intermediate results from context\n",
    "revenue_df = pipeline.context.get(\"add_revenue\")\n",
    "\n",
    "print(\"üí∞ Intermediate result 'add_revenue' (before filtering):\")\n",
    "print(f\"  Rows: {len(revenue_df)}\")\n",
    "print(f\"  Has revenue column: {'revenue' in revenue_df.columns}\")\n",
    "revenue_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare before and after filtering\n",
    "electronics_df = pipeline.context.get(\"electronics_only\")\n",
    "\n",
    "print(\"üìä Before filtering (add_revenue):\")\n",
    "print(f\"  Total rows: {len(revenue_df)}\")\n",
    "print(f\"  Categories: {revenue_df['category'].unique().tolist()}\")\n",
    "\n",
    "print(\"\\nüìä After filtering (electronics_only):\")\n",
    "print(f\"  Total rows: {len(electronics_df)}\")\n",
    "print(f\"  Categories: {electronics_df['category'].unique().tolist()}\")\n",
    "print(f\"  Filtered out: {len(revenue_df) - len(electronics_df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Context is powerful!**\n",
    "- Every node registers its result\n",
    "- Downstream nodes access by name\n",
    "- Great for debugging (inspect intermediate results)\n",
    "- Same API for Spark and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 8: Simplified Orchestration with PipelineManager\n",
    "\n",
    "**Problem:** Manually loading YAML, creating configs, and setting up connections is verbose.\n",
    "\n",
    "**Solution:** `PipelineManager` handles everything from a single project configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded pipelines: ['simple_etl_managed']\n",
      "\n",
      "‚ñ∂Ô∏è Running managed pipeline...\n",
      "\n",
      "\n",
      "============================================================\n",
      "Running pipeline: simple_etl_managed\n",
      "============================================================\n",
      "\n",
      "\n",
      "‚úÖ SUCCESS - simple_etl_managed\n",
      "  Completed: 2 nodes\n",
      "  Failed: 0 nodes\n",
      "  Duration: 239.39s\n",
      "  Story: c:\\Users\\hodibi\\OneDrive - Ingredion\\Desktop\\Repos\\Odibi\\examples\\getting_started\\output\\stories\\simple_etl_managed_20251119_122921.md\n",
      "\n",
      "‚úÖ Success! Output saved to c:\\Users\\hodibi\\OneDrive - Ingredion\\Desktop\\Repos\\Odibi\\examples\\getting_started\\output\\stories\\simple_etl_managed_20251119_122921.md\n"
     ]
    }
   ],
   "source": [
    "from odibi.pipeline import PipelineManager\n",
    "\n",
    "# Initialize manager from project config (pipelines/manager_demo.yaml)\n",
    "# This automatically:\n",
    "# 1. Loads the project config\n",
    "# 2. Sets up connections\n",
    "# 3. Creates all pipelines\n",
    "manager = PipelineManager.from_yaml(\"pipelines/manager_demo.yaml\")\n",
    "\n",
    "print(f\"‚úÖ Loaded pipelines: {manager.list_pipelines()}\")\n",
    "\n",
    "# Run the pipeline managed by the manager\n",
    "print(\"\\n‚ñ∂Ô∏è Running managed pipeline...\\n\")\n",
    "results = manager.run(\"simple_etl_managed\")\n",
    "\n",
    "print(f\"\\n‚úÖ Success! Output saved to {results.story_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why use PipelineManager?**\n",
    "- Single source of truth (project config)\n",
    "- Automatic connection setup\n",
    "- Manages multiple pipelines\n",
    "- Consistent execution environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "**üéâ Congratulations!** You've learned:\n",
    "\n",
    "### ‚úÖ Core Concepts:\n",
    "1. **YAML Configs** - Declarative pipeline definitions\n",
    "2. **Nodes** - Read ‚Üí Transform ‚Üí Write units\n",
    "3. **Dependencies** - Explicit `depends_on` declarations\n",
    "4. **Context** - Data passing between nodes\n",
    "5. **Connections** - Abstract data sources/destinations\n",
    "\n",
    "### ‚úÖ Features Used:\n",
    "- ‚úÖ CSV/Parquet read/write\n",
    "- ‚úÖ Transform functions (`@transform` decorator)\n",
    "- ‚úÖ SQL transforms (DuckDB)\n",
    "- ‚úÖ Multi-source joins\n",
    "- ‚úÖ Aggregation\n",
    "- ‚úÖ Dependency graph visualization\n",
    "- ‚úÖ Single node debugging\n",
    "- ‚úÖ Error handling\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "\n",
    "**Try building your own pipeline:**\n",
    "1. Create your own YAML config\n",
    "2. Write custom `@transform` functions\n",
    "3. Process your own data\n",
    "\n",
    "**Explore more:**\n",
    "- Read the framework docs: `docs/ODIBI_FRAMEWORK_PLAN.md`\n",
    "- Review test examples: `test_exploration_phase2.ipynb`\n",
    "- Check improvements list: `docs/IMPROVEMENTS.md`\n",
    "\n",
    "**Happy data engineering!** üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
