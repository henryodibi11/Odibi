# Simple Pipeline - Read and Write
# This pipeline just loads data and saves it in a different format

pipeline: simple_etl
description: "Load CSV and save as Parquet"

nodes:
  # Step 1: Load sales data
  - name: load_sales
    description: "Load sales data from CSV"
    read:
      connection: local_data
      format: csv
      path: sales.csv
  
  # Step 2: Save as Parquet
  - name: save_parquet
    description: "Save sales data as Parquet"
    depends_on: [load_sales]
    write:
      connection: local_output
      format: parquet
      path: sales.parquet
      mode: overwrite
