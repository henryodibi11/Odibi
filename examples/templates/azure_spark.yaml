# ============================================
# Azure ADLS + Spark Template
# ============================================
# Best for: Cloud production pipelines
# --------------------------------------------
project: Azure Spark ETL
engine: spark
retry:
  enabled: true
  max_attempts: 3
  backoff: exponential

connections:
  adls_gen2:
    type: azure_blob
    account_name: "${ADLS_ACCOUNT}"
    container: "${ADLS_CONTAINER}"
    validation_mode: lazy
    auth:
      key_vault_name: "${KV_NAME}"
      secret_name: "${KV_SECRET}"

  spark_catalog:
    type: delta
    catalog: hive_metastore
    schema: default

pipelines:
  - pipeline: cloud_migration
    nodes:
      - name: read_delta
        read:
          connection: adls_gen2
          path: raw/events
          format: delta
          
      - name: agg_daily
        depends_on: [read_delta]
        transform:
          steps:
            - sql: |
                SELECT date, count(*) as events 
                FROM read_delta 
                GROUP BY date
                
      - name: write_summary
        depends_on: [agg_daily]
        write:
          connection: adls_gen2
          path: processed/daily_summary
          format: delta
          mode: overwrite
