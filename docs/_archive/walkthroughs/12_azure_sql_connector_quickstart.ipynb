{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 - Azure SQL Connector Quickstart\n",
    "\n",
    "## üß≠ Goal\n",
    "\n",
    "Learn how to connect to Azure SQL Database using ODIBI's connection system with support for both Azure AD and SQL authentication.\n",
    "\n",
    "This notebook will:\n",
    "- Show how to use `AzureSQLConnection` from `odibi.connections`\n",
    "- Demonstrate two authentication modes: `azure_ad` and `sql_auth`\n",
    "- Use SQLite fallback for offline-safe execution (no Azure SQL required)\n",
    "- Show connection configuration patterns\n",
    "- Read/write data to SQL database\n",
    "- Demonstrate safe credential handling\n",
    "\n",
    "**Estimated time:** 30 seconds\n",
    "\n",
    "---\n",
    "\n",
    "## üß± Core Concepts\n",
    "\n",
    "**Azure SQL Connection Modes:**\n",
    "```python\n",
    "# Azure AD Authentication (recommended for cloud)\n",
    "conn = AzureSQLConnection(\n",
    "    server=\"myserver.database.windows.net\",\n",
    "    database=\"mydb\",\n",
    "    auth_mode=\"azure_ad\"\n",
    ")\n",
    "\n",
    "# SQL Authentication (username/password)\n",
    "conn = AzureSQLConnection(\n",
    "    server=\"myserver.database.windows.net\",\n",
    "    database=\"mydb\",\n",
    "    auth_mode=\"sql_auth\",\n",
    "    username=\"user\",\n",
    "    password=\"pass\"\n",
    ")\n",
    "```\n",
    "\n",
    "**Offline Fallback:**\n",
    "- This notebook uses SQLite for execution (no Azure required)\n",
    "- Configuration examples show Azure patterns\n",
    "- Safe for learning and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Environment Setup\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import yaml\n",
    "import sqlite3\n",
    "\n",
    "# Navigate to project root\n",
    "project_root = Path.cwd().parent if Path.cwd().name == 'walkthroughs' else Path.cwd()\n",
    "os.chdir(project_root)\n",
    "\n",
    "# Create artifacts directory\n",
    "artifacts_dir = Path('walkthroughs/.artifacts/12_azure_sql')\n",
    "artifacts_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Database path\n",
    "db_path = artifacts_dir / 'test_database.db'\n",
    "\n",
    "print(f\"‚úÖ Environment ready\")\n",
    "print(f\"üìÅ Artifacts: {artifacts_dir}\")\n",
    "print(f\"üóÑÔ∏è  Database: {db_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Configuration: Azure AD Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Azure AD authentication config example\n",
    "azure_ad_config = {\n",
    "    \"connection_type\": \"azure_sql\",\n",
    "    \"server\": \"mycompany.database.windows.net\",\n",
    "    \"database\": \"production_db\",\n",
    "    \"auth_mode\": \"azure_ad\",\n",
    "    \"driver\": \"ODBC Driver 17 for SQL Server\",\n",
    "    \"connection_timeout\": 30,\n",
    "    \"encrypt\": True,\n",
    "    \"trust_server_certificate\": False\n",
    "}\n",
    "\n",
    "config_path_azure_ad = artifacts_dir / 'connection_config_azure_ad.yaml'\n",
    "with open(config_path_azure_ad, 'w') as f:\n",
    "    yaml.dump(azure_ad_config, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(\"üîê Azure AD Authentication Config:\\n\")\n",
    "print(yaml.dump(azure_ad_config, default_flow_style=False, sort_keys=False))\n",
    "print(f\"‚úÖ Saved to: {config_path_azure_ad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Configuration: SQL Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SQL authentication config example\n",
    "sql_auth_config = {\n",
    "    \"connection_type\": \"azure_sql\",\n",
    "    \"server\": \"mycompany.database.windows.net\",\n",
    "    \"database\": \"production_db\",\n",
    "    \"auth_mode\": \"sql_auth\",\n",
    "    \"username\": \"${SQL_USERNAME}\",  # Environment variable reference\n",
    "    \"password\": \"${SQL_PASSWORD}\",  # Never hardcode credentials!\n",
    "    \"driver\": \"ODBC Driver 17 for SQL Server\",\n",
    "    \"connection_timeout\": 30,\n",
    "    \"encrypt\": True\n",
    "}\n",
    "\n",
    "config_path_sql_auth = artifacts_dir / 'connection_config_sql_auth.yaml'\n",
    "with open(config_path_sql_auth, 'w') as f:\n",
    "    yaml.dump(sql_auth_config, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(\"üîë SQL Authentication Config:\\n\")\n",
    "print(yaml.dump(sql_auth_config, default_flow_style=False, sort_keys=False))\n",
    "print(f\"‚úÖ Saved to: {config_path_sql_auth}\")\n",
    "print(\"\\n‚ö†Ô∏è  Note: Use environment variables for credentials!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîå Create Connection (SQLite Fallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this walkthrough, use SQLite as fallback\n",
    "# In production, you would use AzureSQLConnection\n",
    "\n",
    "# Create or connect to SQLite database\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "print(\"üîå Connection established\")\n",
    "print(f\"üìç Mode: SQLite fallback (offline-safe)\")\n",
    "print(f\"üóÑÔ∏è  Database: {db_path}\")\n",
    "print(\"\\nüí° In production, you would use:\")\n",
    "print(\"   from odibi.connections.azure_sql import AzureSQLConnection\")\n",
    "print(\"   conn = AzureSQLConnection(**config)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ñ∂Ô∏è Run: Write DataFrame to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data\n",
    "df_sales = pd.DataFrame({\n",
    "    \"product_id\": [1, 2, 3, 4, 5],\n",
    "    \"product_name\": [\"Widget\", \"Gadget\", \"Gizmo\", \"Doohickey\", \"Thingamajig\"],\n",
    "    \"category\": [\"Electronics\", \"Home\", \"Electronics\", \"Tools\", \"Home\"],\n",
    "    \"price\": [29.99, 49.99, 19.99, 39.99, 24.99],\n",
    "    \"quantity_sold\": [150, 89, 234, 56, 178]\n",
    "})\n",
    "\n",
    "print(\"üìä Sample Data:\\n\")\n",
    "print(df_sales)\n",
    "\n",
    "# Write to database\n",
    "df_sales.to_sql('products', conn, if_exists='replace', index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Wrote {len(df_sales)} rows to 'products' table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ñ∂Ô∏è Run: Read Data from Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read back from database\n",
    "df_read = pd.read_sql('SELECT * FROM products', conn)\n",
    "\n",
    "print(\"üìñ Data read from database:\\n\")\n",
    "print(df_read)\n",
    "\n",
    "# Verify row count matches\n",
    "assert len(df_read) == len(df_sales), \"Row count mismatch!\"\n",
    "print(f\"\\n‚úÖ Read {len(df_read)} rows from 'products' table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Execute: Parameterized Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe parameterized query (protects against SQL injection)\n",
    "query = \"\"\"\n",
    "SELECT product_name, category, price, quantity_sold,\n",
    "       (price * quantity_sold) as revenue\n",
    "FROM products\n",
    "WHERE category = ?\n",
    "ORDER BY revenue DESC\n",
    "\"\"\"\n",
    "\n",
    "category_filter = \"Electronics\"\n",
    "df_filtered = pd.read_sql(query, conn, params=[category_filter])\n",
    "\n",
    "print(f\"üîç Query: Products in category '{category_filter}'\\n\")\n",
    "print(df_filtered)\n",
    "\n",
    "# Save query results\n",
    "results_path = artifacts_dir / 'query_results.csv'\n",
    "df_filtered.to_csv(results_path, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Query results saved to: {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Analytics: Table Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get row counts per category\n",
    "query_stats = \"\"\"\n",
    "SELECT category, \n",
    "       COUNT(*) as product_count,\n",
    "       SUM(quantity_sold) as total_units_sold,\n",
    "       ROUND(AVG(price), 2) as avg_price\n",
    "FROM products\n",
    "GROUP BY category\n",
    "ORDER BY product_count DESC\n",
    "\"\"\"\n",
    "\n",
    "df_stats = pd.read_sql(query_stats, conn)\n",
    "\n",
    "print(\"üìä Category Statistics:\\n\")\n",
    "print(df_stats)\n",
    "\n",
    "# Convert to dict for JSON export\n",
    "row_counts = {\n",
    "    \"total_products\": int(df_read.shape[0]),\n",
    "    \"by_category\": df_stats.set_index('category')['product_count'].to_dict(),\n",
    "    \"total_units_sold\": int(df_read['quantity_sold'].sum()),\n",
    "    \"avg_price_overall\": round(float(df_read['price'].mean()), 2)\n",
    "}\n",
    "\n",
    "# Save row counts\n",
    "counts_path = artifacts_dir / 'row_counts.json'\n",
    "with open(counts_path, 'w') as f:\n",
    "    json.dump(row_counts, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Statistics saved to: {counts_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîó DSN Parsing Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example DSN connection strings for Azure SQL\n",
    "dsn_examples = {\n",
    "    \"azure_ad\": (\n",
    "        \"Driver={ODBC Driver 17 for SQL Server};\"\n",
    "        \"Server=tcp:myserver.database.windows.net,1433;\"\n",
    "        \"Database=mydb;\"\n",
    "        \"Authentication=ActiveDirectoryIntegrated;\"\n",
    "        \"Encrypt=yes;\"\n",
    "        \"TrustServerCertificate=no;\"\n",
    "    ),\n",
    "    \"sql_auth\": (\n",
    "        \"Driver={ODBC Driver 17 for SQL Server};\"\n",
    "        \"Server=tcp:myserver.database.windows.net,1433;\"\n",
    "        \"Database=mydb;\"\n",
    "        \"UID=username;\"\n",
    "        \"PWD=password;\"\n",
    "        \"Encrypt=yes;\"\n",
    "    ),\n",
    "    \"connection_string\": (\n",
    "        \"mssql+pyodbc://username:password@myserver.database.windows.net/mydb?\"\n",
    "        \"driver=ODBC+Driver+17+for+SQL+Server&Encrypt=yes\"\n",
    "    )\n",
    "}\n",
    "\n",
    "print(\"üîó Azure SQL DSN Examples:\\n\")\n",
    "for auth_type, dsn in dsn_examples.items():\n",
    "    print(f\"\\n{auth_type.upper()}:\")\n",
    "    print(f\"  {dsn}\")\n",
    "\n",
    "print(\"\\nüí° These connection strings can be used with:\")\n",
    "print(\"   - pyodbc.connect(dsn)\")\n",
    "print(\"   - sqlalchemy.create_engine(connection_string)\")\n",
    "print(\"   - AzureSQLConnection.from_dsn(dsn)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connection\n",
    "conn.close()\n",
    "\n",
    "print(\"‚úÖ Connection closed\")\n",
    "print(\"üóÑÔ∏è  SQLite database preserved for inspection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Self-Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Check SQLite database exists\n",
    "    assert db_path.exists(), \"SQLite database not found\"\n",
    "    \n",
    "    # Check config files exist\n",
    "    assert config_path_azure_ad.exists(), \"Azure AD config not found\"\n",
    "    assert config_path_sql_auth.exists(), \"SQL auth config not found\"\n",
    "    \n",
    "    # Check query results exist\n",
    "    assert (artifacts_dir / 'query_results.csv').exists(), \"Query results CSV not found\"\n",
    "    \n",
    "    # Check row counts JSON exists\n",
    "    assert (artifacts_dir / 'row_counts.json').exists(), \"Row counts JSON not found\"\n",
    "    \n",
    "    # Validate query results\n",
    "    df_check = pd.read_csv(artifacts_dir / 'query_results.csv')\n",
    "    assert len(df_check) == 2, f\"Expected 2 Electronics products, got {len(df_check)}\"\n",
    "    assert 'revenue' in df_check.columns, \"Revenue column missing\"\n",
    "    \n",
    "    # Validate row counts JSON\n",
    "    with open(artifacts_dir / 'row_counts.json') as f:\n",
    "        counts = json.load(f)\n",
    "    \n",
    "    assert counts['total_products'] == 5, f\"Expected 5 products, got {counts['total_products']}\"\n",
    "    assert 'by_category' in counts, \"Category breakdown missing\"\n",
    "    assert counts['total_units_sold'] == 707, f\"Expected 707 units, got {counts['total_units_sold']}\"\n",
    "    \n",
    "    # Validate configs\n",
    "    with open(config_path_azure_ad) as f:\n",
    "        azure_config = yaml.safe_load(f)\n",
    "    assert azure_config['auth_mode'] == 'azure_ad', \"Azure AD auth mode incorrect\"\n",
    "    \n",
    "    with open(config_path_sql_auth) as f:\n",
    "        sql_config = yaml.safe_load(f)\n",
    "    assert sql_config['auth_mode'] == 'sql_auth', \"SQL auth mode incorrect\"\n",
    "    assert '${SQL_USERNAME}' in sql_config['username'], \"Username should use env var\"\n",
    "    \n",
    "    # Check runtime\n",
    "    elapsed = time.time() - start_time\n",
    "    assert elapsed < 30, f\"Runtime {elapsed:.1f}s exceeds 30s budget\"\n",
    "    \n",
    "    print(\"üéâ Walkthrough verified successfully!\")\n",
    "    print(f\"‚è±Ô∏è  Runtime: {elapsed:.2f}s\")\n",
    "    print(f\"üóÑÔ∏è  Database size: {db_path.stat().st_size / 1024:.1f} KB\")\n",
    "    print(f\"üìä Products: {counts['total_products']}\")\n",
    "    print(f\"üì¶ Units sold: {counts['total_units_sold']}\")\n",
    "    print(f\"‚úÖ All checks passed!\")\n",
    "    \n",
    "except AssertionError as e:\n",
    "    print(f\"‚ùå Walkthrough failed: {e}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Unexpected error: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Reflection\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "1. **Dual Authentication**: Azure SQL supports both Azure AD (recommended) and SQL authentication\n",
    "2. **Safe Credentials**: Always use environment variables or secret management, never hardcode\n",
    "3. **Parameterized Queries**: Protect against SQL injection with parameterized queries\n",
    "4. **Offline Development**: SQLite fallback enables offline-safe testing and learning\n",
    "\n",
    "### Connection Pattern\n",
    "\n",
    "```python\n",
    "# In production ODIBI pipelines:\n",
    "from odibi.connections.azure_sql import AzureSQLConnection\n",
    "\n",
    "# Load config from YAML\n",
    "with open('connection_config.yaml') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Create connection\n",
    "conn = AzureSQLConnection(**config)\n",
    "\n",
    "# Use with pandas\n",
    "df = pd.read_sql(query, conn)\n",
    "df.to_sql('table_name', conn, if_exists='replace')\n",
    "```\n",
    "\n",
    "### Security Best Practices\n",
    "\n",
    "1. **Environment Variables**: `${SQL_USERNAME}`, `${SQL_PASSWORD}`\n",
    "2. **Azure Key Vault**: Store credentials centrally\n",
    "3. **Managed Identity**: Prefer Azure AD auth over SQL auth\n",
    "4. **Encryption**: Always use `Encrypt=yes` in connection strings\n",
    "5. **Least Privilege**: Grant only necessary database permissions\n",
    "\n",
    "### DSN Components\n",
    "\n",
    "- **Driver**: ODBC driver version (17 or 18)\n",
    "- **Server**: Fully qualified domain name + port\n",
    "- **Database**: Target database name\n",
    "- **Authentication**: ActiveDirectoryIntegrated, ActiveDirectoryPassword, or SQL\n",
    "- **Encryption**: Transport layer security settings\n",
    "\n",
    "---\n",
    "\n",
    "## ‚è≠ Next Steps\n",
    "\n",
    "**Continue to:** [13_advanced_connection_patterns.ipynb](13_advanced_connection_patterns.ipynb)\n",
    "\n",
    "Learn advanced patterns like connection pooling, retry logic, and multi-database operations.\n",
    "\n",
    "**Deep dive:**\n",
    "- Read `odibi/connections/azure_sql.py` - Azure SQL connection implementation\n",
    "- Read `odibi/connections/base.py` - Base connection interface\n",
    "- Read `odibi/connections/secrets.py` - Credential management system"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
