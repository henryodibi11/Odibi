{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Local Pipeline with Pandas\n",
    "\n",
    "## üß≠ Goal\n",
    "\n",
    "Run a complete data pipeline using ODIBI's Pandas engine.\n",
    "\n",
    "This notebook will:\n",
    "- Create sample sales data\n",
    "- Run the `example_local.yaml` pipeline\n",
    "- Transform Bronze ‚Üí Silver ‚Üí Gold layers\n",
    "- Inspect output files\n",
    "\n",
    "**Estimated time:** 2 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment ready\n",
      "üìÅ Working directory: c:\\Users\\hodibi\\OneDrive - Ingredion\\Desktop\\Repos\\Odibi\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Environment Setup\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "# Navigate to project root\n",
    "project_root = Path.cwd().parent if Path.cwd().name == 'walkthroughs' else Path.cwd()\n",
    "os.chdir(project_root)\n",
    "\n",
    "# Import ODIBI\n",
    "from odibi.pipeline import Pipeline\n",
    "from odibi.config import PipelineConfig, ProjectConfig\n",
    "from odibi.connections import LocalConnection\n",
    "\n",
    "print(f\"‚úÖ Environment ready\")\n",
    "print(f\"üìÅ Working directory: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Create Sample Data\n",
    "\n",
    "Let's create some sample sales data for our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sample data created\n",
      "\n",
      "Sample data preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>transaction_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T001</td>\n",
       "      <td>C001</td>\n",
       "      <td>P001</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2024-01-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T002</td>\n",
       "      <td>C001</td>\n",
       "      <td>P002</td>\n",
       "      <td>75.5</td>\n",
       "      <td>2024-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T003</td>\n",
       "      <td>C002</td>\n",
       "      <td>P001</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2024-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T004</td>\n",
       "      <td>C002</td>\n",
       "      <td>P003</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2024-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T005</td>\n",
       "      <td>C003</td>\n",
       "      <td>P002</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2024-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T006</td>\n",
       "      <td>C001</td>\n",
       "      <td>P001</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2024-02-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transaction_id customer_id product_id  amount transaction_date\n",
       "0           T001        C001       P001    50.0       2024-01-15\n",
       "1           T002        C001       P002    75.5       2024-01-20\n",
       "2           T003        C002       P001   120.0       2024-01-22\n",
       "3           T004        C002       P003    45.0       2024-01-25\n",
       "4           T005        C003       P002   200.0       2024-02-01\n",
       "5           T006        C001       P001    30.0       2024-02-05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create data directories\n",
    "Path(\"data/bronze\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create sample sales CSV\n",
    "sales_data = pd.DataFrame({\n",
    "    'transaction_id': ['T001', 'T002', 'T003', 'T004', 'T005', 'T006'],\n",
    "    'customer_id': ['C001', 'C001', 'C002', 'C002', 'C003', 'C001'],\n",
    "    'product_id': ['P001', 'P002', 'P001', 'P003', 'P002', 'P001'],\n",
    "    'amount': [50.00, 75.50, 120.00, 45.00, 200.00, 30.00],\n",
    "    'transaction_date': ['2024-01-15', '2024-01-20', '2024-01-22', '2024-01-25', '2024-02-01', '2024-02-05']\n",
    "})\n",
    "\n",
    "sales_data.to_csv('data/bronze/sales.csv', index=False)\n",
    "\n",
    "print(\"‚úÖ Sample data created\")\n",
    "print(\"\\nSample data preview:\")\n",
    "display(sales_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ñ∂Ô∏è Run Pipeline\n",
    "\n",
    "Now let's run the Bronze ‚Üí Silver ‚Üí Gold pipeline using `example_local.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function read_csv at 0x000002239AF2BA30>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'project': 'Local Pandas Example', 'engine': 'pandas', 'connections': {'data': {'type': 'local', 'base_path': './data'}, 'outputs': {'type': 'local', 'base_path': './outputs'}}, 'story': {'connection': 'outputs', 'path': 'stories/', 'max_sample_rows': 10}, 'pipelines': [{'pipeline': 'bronze_to_silver', 'layer': 'transformation', 'nodes': [{'name': 'load_raw_sales', 'read': {'connection': 'data', 'path': 'bronze/sales.csv', 'format': 'csv', 'options': {'header': 0, 'dtype': {'transaction_id': 'str', 'amount': 'float'}}}, 'cache': True}, {'name': 'clean_sales', 'depends_on': ['load_raw_sales'], 'transform': {'steps': ['SELECT\\n  transaction_id,\\n  customer_id,\\n  product_id,\\n  amount,\\n  transaction_date\\nFROM load_raw_sales\\nWHERE amount > 0  -- Remove invalid transactions\\n  AND transaction_date IS NOT NULL\\n']}}, {'name': 'save_silver', 'depends_on': ['clean_sales'], 'write': {'connection': 'data', 'path': 'silver/sales.parquet', 'format': 'parquet', 'mode': 'overwrite'}}]}, {'pipeline': 'silver_to_gold', 'layer': 'aggregation', 'nodes': [{'name': 'load_silver_sales', 'read': {'connection': 'data', 'path': 'silver/sales.parquet', 'format': 'parquet'}, 'cache': True}, {'name': 'customer_summary', 'depends_on': ['load_silver_sales'], 'transform': {'steps': ['SELECT\\n  customer_id,\\n  COUNT(*) as transaction_count,\\n  SUM(amount) as total_spent,\\n  AVG(amount) as avg_transaction,\\n  MAX(transaction_date) as last_purchase_date\\nFROM load_silver_sales\\nGROUP BY customer_id\\nHAVING total_spent > 100  -- Only customers with >$100 spend\\n']}}, {'name': 'save_gold', 'depends_on': ['customer_summary'], 'write': {'connection': 'data', 'path': 'gold/customer_summary.parquet', 'format': 'parquet', 'mode': 'overwrite'}}]}]}\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Pipeline configuration loaded (v1.1)\n",
      "   Project: Local Pandas Example\n",
      "   Engine: pandas\n",
      "   Connections: ['data', 'outputs']\n",
      "   Pipelines: 2\n"
     ]
    }
   ],
   "source": [
    "# Load pipeline configuration\n",
    "with open('examples/example_local.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"üìã Pipeline configuration loaded (v1.1)\")\n",
    "print(f\"   Project: {config['project']}\")\n",
    "print(f\"   Engine: {config['engine']}\")\n",
    "print(f\"   Connections: {list(config['connections'].keys())}\")\n",
    "print(f\"   Pipelines: {len(config['pipelines'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Concept: v1.1 Single Source of Truth\n",
    "\n",
    "**Key changes in ODIBI v1.1:**\n",
    "\n",
    "- **ProjectConfig is the single source of truth**: No raw dict parsing or field slicing needed\n",
    "  - All configuration fields (connections, story, retry, logging, pipelines) validated at load time\n",
    "  - Simply pass `ProjectConfig(**config)` - no manual filtering required\n",
    "\n",
    "- **Story configuration is mandatory**: Every pipeline generates an execution story\n",
    "  - `story.connection` specifies where stories are saved\n",
    "  - Stories provide observability into pipeline execution\n",
    "\n",
    "- **Connections use pattern**: Multiple connections supported (e.g., `data` for inputs, `outputs` for stories)\n",
    "  - Each node specifies which connection to use via `connection` field\n",
    "  - Connection objects still required at runtime for actual I/O operations\n",
    "\n",
    "**In notebooks:** Create `ProjectConfig(**config)` directly - no dict manipulation needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pipeline': 'bronze_to_silver', 'layer': 'transformation', 'nodes': [{'name': 'load_raw_sales', 'read': {'connection': 'data', 'path': 'bronze/sales.csv', 'format': 'csv', 'options': {'header': 0, 'dtype': {'transaction_id': 'str', 'amount': 'float'}}}, 'cache': True}, {'name': 'clean_sales', 'depends_on': ['load_raw_sales'], 'transform': {'steps': ['SELECT\\n  transaction_id,\\n  customer_id,\\n  product_id,\\n  amount,\\n  transaction_date\\nFROM load_raw_sales\\nWHERE amount > 0  -- Remove invalid transactions\\n  AND transaction_date IS NOT NULL\\n']}}, {'name': 'save_silver', 'depends_on': ['clean_sales'], 'write': {'connection': 'data', 'path': 'silver/sales.parquet', 'format': 'parquet', 'mode': 'overwrite'}}]}\n",
      "{'pipeline': 'silver_to_gold', 'layer': 'aggregation', 'nodes': [{'name': 'load_silver_sales', 'read': {'connection': 'data', 'path': 'silver/sales.parquet', 'format': 'parquet'}, 'cache': True}, {'name': 'customer_summary', 'depends_on': ['load_silver_sales'], 'transform': {'steps': ['SELECT\\n  customer_id,\\n  COUNT(*) as transaction_count,\\n  SUM(amount) as total_spent,\\n  AVG(amount) as avg_transaction,\\n  MAX(transaction_date) as last_purchase_date\\nFROM load_silver_sales\\nGROUP BY customer_id\\nHAVING total_spent > 100  -- Only customers with >$100 spend\\n']}}, {'name': 'save_gold', 'depends_on': ['customer_summary'], 'write': {'connection': 'data', 'path': 'gold/customer_summary.parquet', 'format': 'parquet', 'mode': 'overwrite'}}]}\n"
     ]
    }
   ],
   "source": [
    "for pipeline in (config['pipelines']):\n",
    "    print(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Running Bronze ‚Üí Silver pipeline...\n",
      "\n",
      "\n",
      "‚úÖ Pipeline completed\n",
      "   Completed nodes: 3\n",
      "   Failed nodes: 0\n",
      "   Nodes: ['load_raw_sales', 'clean_sales', 'save_silver']\n"
     ]
    }
   ],
   "source": [
    "# Run Bronze ‚Üí Silver pipeline\n",
    "print(\"\\nüîÑ Running Bronze ‚Üí Silver pipeline...\\n\")\n",
    "\n",
    "# v1.1: ProjectConfig is single source of truth - no dict slicing needed\n",
    "project_config = ProjectConfig(**config)\n",
    "pipeline_config = PipelineConfig(**config['pipelines'][0])\n",
    "\n",
    "# Create runtime connection instances\n",
    "# v1.1 uses multiple connections: 'data' for inputs, 'outputs' for stories\n",
    "connections = {\n",
    "    'data': LocalConnection(base_path='./data'),\n",
    "    'outputs': LocalConnection(base_path='./outputs')\n",
    "}\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline(\n",
    "    pipeline_config=pipeline_config,\n",
    "    engine=project_config.engine,\n",
    "    connections=connections\n",
    ")\n",
    "results = pipeline.run()\n",
    "\n",
    "# Check results\n",
    "print(f\"\\n‚úÖ Pipeline completed\")\n",
    "print(f\"   Completed nodes: {len(results.completed)}\")\n",
    "print(f\"   Failed nodes: {len(results.failed)}\")\n",
    "print(f\"   Nodes: {results.completed}\")\n",
    "\n",
    "# Debug tip: If pipeline fails, inspect failures\n",
    "if results.failed:\n",
    "    print(f\"\\n‚ö†Ô∏è Failed nodes detected:\")\n",
    "    for node_name in results.failed:\n",
    "        node_result = results.get_node_result(node_name)\n",
    "        if node_result and node_result.error:\n",
    "            print(f\"   {node_name}: {node_result.error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Running Silver ‚Üí Gold pipeline...\n",
      "\n",
      "\n",
      "‚úÖ Pipeline completed\n",
      "   Completed nodes: 3\n",
      "   Failed nodes: 0\n",
      "   Nodes: ['load_silver_sales', 'customer_summary', 'save_gold']\n"
     ]
    }
   ],
   "source": [
    "# Run Silver ‚Üí Gold pipeline\n",
    "print(\"\\nüîÑ Running Silver ‚Üí Gold pipeline...\\n\")\n",
    "\n",
    "pipeline_config = PipelineConfig(**config['pipelines'][1])\n",
    "pipeline = Pipeline(\n",
    "    pipeline_config=pipeline_config,\n",
    "    engine=project_config.engine,\n",
    "    connections=connections  # Reuse connection objects from above\n",
    ")\n",
    "results = pipeline.run()\n",
    "\n",
    "print(f\"\\n‚úÖ Pipeline completed\")\n",
    "print(f\"   Completed nodes: {len(results.completed)}\")\n",
    "print(f\"   Failed nodes: {len(results.failed)}\")\n",
    "print(f\"   Nodes: {results.completed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° How SQL Works with the Pandas Engine\n",
    "\n",
    "**You might wonder:** How can we use SQL with `engine='pandas'`?\n",
    "\n",
    "**Answer:** ODIBI uses [DuckDB](https://duckdb.org/) to run SQL queries over in-memory Pandas DataFrames:\n",
    "- Each node's output is registered as a SQL view using the **node name**\n",
    "- In the pipeline YAML, you can reference upstream nodes directly in SQL (e.g., `FROM load_raw_sales`)\n",
    "- DuckDB translates SQL to DataFrame operations automatically\n",
    "\n",
    "**Example from `example_local.yaml`:**\n",
    "```sql\n",
    "SELECT transaction_id, customer_id, amount\n",
    "FROM load_raw_sales  -- ‚Üê This is the upstream node name!\n",
    "WHERE amount > 0\n",
    "```\n",
    "\n",
    "This is why node naming is important - they become your SQL table names!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Inspect Outputs\n",
    "\n",
    "Let's examine the data at each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Bronze Layer (Raw Data):\n",
      "   Rows: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>transaction_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T001</td>\n",
       "      <td>C001</td>\n",
       "      <td>P001</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2024-01-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T002</td>\n",
       "      <td>C001</td>\n",
       "      <td>P002</td>\n",
       "      <td>75.5</td>\n",
       "      <td>2024-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T003</td>\n",
       "      <td>C002</td>\n",
       "      <td>P001</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2024-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T004</td>\n",
       "      <td>C002</td>\n",
       "      <td>P003</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2024-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T005</td>\n",
       "      <td>C003</td>\n",
       "      <td>P002</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2024-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T006</td>\n",
       "      <td>C001</td>\n",
       "      <td>P001</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2024-02-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transaction_id customer_id product_id  amount transaction_date\n",
       "0           T001        C001       P001    50.0       2024-01-15\n",
       "1           T002        C001       P002    75.5       2024-01-20\n",
       "2           T003        C002       P001   120.0       2024-01-22\n",
       "3           T004        C002       P003    45.0       2024-01-25\n",
       "4           T005        C003       P002   200.0       2024-02-01\n",
       "5           T006        C001       P001    30.0       2024-02-05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check Bronze layer (original CSV)\n",
    "bronze_data = pd.read_csv('data/bronze/sales.csv')\n",
    "print(\"üìÅ Bronze Layer (Raw Data):\")\n",
    "print(f\"   Rows: {len(bronze_data)}\")\n",
    "display(bronze_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Silver Layer (Cleaned Data):\n",
      "   Rows: 6\n",
      "   Columns: ['transaction_id', 'customer_id', 'product_id', 'amount', 'transaction_date']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>transaction_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T001</td>\n",
       "      <td>C001</td>\n",
       "      <td>P001</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2024-01-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T002</td>\n",
       "      <td>C001</td>\n",
       "      <td>P002</td>\n",
       "      <td>75.5</td>\n",
       "      <td>2024-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T003</td>\n",
       "      <td>C002</td>\n",
       "      <td>P001</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2024-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T004</td>\n",
       "      <td>C002</td>\n",
       "      <td>P003</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2024-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T005</td>\n",
       "      <td>C003</td>\n",
       "      <td>P002</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2024-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T006</td>\n",
       "      <td>C001</td>\n",
       "      <td>P001</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2024-02-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transaction_id customer_id product_id  amount transaction_date\n",
       "0           T001        C001       P001    50.0       2024-01-15\n",
       "1           T002        C001       P002    75.5       2024-01-20\n",
       "2           T003        C002       P001   120.0       2024-01-22\n",
       "3           T004        C002       P003    45.0       2024-01-25\n",
       "4           T005        C003       P002   200.0       2024-02-01\n",
       "5           T006        C001       P001    30.0       2024-02-05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check Silver layer (cleaned Parquet)\n",
    "silver_data = pd.read_parquet('data/silver/sales.parquet')\n",
    "print(\"\\nüìÅ Silver Layer (Cleaned Data):\")\n",
    "print(f\"   Rows: {len(silver_data)}\")\n",
    "print(f\"   Columns: {list(silver_data.columns)}\")\n",
    "display(silver_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Gold Layer (Customer Analytics):\n",
      "   Rows: 4\n",
      "   Columns: ['customer_id', 'transaction_count', 'total_spent', 'avg_transaction', 'last_purchase_date']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>transaction_count</th>\n",
       "      <th>total_spent</th>\n",
       "      <th>avg_transaction</th>\n",
       "      <th>last_purchase_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C002</td>\n",
       "      <td>2</td>\n",
       "      <td>145.0</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>2024-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C001</td>\n",
       "      <td>3</td>\n",
       "      <td>155.5</td>\n",
       "      <td>51.833333</td>\n",
       "      <td>2024-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C003</td>\n",
       "      <td>1</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>2024-01-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C004</td>\n",
       "      <td>1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>2024-02-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id  transaction_count  total_spent  avg_transaction  \\\n",
       "0        C002                  2        145.0        72.500000   \n",
       "1        C001                  3        155.5        51.833333   \n",
       "2        C003                  1        150.0       150.000000   \n",
       "3        C004                  1        200.0       200.000000   \n",
       "\n",
       "  last_purchase_date  \n",
       "0         2024-01-25  \n",
       "1         2024-02-01  \n",
       "2         2024-01-28  \n",
       "3         2024-02-05  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check Gold layer (aggregated analytics)\n",
    "gold_data = pd.read_parquet('data/gold/customer_summary.parquet')\n",
    "print(\"\\nüìÅ Gold Layer (Customer Analytics):\")\n",
    "print(f\"   Rows: {len(gold_data)}\")\n",
    "print(f\"   Columns: {list(gold_data.columns)}\")\n",
    "display(gold_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Troubleshooting\n",
    "\n",
    "**Common issues and solutions (v1.1):**\n",
    "\n",
    "| Error | Cause | Solution |\n",
    "|-------|-------|----------|\n",
    "| `ValidationError: story is required` | Missing mandatory story field in YAML | Add `story:` section with `connection`, `path`, `enabled` fields |\n",
    "| `ValidationError: story.connection is required` | Story section missing connection field | Add `connection: outputs` to story section |\n",
    "| `KeyError: 'data'` | Connection name mismatch | Ensure nodes use `connection: data` and connections dict has `'data': LocalConnection(...)` |\n",
    "| `FileNotFoundError: data/silver/sales.parquet` | Wrong working directory or pipeline failed | Re-run Setup cell; check `results.failed` for errors |\n",
    "| `ImportError: Missing optional dependency 'pyarrow'` | Parquet library not installed | Run: `pip install pyarrow` |\n",
    "| `KeyError: 'load_raw_sales'` in SQL | Node name mismatch in dependencies or SQL | Ensure SQL table names match upstream node names exactly |\n",
    "| Pipeline runs but no output files | Pipeline node failed silently | Check `results.failed` and inspect node errors (see debug code above) |\n",
    "\n",
    "**Debug checklist:**\n",
    "1. ‚úÖ Re-run Setup cell to ensure correct working directory\n",
    "2. ‚úÖ Check `results.failed` for any failed nodes\n",
    "3. ‚úÖ Verify YAML has required fields: `story`, `connections`, `pipelines`\n",
    "4. ‚úÖ Ensure connection objects match YAML connection names (e.g., `'data'`, `'outputs'`)\n",
    "5. ‚úÖ Ensure bronze data exists: `data/bronze/sales.csv`\n",
    "6. ‚úÖ Install dependencies: `pip install pyarrow pyyaml pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü™û Reflect\n",
    "\n",
    "**What we learned:**\n",
    "- Created sample data programmatically\n",
    "- Ran a multi-layer pipeline (Bronze ‚Üí Silver ‚Üí Gold)\n",
    "- Transformed CSV to Parquet format\n",
    "- Applied SQL-based filtering and aggregation\n",
    "- Inspected outputs at each layer\n",
    "\n",
    "**Key concepts:**\n",
    "- **Bronze:** Raw data, minimal processing\n",
    "- **Silver:** Cleaned, validated, ready for analysis\n",
    "- **Gold:** Business-level aggregates and metrics\n",
    "\n",
    "**Next step:**  \n",
    "Go to **`02_cli_and_testing.ipynb`** to learn about CLI tools and testing (Phase 2 preview)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Self-Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running self-check...\n",
      "‚úÖ Data pipeline ran successfully\n",
      "   Bronze: 6 rows\n",
      "   Silver: 6 rows\n",
      "   Gold: 4 customers\n",
      "üéâ Walkthrough 01 verified successfully\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Self-Check\n",
    "try:\n",
    "    import sys, os\n",
    "    print(\"Running self-check...\")\n",
    "    \n",
    "    # Verify example config exists\n",
    "    assert os.path.exists(\"examples/example_local.yaml\"), \"Missing example_local.yaml\"\n",
    "    \n",
    "    # Verify data layers were created\n",
    "    assert os.path.exists(\"data/bronze/sales.csv\"), \"Missing Bronze layer\"\n",
    "    assert os.path.exists(\"data/silver/sales.parquet\"), \"Missing Silver layer\"\n",
    "    assert os.path.exists(\"data/gold/customer_summary.parquet\"), \"Missing Gold layer\"\n",
    "    \n",
    "    # Verify data integrity\n",
    "    import pandas as pd\n",
    "    gold = pd.read_parquet(\"data/gold/customer_summary.parquet\")\n",
    "    assert len(gold) > 0, \"Gold layer has no data\"\n",
    "    assert 'total_spent' in gold.columns, \"Missing expected column in Gold layer\"\n",
    "    \n",
    "    print(\"‚úÖ Data pipeline ran successfully\")\n",
    "    print(f\"   Bronze: {len(pd.read_csv('data/bronze/sales.csv'))} rows\")\n",
    "    print(f\"   Silver: {len(pd.read_parquet('data/silver/sales.parquet'))} rows\")\n",
    "    print(f\"   Gold: {len(gold)} customers\")\n",
    "    \n",
    "    print(\"üéâ Walkthrough 01 verified successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Walkthrough failed self-check: {e}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
