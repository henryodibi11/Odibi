{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Local Pipeline with Pandas\n",
    "\n",
    "## üß≠ Goal\n",
    "\n",
    "Run a complete data pipeline using ODIBI's Pandas engine.\n",
    "\n",
    "This notebook will:\n",
    "- Create sample sales data\n",
    "- Run the `example_local.yaml` pipeline\n",
    "- Transform Bronze ‚Üí Silver ‚Üí Gold layers\n",
    "- Inspect output files\n",
    "\n",
    "**Estimated time:** 2 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Environment Setup\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "# Navigate to project root\n",
    "project_root = Path.cwd().parent if Path.cwd().name == 'walkthroughs' else Path.cwd()\n",
    "os.chdir(project_root)\n",
    "\n",
    "# Import ODIBI\n",
    "from odibi.pipeline import Pipeline\n",
    "from odibi.config import PipelineConfig, ProjectConfig\n",
    "from odibi.connections import LocalConnection\n",
    "\n",
    "print(f\"‚úÖ Environment ready\")\n",
    "print(f\"üìÅ Working directory: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Create Sample Data\n",
    "\n",
    "Let's create some sample sales data for our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directories\n",
    "Path(\"data/bronze\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create sample sales CSV\n",
    "sales_data = pd.DataFrame({\n",
    "    'transaction_id': ['T001', 'T002', 'T003', 'T004', 'T005', 'T006'],\n",
    "    'customer_id': ['C001', 'C001', 'C002', 'C002', 'C003', 'C001'],\n",
    "    'product_id': ['P001', 'P002', 'P001', 'P003', 'P002', 'P001'],\n",
    "    'amount': [50.00, 75.50, 120.00, 45.00, 200.00, 30.00],\n",
    "    'transaction_date': ['2024-01-15', '2024-01-20', '2024-01-22', '2024-01-25', '2024-02-01', '2024-02-05']\n",
    "})\n",
    "\n",
    "sales_data.to_csv('data/bronze/sales.csv', index=False)\n",
    "\n",
    "print(\"‚úÖ Sample data created\")\n",
    "print(\"\\nSample data preview:\")\n",
    "display(sales_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ñ∂Ô∏è Run Pipeline\n",
    "\n",
    "Now let's run the Bronze ‚Üí Silver ‚Üí Gold pipeline using `example_local.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline configuration\n",
    "with open('examples/example_local.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"üìã Pipeline configuration loaded\")\n",
    "print(f\"   Project: {config['project']}\")\n",
    "print(f\"   Engine: {config['engine']}\")\n",
    "print(f\"   Pipelines: {len(config['pipelines'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Bronze ‚Üí Silver pipeline\n",
    "print(\"\\nüîÑ Running Bronze ‚Üí Silver pipeline...\\n\")\n",
    "\n",
    "pipeline_config = PipelineConfig(**config['pipelines'][0])\n",
    "project_config = ProjectConfig(**{k: v for k, v in config.items() if k != 'pipelines'})\n",
    "\n",
    "# Create connection objects (NOT raw dicts from config)\n",
    "connections = {\n",
    "    'local': LocalConnection(base_path='./data')\n",
    "}\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline(\n",
    "    pipeline_config=pipeline_config,\n",
    "    engine=project_config.engine,\n",
    "    connections=connections\n",
    ")\n",
    "results = pipeline.run()\n",
    "\n",
    "# Check results\n",
    "print(f\"\\n‚úÖ Pipeline completed\")\n",
    "print(f\"   Completed nodes: {len(results.completed)}\")\n",
    "print(f\"   Failed nodes: {len(results.failed)}\")\n",
    "print(f\"   Nodes: {results.completed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Silver ‚Üí Gold pipeline\n",
    "print(\"\\nüîÑ Running Silver ‚Üí Gold pipeline...\\n\")\n",
    "\n",
    "pipeline_config = PipelineConfig(**config['pipelines'][1])\n",
    "pipeline = Pipeline(\n",
    "    pipeline_config=pipeline_config,\n",
    "    engine=project_config.engine,\n",
    "    connections=connections  # Reuse connection objects from above\n",
    ")\n",
    "results = pipeline.run()\n",
    "\n",
    "print(f\"\\n‚úÖ Pipeline completed\")\n",
    "print(f\"   Completed nodes: {len(results.completed)}\")\n",
    "print(f\"   Failed nodes: {len(results.failed)}\")\n",
    "print(f\"   Nodes: {results.completed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Inspect Outputs\n",
    "\n",
    "Let's examine the data at each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Bronze layer (original CSV)\n",
    "bronze_data = pd.read_csv('data/bronze/sales.csv')\n",
    "print(\"üìÅ Bronze Layer (Raw Data):\")\n",
    "print(f\"   Rows: {len(bronze_data)}\")\n",
    "display(bronze_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Silver layer (cleaned Parquet)\n",
    "silver_data = pd.read_parquet('data/silver/sales.parquet')\n",
    "print(\"\\nüìÅ Silver Layer (Cleaned Data):\")\n",
    "print(f\"   Rows: {len(silver_data)}\")\n",
    "print(f\"   Columns: {list(silver_data.columns)}\")\n",
    "display(silver_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Gold layer (aggregated analytics)\n",
    "gold_data = pd.read_parquet('data/gold/customer_summary.parquet')\n",
    "print(\"\\nüìÅ Gold Layer (Customer Analytics):\")\n",
    "print(f\"   Rows: {len(gold_data)}\")\n",
    "print(f\"   Columns: {list(gold_data.columns)}\")\n",
    "display(gold_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü™û Reflect\n",
    "\n",
    "**What we learned:**\n",
    "- Created sample data programmatically\n",
    "- Ran a multi-layer pipeline (Bronze ‚Üí Silver ‚Üí Gold)\n",
    "- Transformed CSV to Parquet format\n",
    "- Applied SQL-based filtering and aggregation\n",
    "- Inspected outputs at each layer\n",
    "\n",
    "**Key concepts:**\n",
    "- **Bronze:** Raw data, minimal processing\n",
    "- **Silver:** Cleaned, validated, ready for analysis\n",
    "- **Gold:** Business-level aggregates and metrics\n",
    "\n",
    "**Next step:**  \n",
    "Go to **`02_cli_and_testing.ipynb`** to learn about CLI tools and testing (Phase 2 preview)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Self-Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Self-Check\n",
    "try:\n",
    "    import sys, os\n",
    "    print(\"Running self-check...\")\n",
    "    \n",
    "    # Verify example config exists\n",
    "    assert os.path.exists(\"examples/example_local.yaml\"), \"Missing example_local.yaml\"\n",
    "    \n",
    "    # Verify data layers were created\n",
    "    assert os.path.exists(\"data/bronze/sales.csv\"), \"Missing Bronze layer\"\n",
    "    assert os.path.exists(\"data/silver/sales.parquet\"), \"Missing Silver layer\"\n",
    "    assert os.path.exists(\"data/gold/customer_summary.parquet\"), \"Missing Gold layer\"\n",
    "    \n",
    "    # Verify data integrity\n",
    "    import pandas as pd\n",
    "    gold = pd.read_parquet(\"data/gold/customer_summary.parquet\")\n",
    "    assert len(gold) > 0, \"Gold layer has no data\"\n",
    "    assert 'total_spent' in gold.columns, \"Missing expected column in Gold layer\"\n",
    "    \n",
    "    print(\"‚úÖ Data pipeline ran successfully\")\n",
    "    print(f\"   Bronze: {len(pd.read_csv('data/bronze/sales.csv'))} rows\")\n",
    "    print(f\"   Silver: {len(pd.read_parquet('data/silver/sales.parquet'))} rows\")\n",
    "    print(f\"   Gold: {len(gold)} customers\")\n",
    "    \n",
    "    print(\"üéâ Walkthrough 01 verified successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Walkthrough failed self-check: {e}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
