{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 - CLI Story Tools: Generate, Diff, List\n",
    "\n",
    "## üß≠ Goal\n",
    "\n",
    "Master ODIBI's CLI story commands to generate, compare, and manage pipeline execution stories.\n",
    "\n",
    "This notebook will:\n",
    "- Demonstrate `odibi story generate`, `odibi story list`, and `odibi story diff` commands\n",
    "- Use subprocess to call CLI commands (with fallback to Python functions)\n",
    "- Show how to compare pipeline runs across configuration changes\n",
    "- Practice the story diffing workflow for pipeline debugging\n",
    "- Track changes between pipeline executions\n",
    "\n",
    "**Estimated time:** 30 seconds\n",
    "\n",
    "---\n",
    "\n",
    "## üß± Core Concepts\n",
    "\n",
    "**Story Generation Workflow:**\n",
    "```bash\n",
    "# Generate a story from pipeline run\n",
    "odibi story generate --run-dir ./runs/run_1 --output story.json\n",
    "\n",
    "# List all available stories\n",
    "odibi story list --runs-dir ./runs\n",
    "\n",
    "# Compare two story runs\n",
    "odibi story diff --run-1 ./runs/run_1 --run-2 ./runs/run_2\n",
    "```\n",
    "\n",
    "**Why Stories Matter:**\n",
    "- Track what changed between pipeline runs\n",
    "- Debug configuration changes\n",
    "- Understand data transformations\n",
    "- Audit pipeline behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Environment Setup\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import subprocess\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "# Navigate to project root\n",
    "project_root = Path.cwd().parent if Path.cwd().name == 'walkthroughs' else Path.cwd()\n",
    "os.chdir(project_root)\n",
    "\n",
    "# Create artifacts directory\n",
    "artifacts_dir = Path('walkthroughs/.artifacts/11_cli')\n",
    "artifacts_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create run directories\n",
    "run1_dir = artifacts_dir / 'runs' / 'run_1'\n",
    "run2_dir = artifacts_dir / 'runs' / 'run_2'\n",
    "run1_dir.mkdir(parents=True, exist_ok=True)\n",
    "run2_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check if CLI is available\n",
    "def check_cli():\n",
    "    \"\"\"Check if odibi CLI is available.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(['odibi', '--version'], capture_output=True, text=True, timeout=5)\n",
    "        return result.returncode == 0\n",
    "    except (FileNotFoundError, subprocess.TimeoutExpired):\n",
    "        return False\n",
    "\n",
    "cli_available = check_cli()\n",
    "\n",
    "print(f\"‚úÖ Environment ready\")\n",
    "print(f\"üìÅ Artifacts: {artifacts_dir}\")\n",
    "print(f\"üîß CLI available: {cli_available}\")\n",
    "if not cli_available:\n",
    "    print(\"‚ö†Ô∏è  Will use Python fallback functions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Create: Sample Pipeline Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create first configuration (conservative threshold)\n",
    "config_v1 = {\n",
    "    \"pipeline\": \"sales_analysis\",\n",
    "    \"version\": \"1.0\",\n",
    "    \"parameters\": {\n",
    "        \"threshold\": 100,\n",
    "        \"filter_type\": \"greater_than\",\n",
    "        \"aggregation\": \"sum\"\n",
    "    },\n",
    "    \"nodes\": [\n",
    "        {\"id\": \"load\", \"operation\": \"load_csv\", \"params\": {\"path\": \"data.csv\"}},\n",
    "        {\"id\": \"filter\", \"operation\": \"filter_threshold\", \"params\": {\"threshold\": 100}},\n",
    "        {\"id\": \"aggregate\", \"operation\": \"group_by\", \"params\": {\"by\": \"category\"}}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create second configuration (higher threshold)\n",
    "config_v2 = {\n",
    "    \"pipeline\": \"sales_analysis\",\n",
    "    \"version\": \"2.0\",\n",
    "    \"parameters\": {\n",
    "        \"threshold\": 250,  # Changed!\n",
    "        \"filter_type\": \"greater_than\",\n",
    "        \"aggregation\": \"sum\"\n",
    "    },\n",
    "    \"nodes\": [\n",
    "        {\"id\": \"load\", \"operation\": \"load_csv\", \"params\": {\"path\": \"data.csv\"}},\n",
    "        {\"id\": \"filter\", \"operation\": \"filter_threshold\", \"params\": {\"threshold\": 250}},  # Changed!\n",
    "        {\"id\": \"aggregate\", \"operation\": \"group_by\", \"params\": {\"by\": \"category\"}}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Save configurations\n",
    "with open(artifacts_dir / 'config_v1.yaml', 'w') as f:\n",
    "    f.write(f\"# Configuration v1.0 - Threshold: {config_v1['parameters']['threshold']}\\n\")\n",
    "    json.dump(config_v1, f, indent=2)\n",
    "\n",
    "with open(artifacts_dir / 'config_v2.yaml', 'w') as f:\n",
    "    f.write(f\"# Configuration v2.0 - Threshold: {config_v2['parameters']['threshold']}\\n\")\n",
    "    json.dump(config_v2, f, indent=2)\n",
    "\n",
    "print(\"üìù Created pipeline configurations:\")\n",
    "print(f\"   v1: threshold={config_v1['parameters']['threshold']}\")\n",
    "print(f\"   v2: threshold={config_v2['parameters']['threshold']}\")\n",
    "print(f\"\\n‚úÖ Configs saved to {artifacts_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ñ∂Ô∏è Run: Generate Stories (with CLI or Fallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample story data for both runs\n",
    "def create_story(run_name, threshold, row_count):\n",
    "    \"\"\"Generate a sample story JSON.\"\"\"\n",
    "    return {\n",
    "        \"run_id\": run_name,\n",
    "        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"config\": {\n",
    "            \"threshold\": threshold,\n",
    "            \"filter_type\": \"greater_than\"\n",
    "        },\n",
    "        \"execution\": [\n",
    "            {\"node\": \"load\", \"status\": \"success\", \"rows_in\": 1000, \"rows_out\": 1000},\n",
    "            {\"node\": \"filter\", \"status\": \"success\", \"rows_in\": 1000, \"rows_out\": row_count},\n",
    "            {\"node\": \"aggregate\", \"status\": \"success\", \"rows_in\": row_count, \"rows_out\": 5}\n",
    "        ],\n",
    "        \"summary\": {\n",
    "            \"total_rows_processed\": 1000,\n",
    "            \"final_rows\": 5,\n",
    "            \"filtered_out\": 1000 - row_count\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Generate stories using CLI or fallback\n",
    "def generate_story_cli(run_dir, config, threshold, row_count):\n",
    "    \"\"\"Generate story using CLI or Python fallback.\"\"\"\n",
    "    story_path = run_dir / 'story.json'\n",
    "    \n",
    "    if cli_available:\n",
    "        try:\n",
    "            # Try CLI command\n",
    "            cmd = ['odibi', 'story', 'generate', '--run-dir', str(run_dir), '--output', str(story_path)]\n",
    "            result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)\n",
    "            if result.returncode == 0:\n",
    "                print(f\"‚úÖ CLI: Generated story for {run_dir.name}\")\n",
    "                return True\n",
    "        except (subprocess.TimeoutExpired, Exception) as e:\n",
    "            print(f\"‚ö†Ô∏è  CLI failed: {e}\")\n",
    "    \n",
    "    # Fallback: Generate story directly\n",
    "    story = create_story(run_dir.name, threshold, row_count)\n",
    "    with open(story_path, 'w') as f:\n",
    "        json.dump(story, f, indent=2)\n",
    "    print(f\"‚úÖ Python: Generated story for {run_dir.name}\")\n",
    "    return False\n",
    "\n",
    "# Generate both stories\n",
    "print(\"üîÑ Generating stories...\\n\")\n",
    "used_cli_1 = generate_story_cli(run1_dir, config_v1, 100, 750)\n",
    "time.sleep(0.1)  # Ensure different timestamps\n",
    "used_cli_2 = generate_story_cli(run2_dir, config_v2, 250, 400)\n",
    "\n",
    "print(f\"\\nüì¶ Stories created:\")\n",
    "print(f\"   - {run1_dir / 'story.json'}\")\n",
    "print(f\"   - {run2_dir / 'story.json'}\")\n",
    "print(f\"\\nüîß Method: {'CLI' if (used_cli_1 or used_cli_2) else 'Python fallback'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã List: Discover All Available Stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List stories using CLI or fallback\n",
    "def list_stories_cli(runs_dir):\n",
    "    \"\"\"List stories using CLI or Python fallback.\"\"\"\n",
    "    output_path = artifacts_dir / 'story_list.txt'\n",
    "    \n",
    "    if cli_available:\n",
    "        try:\n",
    "            cmd = ['odibi', 'story', 'list', '--runs-dir', str(runs_dir)]\n",
    "            result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)\n",
    "            if result.returncode == 0:\n",
    "                with open(output_path, 'w') as f:\n",
    "                    f.write(result.stdout)\n",
    "                print(\"‚úÖ CLI: Listed all stories\")\n",
    "                print(result.stdout)\n",
    "                return\n",
    "        except (subprocess.TimeoutExpired, Exception) as e:\n",
    "            print(f\"‚ö†Ô∏è  CLI failed: {e}\")\n",
    "    \n",
    "    # Fallback: List stories with Python\n",
    "    stories = []\n",
    "    for run_dir in runs_dir.iterdir():\n",
    "        if run_dir.is_dir():\n",
    "            story_file = run_dir / 'story.json'\n",
    "            if story_file.exists():\n",
    "                with open(story_file) as f:\n",
    "                    story = json.load(f)\n",
    "                stories.append({\n",
    "                    'run': run_dir.name,\n",
    "                    'timestamp': story.get('timestamp', 'unknown'),\n",
    "                    'threshold': story.get('config', {}).get('threshold', 'N/A'),\n",
    "                    'rows_processed': story.get('summary', {}).get('total_rows_processed', 0)\n",
    "                })\n",
    "    \n",
    "    output = \"üìã Available Stories:\\n\\n\"\n",
    "    for s in stories:\n",
    "        output += f\"  ‚Ä¢ {s['run']:10} | {s['timestamp']} | threshold={s['threshold']:3} | rows={s['rows_processed']}\\n\"\n",
    "    \n",
    "    print(output)\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(output)\n",
    "    print(\"‚úÖ Python: Listed all stories\")\n",
    "\n",
    "print(\"üîç Listing all available stories...\\n\")\n",
    "list_stories_cli(artifacts_dir / 'runs')\n",
    "print(f\"\\nüíæ List saved to: {artifacts_dir / 'story_list.txt'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Diff: Compare Two Pipeline Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diff stories using CLI or fallback\n",
    "def diff_stories_cli(run1_dir, run2_dir):\n",
    "    \"\"\"Diff two stories using CLI or Python fallback.\"\"\"\n",
    "    output_path = artifacts_dir / 'diff_run_1_run_2.txt'\n",
    "    \n",
    "    if cli_available:\n",
    "        try:\n",
    "            cmd = ['odibi', 'story', 'diff', '--run-1', str(run1_dir), '--run-2', str(run2_dir)]\n",
    "            result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)\n",
    "            if result.returncode == 0:\n",
    "                with open(output_path, 'w') as f:\n",
    "                    f.write(result.stdout)\n",
    "                print(\"‚úÖ CLI: Generated diff\")\n",
    "                print(result.stdout)\n",
    "                return\n",
    "        except (subprocess.TimeoutExpired, Exception) as e:\n",
    "            print(f\"‚ö†Ô∏è  CLI failed: {e}\")\n",
    "    \n",
    "    # Fallback: Diff stories with Python\n",
    "    with open(run1_dir / 'story.json') as f:\n",
    "        story1 = json.load(f)\n",
    "    with open(run2_dir / 'story.json') as f:\n",
    "        story2 = json.load(f)\n",
    "    \n",
    "    diff_output = f\"üîç Story Diff: {run1_dir.name} ‚Üí {run2_dir.name}\\n\\n\"\n",
    "    diff_output += \"=\"*60 + \"\\n\\n\"\n",
    "    \n",
    "    # Compare configurations\n",
    "    diff_output += \"üìù Configuration Changes:\\n\"\n",
    "    threshold1 = story1.get('config', {}).get('threshold', 'N/A')\n",
    "    threshold2 = story2.get('config', {}).get('threshold', 'N/A')\n",
    "    \n",
    "    if threshold1 != threshold2:\n",
    "        diff_output += f\"  ‚ö†Ô∏è  threshold changed: {threshold1} ‚Üí {threshold2}\\n\"\n",
    "    else:\n",
    "        diff_output += f\"  ‚úì threshold unchanged: {threshold1}\\n\"\n",
    "    \n",
    "    diff_output += \"\\nüìä Execution Comparison:\\n\"\n",
    "    \n",
    "    # Compare execution nodes\n",
    "    for i, (node1, node2) in enumerate(zip(story1.get('execution', []), story2.get('execution', []))):\n",
    "        node_name = node1.get('node', f'node_{i}')\n",
    "        rows1 = node1.get('rows_out', 0)\n",
    "        rows2 = node2.get('rows_out', 0)\n",
    "        \n",
    "        if rows1 != rows2:\n",
    "            diff_output += f\"  ‚ö†Ô∏è  {node_name}: {rows1} ‚Üí {rows2} rows (difference: {rows2-rows1:+d})\\n\"\n",
    "        else:\n",
    "            diff_output += f\"  ‚úì {node_name}: {rows1} rows (unchanged)\\n\"\n",
    "    \n",
    "    # Summary comparison\n",
    "    diff_output += \"\\nüìà Summary Differences:\\n\"\n",
    "    filtered1 = story1.get('summary', {}).get('filtered_out', 0)\n",
    "    filtered2 = story2.get('summary', {}).get('filtered_out', 0)\n",
    "    diff_output += f\"  ‚Ä¢ Filtered out: {filtered1} ‚Üí {filtered2} (difference: {filtered2-filtered1:+d})\\n\"\n",
    "    \n",
    "    print(diff_output)\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(diff_output)\n",
    "    print(\"‚úÖ Python: Generated diff\")\n",
    "\n",
    "print(\"‚öñÔ∏è  Comparing run_1 vs run_2...\\n\")\n",
    "diff_stories_cli(run1_dir, run2_dir)\n",
    "print(f\"\\nüíæ Diff saved to: {artifacts_dir / 'diff_run_1_run_2.txt'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîé Inspect: View Story Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display both stories\n",
    "print(\"üìñ Story Details:\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for run_dir in [run1_dir, run2_dir]:\n",
    "    with open(run_dir / 'story.json') as f:\n",
    "        story = json.load(f)\n",
    "    \n",
    "    print(f\"\\nüè∑Ô∏è  {story['run_id'].upper()}\")\n",
    "    print(f\"‚è∞ Timestamp: {story['timestamp']}\")\n",
    "    print(f\"‚öôÔ∏è  Threshold: {story['config']['threshold']}\")\n",
    "    print(f\"üìä Processed: {story['summary']['total_rows_processed']} rows\")\n",
    "    print(f\"üóëÔ∏è  Filtered: {story['summary']['filtered_out']} rows\")\n",
    "    print(f\"‚úÖ Final: {story['summary']['final_rows']} rows\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "print(\"\\n‚úÖ Both stories loaded and inspected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Self-Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Check run directories exist\n",
    "    assert run1_dir.exists(), f\"Run 1 directory not found: {run1_dir}\"\n",
    "    assert run2_dir.exists(), f\"Run 2 directory not found: {run2_dir}\"\n",
    "    \n",
    "    # Check story files exist\n",
    "    assert (run1_dir / 'story.json').exists(), \"story.json not found in run_1\"\n",
    "    assert (run2_dir / 'story.json').exists(), \"story.json not found in run_2\"\n",
    "    \n",
    "    # Check diff file exists\n",
    "    diff_file = artifacts_dir / 'diff_run_1_run_2.txt'\n",
    "    assert diff_file.exists(), \"diff_run_1_run_2.txt not found\"\n",
    "    \n",
    "    # Validate diff contains meaningful content\n",
    "    with open(diff_file) as f:\n",
    "        diff_content = f.read().lower()\n",
    "    assert 'changed' in diff_content or 'difference' in diff_content, \"Diff file doesn't contain change indicators\"\n",
    "    \n",
    "    # Check list output exists\n",
    "    list_file = artifacts_dir / 'story_list.txt'\n",
    "    assert list_file.exists(), \"story_list.txt not found\"\n",
    "    \n",
    "    # Validate list contains both runs\n",
    "    with open(list_file) as f:\n",
    "        list_content = f.read()\n",
    "    assert 'run_1' in list_content, \"run_1 not found in story list\"\n",
    "    assert 'run_2' in list_content, \"run_2 not found in story list\"\n",
    "    \n",
    "    # Check config files exist\n",
    "    assert (artifacts_dir / 'config_v1.yaml').exists(), \"config_v1.yaml not found\"\n",
    "    assert (artifacts_dir / 'config_v2.yaml').exists(), \"config_v2.yaml not found\"\n",
    "    \n",
    "    # Validate story JSON structure\n",
    "    with open(run1_dir / 'story.json') as f:\n",
    "        story1 = json.load(f)\n",
    "    assert 'run_id' in story1, \"Missing 'run_id' in story\"\n",
    "    assert 'execution' in story1, \"Missing 'execution' in story\"\n",
    "    assert 'summary' in story1, \"Missing 'summary' in story\"\n",
    "    \n",
    "    # Check runtime\n",
    "    elapsed = time.time() - start_time\n",
    "    assert elapsed < 30, f\"Runtime {elapsed:.1f}s exceeds 30s budget\"\n",
    "    \n",
    "    print(\"üéâ Walkthrough verified successfully!\")\n",
    "    print(f\"‚è±Ô∏è  Runtime: {elapsed:.2f}s\")\n",
    "    print(f\"üìÅ Artifacts created: {len(list(artifacts_dir.rglob('*')))} files\")\n",
    "    print(f\"üîß CLI used: {cli_available}\")\n",
    "    print(f\"‚úÖ All checks passed!\")\n",
    "    \n",
    "except AssertionError as e:\n",
    "    print(f\"‚ùå Walkthrough failed: {e}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Unexpected error: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Reflection\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "1. **Story Generation**: How to generate execution stories from pipeline runs using CLI or Python\n",
    "2. **Story Listing**: Discovering all available pipeline run stories in a directory\n",
    "3. **Story Diffing**: Comparing two pipeline runs to identify configuration and data changes\n",
    "4. **CLI Fallback Pattern**: Gracefully handling CLI unavailability with Python fallbacks\n",
    "\n",
    "### Where This Fits in ODIBI\n",
    "\n",
    "```\n",
    "Pipeline Development Cycle:\n",
    "Run Pipeline ‚Üí Generate Story ‚Üí List Stories ‚Üí Compare Runs ‚Üí Debug Changes\n",
    "                     ‚Üë              ‚Üë              ‚Üë\n",
    "              This notebook covered these steps!\n",
    "```\n",
    "\n",
    "Stories are **audit trails** for your pipeline executions. They help you understand what changed, why results differ, and how configurations impact data processing.\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "- **CLI + Fallback**: Always provide fallback when external commands might fail\n",
    "- **Diff-Driven Development**: Use story diffs to understand pipeline evolution\n",
    "- **Automation**: Story generation can be automated in CI/CD pipelines\n",
    "- **Debugging**: Comparing stories reveals subtle configuration bugs\n",
    "\n",
    "---\n",
    "\n",
    "## ‚è≠ Next Steps\n",
    "\n",
    "**Continue to:** [12_advanced_pipeline_composition.ipynb](12_advanced_pipeline_composition.ipynb)\n",
    "\n",
    "Learn how to compose complex pipelines with branching, merging, and conditional execution.\n",
    "\n",
    "**Deep dive:**\n",
    "- Read `odibi/cli/story.py` - CLI story command implementation\n",
    "- Read `odibi/story/generator.py` - Story generation logic\n",
    "- Read `odibi/story/diff.py` - Story diffing algorithm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
