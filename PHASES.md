# ODIBI Framework - Evolution Phases

**Version Strategy:** Semantic Versioning (SemVer)  
**Current Version:** v2.0.0  
**Last Updated:** November 20, 2025  
**Status:** âœ… Phase 5 Complete - Ecosystem Ready!

---

## ðŸ“Š Current Status

### Phase 5: Enterprise + Ecosystem
- **Status:** âœ… Complete
- **Current Version:** v2.0.0
- **Focus:** Observability, Plugins, and Community

| Phase | Status | Version | Completion |
|-------|--------|---------|------------|
| **Phase 1: Scaffolding** | âœ… Complete | v1.1.0 | Nov 2025 |
| **Phase 2: Azure + Spark** | âœ… Complete | v1.2.0 | Nov 2025 |
| **Phase 3: CLI + Stories** | âœ… Complete | v1.3.0 | Nov 2025 |
| **Phase 4: Production** | âœ… Complete | v1.4.0 | Nov 2025 |
| **Phase 6: Reference Project** | âœ… Complete | v2.0.0 | Nov 2025 |
| **Phase 9: Stress Testing** | âœ… Complete | v2.0.0 | Nov 2025 |
| **Phase 10: Documentation** | âœ… Complete | v2.0.0 | Nov 2025 |

### Quick Links
- **CI Status:** [![CI](https://github.com/henryodibi11/Odibi/workflows/CI/badge.svg)](https://github.com/henryodibi11/Odibi/actions)
- **Tests:** 416 passing
- **Coverage:** ~80%
- **Python:** 3.9, 3.10, 3.11, 3.12
- **License:** MIT

---

## Overview

ODIBI has evolved through 5 distinct phases, culminating in a production-ready, enterprise-grade data engineering framework.

**Principles:**
- **Non-breaking:** New engines and connectors are opt-in via extras
- **Tested:** All features require tests before promotion to stable
- **Documented:** New capabilities include examples and setup guides
- **Transparent:** CHANGELOG.md tracks all changes

---

## Phase 1 â€” Spark Engine + Azure Integrations (Scaffolding)

**Target Version:** v1.1.0-alpha.1 â†’ v1.1.0  
**Status:** âœ… Complete (v1.1.0-alpha.2-walkthroughs)  
**Completed:** November 2025

### Goals
- âœ… Scaffold Spark engine and Azure connections **without breaking Pandas**
- âœ… Provide structure, docs, and examples to enable contributions
- âœ… Establish open-source governance and community standards

### Deliverables

#### Code Scaffolding
- [x] **Engine:** `odibi/engine/spark_engine.py`
  - Class `SparkEngine` implementing `Engine` interface
  - Import-guarded (raises helpful error if `pyspark` not installed)
  - Methods stubbed with `NotImplementedError` and PHASES.md references
  - Basic introspection methods implemented (`get_schema`, `get_shape`, `count_rows`)

- [x] **Connections:** Azure and mock DBFS
  - `odibi/connections/azure_adls.py` - Azure Data Lake Storage Gen2 path resolver
  - `odibi/connections/azure_sql.py` - Azure SQL connection config
  - `odibi/connections/local_dbfs.py` - Mock DBFS for local testing
  - All implement `BaseConnection` interface
  - No network I/O in validation phase

#### Documentation
- [x] **Setup Guides:**
  - `docs/setup_databricks.md` - Databricks cluster setup, notebook integration
  - `docs/setup_azure.md` - Authentication options, permissions, connection templates

- [x] **Examples:**
  - `examples/example_spark.yaml` - Spark engine template with ADLS/DBFS
  - `examples/example_local.yaml` - Simplified local Pandas example

#### Open-Source Standards
- [x] **Governance:**
  - `CONTRIBUTING.md` - Contribution workflow, coding standards, testing
  - `CODE_OF_CONDUCT.md` - Contributor Covenant v2.1
  - `SECURITY.md` - Vulnerability reporting process
  - `CODEOWNERS` - Maintainer assignments
  - `CHANGELOG.md` - Version history (Keep a Changelog format)

- [x] **GitHub Templates:**
  - `.github/ISSUE_TEMPLATE/bug_report.md`
  - `.github/ISSUE_TEMPLATE/feature_request.md`
  - `.github/PULL_REQUEST_TEMPLATE.md`

- [x] **CI/CD:**
  - `.github/workflows/ci.yml` - Multi-Python version testing
  - Job: `test-base` (required) - Pandas tests on Python 3.9â€“3.12
  - Job: `test-extras` (optional) - Spark/Azure import tests
  - `.pre-commit-config.yaml` - black, ruff, trailing whitespace

#### README Updates
- [x] Add badges (build status, Python versions, license, PyPI)
- [x] Document installation with extras (`pip install "odibi[spark]"`)
- [x] Update roadmap section to reference PHASES.md
- [x] Link to CONTRIBUTING.md and CODE_OF_CONDUCT.md

#### Testing
- [x] Import tests for new modules (skip if extras not installed)
- [x] Path resolution tests for Azure connections (no network calls)
- [x] All 78 existing Pandas tests still pass

#### Walkthroughs (Phase 1F)
- [x] **6 Jupyter notebooks** covering all core features
  - `00_setup_environment.ipynb` - Setup and mental model
  - `01_local_pipeline_pandas.ipynb` - Full pipeline example with explanations
  - `02_cli_and_testing.ipynb` - Testing patterns and CLI preview
  - `03_spark_preview_stub.ipynb` - Spark architecture overview
  - `04_ci_cd_and_precommit.ipynb` - Code quality automation
  - `05_build_new_pipeline.ipynb` - Build from scratch tutorial
- [x] **Concept explanations:** Config vs Runtime, SQL-over-Pandas
- [x] **Troubleshooting sections:** Common errors with solutions
- [x] **All notebooks tested** and verified to run cell-by-cell

#### Release
- [x] Git tag: `v1.1.0-alpha.1-ci-setup` (scaffolding release)
- [x] Git tag: `v1.1.0-alpha.2-walkthroughs` (walkthroughs complete)
- [x] Update CHANGELOG.md with scaffolding notes
- [x] GitHub Release with clear "experimental" status

### Acceptance Criteria
- [x] All 78 Pandas tests pass with zero modifications
- [x] New modules raise clear errors when extras not installed
- [x] CI green on base job (Pandas); extras job can succeed
- [x] Examples and docs clearly mark Spark/Azure as experimental
- [x] No breaking changes to existing Pandas pipelines

---

## Phase 2 â€” Spark Engine + Azure ADLS (Production-Ready)

**Target Version:** v1.2.0  
**Status:** âœ… Complete  
**Completed:** November 2025

**Design Document:** [docs/PHASE2_DESIGN_DECISIONS.md](docs/PHASE2_DESIGN_DECISIONS.md)

### Goals
- Implement production-ready Spark engine (read, write, transform)
- Complete Azure ADLS integration with Key Vault authentication
- Enable multi-account storage scenarios (Databricks production use case)
- Provide seamless Databricks onboarding experience

### Deliverables

#### Spark Engine Implementation
- [ ] `SparkEngine.read()` - Parquet, CSV, Delta from ADLS/DBFS
- [ ] `SparkEngine.write()` - Parquet, CSV, Delta with modes (overwrite/append)
- [ ] `SparkEngine.execute_sql()` - SQL transforms with temp view registration
- [ ] Connection configuration at engine init (all storage accounts)
- [ ] Integration tests with local Spark session

#### Azure ADLS Authentication
- [ ] **Two auth modes:** `key_vault` (default) and `direct_key` (fallback)
- [ ] Key Vault integration using `DefaultAzureCredential` (Databricks managed identity)
- [ ] Credential caching (fetch once per connection)
- [ ] Storage options injection for Pandas (`pandas_storage_options()`)
- [ ] Spark config setup for all accounts (`configure_spark()`)
- [ ] Eager validation (fail fast on connection init)
- [ ] Production warning when using `direct_key` mode

#### Phase 2A Completion (Nov 2025) âœ…
- [x] AzureADLS connection with Key Vault + direct_key authentication
- [x] PandasEngine `_merge_storage_options()` - Inject connection credentials
- [x] PandasEngine ADLS support - All formats (CSV, Parquet, JSON, Excel, Avro)
- [x] SparkEngine read/write implementation
- [x] SparkEngine multi-account configuration
- [x] Skip `mkdir` for remote URIs (abfss://, s3://, etc.)
- [x] 21 comprehensive ADLS tests (110 total passing)
- [x] `docs/LOCAL_DEVELOPMENT.md` - Local setup guide
- [x] `docs/SUPPORTED_FORMATS.md` - Complete format reference
- [x] `examples/template_full_adls.yaml` - Multi-account example
- [x] `walkthroughs/phase2a_adls_test.ipynb` - Real ADLS validation
- [x] CI/CD integration with Azure packages

#### Phase 2B - Delta Lake âœ…
- [x] Delta Lake read/write (PandasEngine)
- [x] Delta Lake read/write (SparkEngine)
- [x] VACUUM, history, restore operations
- [x] Partitioning support with warnings
- [x] Delta-specific tests (12 comprehensive tests)

#### Phase 2C - Performance & Tools âœ… (Databricks Validated)
- [x] `setup/databricks_setup.ipynb` - Interactive Databricks + Key Vault setup
- [x] `odibi/utils/setup_helpers.py` - Programmatic setup utilities
- [x] Parallel Key Vault fetching (3x+ performance improvement)
- [x] Timeout protection (30s default) for Key Vault operations
- [x] Enhanced error handling and reporting
- [x] Comprehensive tests (15 new tests, 137 total passing)
- [x] Databricks validation (multi-account ADLS, Delta time travel, cross-account transfer)
- [x] Bug fixes: SparkEngine.execute_sql() temp view registration

### Phase 2A Acceptance Criteria âœ…
- [x] Spark engine executes read/write operations
- [x] Multi-account storage works (tested with 2 accounts)
- [x] Key Vault auth implemented (mocked + real tested)
- [x] All tests pass (110/110)
- [x] Documentation complete and validated

---

## Phase 3 â€” CLI Tools + Advanced Features (Azure-First)

**Target Version:** v1.3.0  
**Status:** âœ… Complete  
**Completed:** November 2025

### Goals
- Improve developer experience with polished CLI tools
- Enhance story/report generation for pipeline runs
- Add testing utilities and fixtures
- Complete Azure SQL connector implementation
- **Defer:** AWS S3, GCP (Phase 5 - when needed/community contributions)

### Deliverables

#### CLI Enhancement
- [x] `odibi validate <config>` - Validate YAML without execution
- [x] `odibi run <config>` - Execute pipeline from CLI
- [x] `odibi graph <config>` - Visualize dependency graph (ASCII art or export to DOT)
- [x] `odibi doctor <config>` - Lint YAML, show resolved connections, check env
- [x] Rich error messages with suggestions and context
- [x] `--log-level` flag (DEBUG, INFO, WARNING, ERROR)
- [x] `--dry-run` mode

#### Testing Utilities
- [x] `odibi.testing.fixtures` - Temporary directories, sample data generators
- [x] `odibi.testing.spark` - Mock Spark session factory (skipped if missing)
- [x] `odibi.testing.assertions` - DataFrame equality helpers (engine-agnostic)
- [x] Example datasets compatible with both Pandas and Spark

#### Story Generator Enhancements
- [x] `odibi.story` module enhancement
- [x] Capture run metadata: timestamps, node durations, success/failure
- [x] Sample data snapshots (first N rows per node)
- [x] Schema tracking (detect schema changes between nodes)
- [x] Export formats: Markdown, JSON, HTML (basic)
- [ ] **Verbosity Levels:** Control detail (Summary vs. Audit vs. Debug) (Deferred)
- [x] **Contextual Metadata:** Capture Environment, Git Commit, Odibi Version (Reproducibility)
- [x] **Config Snapshot:** Embed effective configuration in the story (Traceability)
- [ ] **Rendered Logic:** Show actual SQL/Params executed (Transparency) (Deferred)
- [ ] **Data Quality Evidence:** Show *why* data failed (e.g., "Top 5 invalid values") rather than just "Failed" (Deferred)
- [ ] **I/O Manifest:** Log exact file paths, ETags, and modification times for provenance (Deferred)
- [ ] **Visual Lineage:** Embed pipeline graph (Mermaid/ASCII) directly in the story (Deferred)
- [ ] **Resource Telemetry:** Track peak memory usage and CPU time (Efficiency Truth) (Deferred)
- [ ] **Reproduction Token:** Exact CLI command to reproduce this specific run (Deferred)

#### Azure Connector Completion
- [x] `connections/azure_sql.py` - Implement read/write via SQLAlchemy + ODBC
- [x] Azure-specific error handling improvements
- [ ] Azure connection examples and best practices
- [x] Connection factory: YAML `type` field â†’ class instantiation

#### Cloud Connectors (Deferred to Phase 5 Plugins)
- [ ] `connections/s3.py` - AWS S3 (deferred - use plugin)
- [ ] `connections/gcs.py` - Google Cloud Storage (deferred - use plugin)
- **Rationale:** Focus on Azure (production platform). Add S3/GCS via community plugins.

#### Examples
- [x] `examples/spark_sql_pipeline/` - End-to-end Spark SQL transformation
- [x] `examples/azure_etl/` - ADLS read â†’ transform â†’ Azure SQL write
- [x] `examples/story_demo/` - Pipeline showcasing story generation
- [x] `examples/medallion_architecture/` - Complete Bronze/Silver/Gold example

### Acceptance Criteria
- [x] CLI tools functional and documented
- [x] Stories generated with useful metadata
- [x] Testing utilities available for users
- [x] Azure SQL connector implemented with tests
- [x] ~25 new tests for CLI, stories, and Azure SQL
- [x] Zero breaking changes to Phase 2 features

---

## Phase 4 â€” Performance + Production Hardening

**Target Version:** v1.4.0  
**Status:** âœ… Complete  
**Completed:** November 2025

### Goals
- Stabilize API contracts and error semantics
- Optimize performance for production workloads (Chunking, Parallelism)
- Add retry logic, idempotency, and checkpointing
- Enable enterprise features (PII redaction, Alerting, Env vars)

### Deliverables

#### Infrastructure (Pre-requisite)
- [x] **Spark CI Hardening:** Ensure GitHub Actions runs Spark tests (install Java/Hadoop)
- [x] **Local Spark Setup:** Scripts/Docs for local Spark testing
  - Windows (Interactive): `examples/run_local_spark.bat`
  - WSL (Recommended): `docs/WSL_GUIDE.md`

#### Performance
- [x] Engine benchmarks (Pandas vs Spark for common operations)
- [x] Lazy evaluation strategies where applicable (Delta Lake implementation)
- [x] Parallel node execution (ThreadPoolExecutor)
- [x] **Memory Safety:** Automatic chunking for Pandas engine
- [x] Benchmark suite in `tests/benchmarks/`
- [x] Performance guide (`docs/performance.md`)

#### Reliability
- [x] Retry/backoff for connection failures (configurable)
- [x] Idempotent write modes (append-once, upsert patterns)
- [x] **Checkpointing:** `--resume-from-failure` support
- [x] Schema validation improvements (consistent across engines)
- [x] Structured logging (JSON output option)
- [x] Log level controls per node

#### Security & Operations
- [x] **PII Redaction:** `sensitive: true` masking in stories/logs
- [x] **Alerting Hooks:** `on_failure` webhooks (Slack/Teams)
- [x] **Config Templating:** Environment variable substitution (`${VAR}`)
- [x] **Artifact Retention:** Auto-cleanup of old stories
- [x] Standardized error types across engines
- [x] Error context preservation through stack
- [x] Detailed error messages with actionable suggestions
- [x] Error recovery strategies (skip, retry, fail-fast)

#### Documentation
- [x] Production deployment guide (`docs/production.md`)
- [x] Monitoring and observability guide
- [x] Performance tuning recommendations

### Acceptance Criteria
- [x] Benchmarks published and documented
- [x] Retry logic tested with simulated failures
- [x] Error messages consistently helpful across engines
- [x] Zero regressions in test suite

---

## Phase 5 â€” Enterprise + Ecosystem

**Target Version:** v2.0.0  
**Status:** âœ… Complete  
**Completed:** November 2025

**Detailed Roadmap:** [docs/_archive/PHASE5_ROADMAP_COMPLETED.md](docs/_archive/PHASE5_ROADMAP_COMPLETED.md)

### Goals
- **Enterprise Scale:** Observability (OTel), Concurrency Safety (Locking), Secret Management.
- **Ecosystem:** Plugin system, Extensions.
- **Community:** Documentation site, Governance.

### Deliverables

#### 5A: Operational Safety
- [x] **Process Locking:** Prevent state corruption during concurrent runs (`portalocker`).
- [x] **Secret Redaction:** Auto-mask keys/passwords in all logs.
- [x] **Secret Tools:** CLI commands to manage local environment secrets.

#### 5B: Observability (OpenTelemetry)
- [x] **Instrumentation:** Traces and Metrics for Pipeline/Node execution.
- [x] **Standard Integration:** Support OTLP exporters (Azure Monitor, Datadog, etc.).

#### 5C: Ecosystem
- [x] **Documentation Site:** MkDocs with API reference.
- [x] **Plugin System:** Entry-points for 3rd party engines/connectors.
- [x] **Community Connectors:** Postgres (via plugins), S3/GCP (deferred).

### Acceptance Criteria
- [x] Parallel runs do not corrupt state file.
- [x] Secrets never appear in logs, even on error.
- [x] Metrics flow to a local OTel collector (verified via Docker).
- [x] Documentation site is live.

---

## Phase 6 â€” Reference Project (OdibiFlix)

**Target Version:** v2.0.0  
**Status:** âœ… Complete  
**Completed:** November 2025

### Goals
- Prove capability with large-scale simulation
- Implement Medallion Architecture (Bronze/Silver/Gold)
- Deliver 10 reference implementations ("The Gauntlet")

### Deliverables
- [x] `examples/reference_project/` structure
- [x] Synthetic data generation scripts
- [x] Identity Resolution logic
- [x] SCD Type 2 implementation

---

## Phase 9 â€” Infinite Gauntlet (Automated Stress Testing)

**Target Version:** v2.0.0  
**Status:** âœ… Complete  
**Completed:** November 2025

### Goals
- Automated fuzz testing against Kaggle/HuggingFace datasets
- Project Scaffolding generator

### Deliverables
- [x] `odibi generate-project` command
- [x] `odibi stress` command
- [x] Integration with Kaggle API for test data
- [x] Hardened Pandas engine against dirty CSVs

---

## Phase 10 â€” Documentation & Education

**Target Version:** v2.0.0  
**Status:** âœ… Complete  
**Completed:** November 2025

### Goals
- DiÃ¡taxis Documentation Overhaul
- Create "Master CLI Guide" and "Cheatsheet"
- Sales-ready README and Getting Started flow

### Deliverables
- [x] `docs/tutorials/` (Getting Started)
- [x] `docs/guides/` (CLI, Production, Custom Transforms)
- [x] `docs/reference/` (Cheatsheet, Configuration)
- [x] `docs/explanation/` (Architecture, Case Studies)
- [x] `examples/templates/security_pii.yaml` (Privacy showcase)

---

## Version History

| Version | Status | Description | Date |
|---------|--------|-------------|------|
| v1.0.0 | âœ… Released | Pandas MVP - Core framework complete | 2025-11-05 |
| v1.1.0 | âœ… Released | Phase 1 stable + Phase 2 CLI tools | 2025-11-15 |
| v1.2.0 | âœ… Released | Phase 2 stable - Spark + ADLS | 2025-11-18 |
| v1.3.0 | âœ… Released | Phase 3 - Stories + Connectors | 2025-11-19 |
| v1.4.0 | âœ… Released | Phase 4 - Performance + Production | 2025-11-20 |
| v2.0.0 | âœ… Released | Phase 5 - Community + Ecosystem | 2025-11-20 |

---

## Contributing to Future Releases

See [CONTRIBUTING.md](CONTRIBUTING.md) for how to get involved.

**Current Focus:** Maintenance & Community Plugins
**Next Up:** Gathering feedback for v2.1 feature set

---

**Last Updated:** 2025-11-20  
**Maintainer:** @henryodibi11
