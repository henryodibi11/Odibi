{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Standard Library Deep Dive\n",
    "## Python's batteries-included toolkit\n",
    "\n",
    "Python comes with a huge set of built-in modules called the **standard library**. \n",
    "You do not need to install them -- they are already there when you install Python.\n",
    "\n",
    "Odibi uses over a dozen standard library modules. This notebook covers every one of them, \n",
    "with real Odibi examples so you understand why each module matters.\n",
    "\n",
    "### What does `import` mean?\n",
    "\n",
    "When you write `import os`, you are telling Python: \"Load the `os` module so I can use it.\" \n",
    "A **module** is just a file full of pre-written functions and classes.\n",
    "\n",
    "There are two ways to import:\n",
    "```python\n",
    "import os                    # Import the whole module, use as os.path.join()\n",
    "from pathlib import Path     # Import just one thing, use as Path()\n",
    "```\n",
    "\n",
    "Both are fine. Use whichever you see in the existing code. Odibi uses both styles.\n",
    "\n",
    "**Rules:** Same as before. Type everything. Run everything. Complete every exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: os and pathlib -- Working with Files and Paths\n",
    "\n",
    "These modules let you interact with the file system: build file paths, check if files exist, \n",
    "list directories, read environment variables.\n",
    "\n",
    "Odibi uses these in 15+ files. Every connection, every config loader, every read/write \n",
    "operation touches file paths.\n",
    "\n",
    "### pathlib.Path -- the modern way\n",
    "\n",
    "`pathlib` was added in Python 3.4 and is the preferred way to work with paths. \n",
    "It represents a path as an **object** instead of a plain string, which means you get \n",
    "methods and operators that make path manipulation cleaner.\n",
    "\n",
    "Odibi uses `from pathlib import Path` in almost every module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\bronze\\customers.csv\n",
      "<class 'pathlib.WindowsPath'>\n",
      "Name: customers.csv\n",
      "Stem: customers\n",
      "Suffix: .csv\n",
      "Parent: data\\bronze\n",
      "Parts: ('data', 'bronze', 'customers.csv')\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Creating paths\n",
    "p = Path(\"data/bronze/customers.csv\")\n",
    "print(p)\n",
    "print(type(p))\n",
    "\n",
    "# Path parts\n",
    "print(f\"Name: {p.name}\")         # customers.csv\n",
    "print(f\"Stem: {p.stem}\")         # customers (name without extension)\n",
    "print(f\"Suffix: {p.suffix}\")     # .csv\n",
    "print(f\"Parent: {p.parent}\")     # data/bronze\n",
    "print(f\"Parts: {p.parts}\")       # (\"data\", \"bronze\", \"customers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\employees.csv\n",
      "data\\employees.parquet\n",
      "False\n",
      "True\n",
      "c:\\Users\\hodibi\\OneDrive - Ingredion\\Desktop\\Repos\\Odibi\\learning\\notebooks\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Building paths with / operator (this is the Pythonic way)\n",
    "base = Path(\"data\")\n",
    "full_path = base / \"bronze\" / \"customers.csv\"\n",
    "print(full_path)  # data/bronze/customers.csv\n",
    "\n",
    "# This is exactly how odibi/connections/local.py builds paths:\n",
    "# self.base_path / relative_path\n",
    "\n",
    "# Change extension\n",
    "parquet_path = full_path.with_suffix(\".parquet\")\n",
    "print(parquet_path)  # data/bronze/customers.parquet\n",
    "\n",
    "# Check existence\n",
    "print(full_path.exists())  # False (we haven't created it)\n",
    "print(Path(\".\").exists())  # True (current directory always exists)\n",
    "\n",
    "# Current working directory\n",
    "print(Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [FILE] 01_python_basics.ipynb\n",
      "  [FILE] 02_data_structures.ipynb\n",
      "  [FILE] 03_standard_library.ipynb\n",
      "  [FILE] 04_oop.ipynb\n",
      "  [FILE] 05_advanced_patterns.ipynb\n",
      "  [FILE] 06_pydantic.ipynb\n",
      "  [FILE] 07_pandas.ipynb\n",
      "  [FILE] 08_mini_odibi_core.ipynb\n",
      "  [FILE] 09_mini_odibi_features.ipynb\n",
      "  [FILE] 10_testing.ipynb\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Listing files in a directory\n",
    "odibi_dir = Path(\".\")  # Current directory\n",
    "\n",
    "# List all items\n",
    "for item in sorted(odibi_dir.iterdir()):\n",
    "    if not str(item).startswith(\".\"):  # Skip hidden files\n",
    "        kind = \"DIR\" if item.is_dir() else \"FILE\"\n",
    "        print(f\"  [{kind}] {item.name}\")\n",
    "        if item.is_dir():\n",
    "            break  # Just show first few to avoid clutter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python files in current dir: 0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# glob - find files matching a pattern\n",
    "# This is how odibi/engine/pandas_engine.py finds data files\n",
    "p = Path(\".\")\n",
    "\n",
    "# Find all Python files in current directory\n",
    "py_files = list(p.glob(\"*.py\"))\n",
    "print(f\"Python files in current dir: {len(py_files)}\")\n",
    "for f in sorted(py_files)[:5]:  # Show first 5\n",
    "    print(f\"  {f.name}\")\n",
    "\n",
    "# Recursive glob with ** (find in all subdirectories)\n",
    "yaml_files = list(p.glob(\"**/*.yaml\"))  # All YAML files anywhere below\n",
    "print(yaml_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os module -- environment variables and system operations\n",
    "\n",
    "While `pathlib` handles paths, `os` is still used for:\n",
    "- Reading environment variables (`os.environ`, `os.getenv()`)\n",
    "- Creating directories (`os.makedirs()`)\n",
    "- Checking if paths exist (`os.path.exists()` -- though `Path.exists()` is preferred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home: C:\\Users\\hodibi\n",
      "Environment: development\n",
      "PATH exists: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Environment variables\n",
    "# These are key-value pairs set in your operating system\n",
    "# Odibi uses them for connection secrets, API keys, etc.\n",
    "\n",
    "# Get an env var (returns None if not set)\n",
    "home = os.getenv(\"USERPROFILE\")  # Windows home directory\n",
    "print(f\"Home: {home}\")\n",
    "\n",
    "# Get with a default\n",
    "env = os.getenv(\"ODIBI_ENV\", \"development\")\n",
    "print(f\"Environment: {env}\")  # \"development\" (since ODIBI_ENV is not set)\n",
    "\n",
    "# Check if env var exists\n",
    "has_key = \"PATH\" in os.environ\n",
    "print(f\"PATH exists: {has_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Creating directories\n",
    "# os.makedirs creates the directory AND all parent directories\n",
    "# exist_ok=True means it won't crash if it already exists\n",
    "\n",
    "test_dir = Path(\"learning//mini_odibi/temp_test\")\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "print(f\"Created: {test_dir.exists()}\")  # True\n",
    "\n",
    "# Clean up\n",
    "test_dir.rmdir()  # Remove empty directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1: File path builder\n",
    "\n",
    "Write a function called `build_output_path` that:\n",
    "- Takes: `base_dir` (str), `layer` (str), `table_name` (str), `format` (str, default \"parquet\")\n",
    "- Returns a Path object like: `base_dir/layer/table_name.format`\n",
    "- Example: `build_output_path(\"data\", \"bronze\", \"customers\")` -> `Path(\"data/bronze/customers.parquet\")`\n",
    "\n",
    "Then use the function and print the resulting path's name, stem, suffix, and parent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full path: data\\bronze\\customers.parquet\n",
      "Name: customers.parquet\n",
      "Stem: customers\n",
      "Suffix: .parquet\n",
      "Parent: data\\bronze\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1.1\n",
    "# YOUR CODE HERE\n",
    "from pathlib import Path\n",
    "\n",
    "def build_output_path(base_dir:str, layer:str, table_name:str, format:str = 'parquet'):\n",
    "    path = Path(f'{base_dir}/{layer}/{table_name}.{format}')\n",
    "    return path\n",
    "\n",
    "\n",
    "\n",
    "# Test:\n",
    "p = build_output_path(\"data\", \"bronze\", \"customers\")\n",
    "print(f\"Full path: {p}\")\n",
    "print(f\"Name: {p.name}\")\n",
    "print(f\"Stem: {p.stem}\")\n",
    "print(f\"Suffix: {p.suffix}\")\n",
    "print(f\"Parent: {p.parent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "Full path: data/bronze/customers.parquet\n",
    "Name: customers.parquet\n",
    "Stem: customers\n",
    "Suffix: .parquet\n",
    "Parent: data/bronze\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: json -- Reading and Writing Structured Data\n",
    "\n",
    "JSON (JavaScript Object Notation) is a text format for storing structured data. \n",
    "It looks almost identical to Python dictionaries and lists.\n",
    "\n",
    "Odibi uses JSON for catalog metadata, diagnostics output, schema exports, and lineage data.\n",
    "\n",
    "The `json` module converts between Python objects and JSON strings:\n",
    "- `json.dumps(obj)` -- Python object -> JSON string (\"dump string\")\n",
    "- `json.loads(text)` -- JSON string -> Python object (\"load string\")\n",
    "- `json.dump(obj, file)` -- Python object -> JSON file\n",
    "- `json.load(file)` -- JSON file -> Python object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compact: {\"name\": \"customers\", \"format\": \"delta\", \"row_count\": 1542, \"columns\": [\"id\", \"name\", \"email\"], \"active\": true, \"last_error\": null}\n",
      "\n",
      "Pretty:\n",
      "{\n",
      "  \"name\": \"customers\",\n",
      "  \"format\": \"delta\",\n",
      "  \"row_count\": 1542,\n",
      "  \"columns\": [\n",
      "    \"id\",\n",
      "    \"name\",\n",
      "    \"email\"\n",
      "  ],\n",
      "  \"active\": true,\n",
      "  \"last_error\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Python dict to JSON string\n",
    "node_config = {\n",
    "    \"name\": \"customers\",\n",
    "    \"format\": \"delta\",\n",
    "    \"row_count\": 1542,\n",
    "    \"columns\": [\"id\", \"name\", \"email\"],\n",
    "    \"active\": True,\n",
    "    \"last_error\": None,\n",
    "}\n",
    "\n",
    "# Convert to JSON string\n",
    "json_str = json.dumps(node_config)\n",
    "print(f\"Compact: {json_str}\")\n",
    "\n",
    "# Pretty-printed (indent=2 is standard)\n",
    "pretty = json.dumps(node_config, indent=2)\n",
    "print(f\"\\nPretty:\\n{pretty}\")\n",
    "\n",
    "# Notice: True became true, None became null\n",
    "# JSON has different names for these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "orders\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# JSON string to Python dict\n",
    "json_text = '{\"name\": \"orders\", \"format\": \"csv\", \"row_count\": 8930, \"active\": true}'\n",
    "\n",
    "config = json.loads(json_text)\n",
    "print(type(config))  # dict\n",
    "print(config['name'])  # orders\n",
    "print(config['active'])  # True (json true becomes Python True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote to learning\\mini_odibi\\test_config.json\n",
      "Loaded: {'name': 'customers', 'format': 'delta', 'row_count': 1542}\n",
      "Name: customers\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Write JSON to a file\n",
    "node_config = {\n",
    "    \"name\": \"customers\",\n",
    "    \"format\": \"delta\",\n",
    "    \"row_count\": 1542,\n",
    "}\n",
    "\n",
    "output_path = Path(\"learning/mini_odibi/test_config.json\")\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "output_path.parent\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(node_config, f, indent=2)\n",
    "print(f\"Wrote to {output_path}\")\n",
    "\n",
    "# Read JSON from a file\n",
    "with open(output_path, \"r\") as f:\n",
    "    loaded = json.load(f)\n",
    "print(f\"Loaded: {loaded}\")\n",
    "print(f\"Name: {loaded['name']}\")\n",
    "\n",
    "# Clean up\n",
    "output_path.unlink()  # Delete the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `with` statement (context managers)\n",
    "\n",
    "You just saw `with open(path, \"w\") as f:`. This is called a **context manager**.\n",
    "\n",
    "When you open a file, you need to close it when you are done. The `with` statement \n",
    "does this automatically -- even if your code crashes:\n",
    "\n",
    "```python\n",
    "# Bad: If an error happens, the file stays open\n",
    "f = open(\"file.txt\", \"r\")\n",
    "data = f.read()      # What if this crashes?\n",
    "f.close()             # This might never run!\n",
    "\n",
    "# Good: File is ALWAYS closed when the block ends\n",
    "with open(\"file.txt\", \"r\") as f:\n",
    "    data = f.read()  # Even if this crashes, file gets closed\n",
    "```\n",
    "\n",
    "Always use `with` when working with files. This is a guaranteed interview topic.\n",
    "\n",
    "Odibi's `PhaseTimer` in `node.py` uses the same `with` pattern for timing execution phases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1: Config file handler\n",
    "\n",
    "Write two functions:\n",
    "1. `save_config(config, filepath)` -- saves a dict as pretty-printed JSON to a file\n",
    "2. `load_config(filepath)` -- loads a JSON file and returns a dict\n",
    "\n",
    "Both should use `with` statements. Test them by saving a config and loading it back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote to learning\\mini_odibi\\test_config.json\n",
      "{'name': 'test_node', 'format': 'csv', 'rows': 100}\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2.1\n",
    "# YOUR CODE HERE\n",
    "import json\n",
    "from pathlib import Path\n",
    "def save_config(config:dict, filepath:str):\n",
    "    with open(filepath,'w') as f:\n",
    "        json.dump(config,f, indent=4)\n",
    "        print(f\"Wrote to {output_path}\")\n",
    "\n",
    "def load_config(filepath:str):\n",
    "    with open(filepath, 'r') as f:\n",
    "        json_str = json.load(f)\n",
    "    return json_str\n",
    "\n",
    "# Test:\n",
    "test_config = {\"name\": \"test_node\", \"format\": \"csv\", \"rows\": 100}\n",
    "save_config(test_config, \"learning/mini_odibi/test_output.json\")\n",
    "loaded = load_config(\"learning/mini_odibi/test_output.json\")\n",
    "print(loaded)\n",
    "print(loaded == test_config)  # Should be True\n",
    "Path(\"learning/mini_odibi/test_output.json\").unlink()  # Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ea79ab",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: re -- Regular Expressions (Pattern Matching)\n",
    "\n",
    "Regular expressions (regex) let you search for **patterns** in text, not just exact matches.\n",
    "\n",
    "Examples of what regex can do:\n",
    "- Find all dates in a string (pattern: `\\d{4}-\\d{2}-\\d{2}`)\n",
    "- Check if a string looks like an email\n",
    "- Extract numbers from mixed text\n",
    "- Replace patterns in text\n",
    "\n",
    "Odibi uses `re` in `context.py`, `config_loader.py`, `introspect.py`, and `node.py` \n",
    "for things like parsing SQL, substituting date variables, and extracting error messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found number: 1542\n",
      "All numbers: ['1542', '3.45']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# re.search() - find the FIRST match\n",
    "text = \"Node customers processed 1542 rows in 3.45 seconds\"\n",
    "\n",
    "# Find a number\n",
    "match = re.search(r\"\\d+\", text)  # \\d+ means \"one or more digits\"\n",
    "if match:\n",
    "    print(f\"Found number: {match.group()}\")  # 1542\n",
    "\n",
    "# re.findall() - find ALL matches\n",
    "numbers = re.findall(r\"[\\d.]+\", text)  # Digits and dots\n",
    "print(f\"All numbers: {numbers}\")  # [\"1542\", \"3.45\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common regex patterns\n",
    "\n",
    "| Pattern | Meaning | Example |\n",
    "|---------|---------|--------|\n",
    "| `\\d` | Any digit (0-9) | `\\d+` matches `1542` |\n",
    "| `\\w` | Any word character (letter, digit, underscore) | `\\w+` matches `customers` |\n",
    "| `\\s` | Any whitespace | `\\s+` matches spaces, tabs |\n",
    "| `.` | Any character | `.+` matches anything |\n",
    "| `*` | Zero or more of previous | `\\d*` matches `\"\"` or `123` |\n",
    "| `+` | One or more of previous | `\\d+` matches `123` but not `\"\"` |\n",
    "| `?` | Zero or one of previous | `\\d?` matches `\"\"` or `1` |\n",
    "| `{n}` | Exactly n of previous | `\\d{4}` matches `2024` |\n",
    "| `^` | Start of string | `^Node` matches `\"Node...\"` |\n",
    "| `$` | End of string | `.csv$` matches `\"file.csv\"` |\n",
    "| `()` | Capture group | `(\\d+)` captures the number |\n",
    "\n",
    "The `r` before the string (`r\"\\d+\"`) means \"raw string\" -- it tells Python not to \n",
    "interpret backslashes. Always use raw strings for regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: data/bronze/sales_2024_01.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# re.sub() - replace patterns\n",
    "# This is how odibi/utils/config_loader.py substitutes date variables\n",
    "config_text = \"source: data/bronze/sales_{YYYY}_{MM}.csv\"\n",
    "\n",
    "# Replace date placeholders\n",
    "result = re.sub(r\"\\{YYYY\\}\", \"2024\", config_text)\n",
    "result = re.sub(r\"\\{MM\\}\", \"01\", result)\n",
    "print(result)  # source: data/bronze/sales_2024_01.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2024-01-15 14:30:00\n",
      "Level: ERROR\n",
      "Node: customers\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Capture groups with ()\n",
    "log_line = \"[2024-01-15 14:30:00] ERROR Node: customers - Column not found\"\n",
    "\n",
    "# Extract the date, level, and node name\n",
    "pattern = r\"\\[(.*?)\\]\\s+(\\w+)\\s+Node:\\s+(\\w+)\"\n",
    "match = re.search(pattern, log_line)\n",
    "if match:\n",
    "    print(f\"Date: {match.group(1)}\")   # 2024-01-15 14:30:00\n",
    "    print(f\"Level: {match.group(2)}\")  # ERROR\n",
    "    print(f\"Node: {match.group(3)}\")   # customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Parse a table path\n",
    "\n",
    "Write a function that uses regex to parse table paths in the format:\n",
    "`schema.table` or `catalog.schema.table`\n",
    "\n",
    "Return a dict with keys: `catalog` (or None), `schema`, `table`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "85e95975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bronze', 'customers']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"bronze.customers\"\n",
    "pattern = r'(\\w+)+'\n",
    "match = re.findall(pattern,\"bronze.customers\")\n",
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'catalog': None, 'schema': 'bronze', 'table': 'customers'}\n",
      "{'catalog': 'main', 'schema': 'bronze', 'table': 'customers'}\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.1\n",
    "# YOUR CODE HERE\n",
    "import re\n",
    "\n",
    "def parse_table_path(table_path:str):\n",
    "    pattern = r'(\\w+)+'\n",
    "    match = re.findall(pattern,table_path)\n",
    "    table_dict = dict()\n",
    "    if len(match) == 2:\n",
    "        table_dict['catalog'] = None\n",
    "        table_dict['schema'] = match[0]\n",
    "        table_dict['table'] = match[1]\n",
    "    else:\n",
    "        table_dict['catalog'] = match[0]\n",
    "        table_dict['schema'] = match[1]\n",
    "        table_dict['table'] = match[2]\n",
    "    return table_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Test:\n",
    "print(parse_table_path(\"bronze.customers\"))         # {\"catalog\": None, \"schema\": \"bronze\", \"table\": \"customers\"}\n",
    "print(parse_table_path(\"main.bronze.customers\"))    # {\"catalog\": \"main\", \"schema\": \"bronze\", \"table\": \"customers\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: logging -- Professional Output\n",
    "\n",
    "In Phase 1, you used `print()` for output. In real code, you use `logging`. Here is why:\n",
    "\n",
    "- **Levels**: DEBUG, INFO, WARNING, ERROR, CRITICAL -- you can filter what you see\n",
    "- **Format**: Timestamps, module names, line numbers -- automatically\n",
    "- **Destinations**: Console, files, remote services -- configurable\n",
    "- **Production**: You can turn off debug messages without changing code\n",
    "\n",
    "Odibi has its own logging system built on top of Python's `logging` module \n",
    "(`odibi/utils/logging.py` and `odibi/utils/logging_context.py`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:34:25 [DEBUG] Detailed info for debugging\n",
      "10:34:25 [INFO] Normal operation info\n",
      "10:34:25 [WARNING] Something unexpected\n",
      "10:34:25 [ERROR] Something went wrong\n",
      "10:34:25 [CRITICAL] System is broken\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# Basic setup\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,  # Show all messages DEBUG and above\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\",\n",
    ")\n",
    "\n",
    "# Create a logger for this module\n",
    "logger = logging.getLogger(\"mini_odibi\")\n",
    "\n",
    "# Five levels (from least to most severe)\n",
    "logger.debug(\"Detailed info for debugging\")    # Usually hidden in production\n",
    "logger.info(\"Normal operation info\")            # Standard messages\n",
    "logger.warning(\"Something unexpected\")          # Not an error, but worth noting\n",
    "logger.error(\"Something went wrong\")            # An error occurred\n",
    "logger.critical(\"System is broken\")             # Fatal error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:34:52 [INFO] Processing node: customers\n",
      "10:34:52 [INFO] Read 1,542 rows in 3.45s\n",
      "10:34:52 [WARNING] Node customers has no validation tests\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# Using logger with f-strings (the way Odibi does it)\n",
    "logger = logging.getLogger(\"mini_odibi\")\n",
    "\n",
    "node_name = \"customers\"\n",
    "row_count = 1542\n",
    "duration = 3.45\n",
    "\n",
    "logger.info(f\"Processing node: {node_name}\")\n",
    "logger.info(f\"Read {row_count:,} rows in {duration:.2f}s\")\n",
    "logger.warning(f\"Node {node_name} has no validation tests\")\n",
    "\n",
    "# In Odibi, you would see:\n",
    "# ctx = get_logging_context()\n",
    "# ctx.info(\"Processing node\", node_name=node_name, rows=row_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: datetime -- Working with Dates and Times\n",
    "\n",
    "Data engineering is obsessed with dates: when was data loaded? When does it expire? \n",
    "What is the processing window? Every Odibi pattern uses timestamps.\n",
    "\n",
    "Python's `datetime` module handles all of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now: 2026-02-09 11:10:58.766892\n",
      "Date only: 2026-02-09\n",
      "Time only: 11:10:58.766892\n",
      "Year: 2026, Month: 2, Day: 9\n",
      "Formatted: 2026-02-09 11:10:58\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "# Current date and time\n",
    "now = datetime.now()\n",
    "print(f\"Now: {now}\")\n",
    "print(f\"Date only: {now.date()}\")\n",
    "print(f\"Time only: {now.time()}\")\n",
    "print(f\"Year: {now.year}, Month: {now.month}, Day: {now.day}\")\n",
    "\n",
    "# Format as string (strftime = \"string format time\")\n",
    "formatted = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f\"Formatted: {formatted}\")\n",
    "\n",
    "# Common format codes:\n",
    "# %Y = 4-digit year (2024)\n",
    "# %m = 2-digit month (01-12)\n",
    "# %d = 2-digit day (01-31)\n",
    "# %H = 24-hour hour (00-23)\n",
    "# %M = minute (00-59)\n",
    "# %S = second (00-59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed: 2024-01-15 14:30:00\n",
      "Year: 2024\n",
      "One week ago: 2026-02-02\n",
      "Tomorrow: 2026-02-10\n",
      "Difference: 74 days\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Parse a string into a datetime (strptime = \"string parse time\")\n",
    "date_str = \"2024-01-15 14:30:00\"\n",
    "dt = datetime.strptime(date_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "print(f\"Parsed: {dt}\")\n",
    "print(f\"Year: {dt.year}\")\n",
    "\n",
    "# timedelta - represent a duration\n",
    "# Odibi uses timedelta for retention periods, SCD2 expiry, etc.\n",
    "now = datetime.now()\n",
    "one_week_ago = now - timedelta(days=7)\n",
    "tomorrow = now + timedelta(days=1)\n",
    "\n",
    "print(f\"One week ago: {one_week_ago.strftime('%Y-%m-%d')}\")\n",
    "print(f\"Tomorrow: {tomorrow.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# Duration between two dates\n",
    "start = datetime(2024, 1, 1)\n",
    "end = datetime(2024, 3, 15)\n",
    "diff = end - start\n",
    "print(f\"Difference: {diff.days} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.1: Timestamp logger\n",
    "\n",
    "Write a function `log_with_timestamp(message)` that:\n",
    "1. Gets the current time\n",
    "2. Formats it as `YYYY-MM-DD HH:MM:SS`\n",
    "3. Prints `[timestamp] message`\n",
    "\n",
    "Then write a function `calculate_duration(start, end)` that:\n",
    "1. Takes two datetime objects\n",
    "2. Returns the duration as a formatted string like `\"2h 15m 30s\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-02-09 11:19:17] Pipeline started\n",
      "[2026-02-09 11:19:17] Node customers completed\n",
      "2:15:30\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5.1\n",
    "# YOUR CODE HERE\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def log_with_timestamp(message:str):\n",
    "    now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f'[{now}] {message}')\n",
    "\n",
    "\n",
    "# Test log_with_timestamp:\n",
    "log_with_timestamp(\"Pipeline started\")\n",
    "log_with_timestamp(\"Node customers completed\")\n",
    "\n",
    "def calculate_duration(start: datetime, end: datetime):\n",
    "    delta = end - start\n",
    "    return delta\n",
    "\n",
    "# Test calculate_duration:\n",
    "start = datetime(2024, 1, 15, 14, 30, 0)\n",
    "end = datetime(2024, 1, 15, 16, 45, 30)\n",
    "print(calculate_duration(start, end))  # 2h 15m 30s\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: hashlib and uuid -- Hashing and Unique IDs\n",
    "\n",
    "### hashlib -- Creating fingerprints of data\n",
    "\n",
    "A **hash** is a fixed-length fingerprint of any data. The same input always produces \n",
    "the same hash. Different inputs (almost always) produce different hashes.\n",
    "\n",
    "Odibi uses hashing in `catalog.py`, `node.py`, and `pandas_engine.py` to:\n",
    "- Detect if data has changed (content hashing)\n",
    "- Create unique row identifiers\n",
    "- Track which version of data was processed\n",
    "\n",
    "### uuid -- Generating unique identifiers\n",
    "\n",
    "A **UUID** (Universally Unique Identifier) is a random 128-bit ID. The odds of generating \n",
    "the same UUID twice are essentially zero.\n",
    "\n",
    "Odibi uses UUIDs in `pipeline.py` and `lineage.py` to give each pipeline run a unique ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "28aefaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'customers|1542|2024-01-15'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MD5 hash: dcfcc194c1be1d330f7142cbd5719b29\n",
      "Same? True\n",
      "SHA256: d1ae72bc40effee1d1ab8a1c432f71e41b0422ef95a88d93e661df20d6e0a60c\n",
      "Run ID: fbd4d480-d359-4da5-94bb-4cee344464ff\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import uuid\n",
    "\n",
    "# hashlib - create a hash of data\n",
    "data = \"customers|1542|2024-01-15\"\n",
    "hash_value = hashlib.md5(data.encode()).hexdigest()\n",
    "print(f\"MD5 hash: {hash_value}\")\n",
    "\n",
    "# Same input = same hash (always)\n",
    "hash_again = hashlib.md5(data.encode()).hexdigest()\n",
    "print(f\"Same? {hash_value == hash_again}\")  # True\n",
    "\n",
    "# SHA256 (more secure, used in Odibi)\n",
    "sha_hash = hashlib.sha256(data.encode()).hexdigest()\n",
    "print(f\"SHA256: {sha_hash}\")\n",
    "\n",
    "# uuid - generate unique run IDs\n",
    "run_id = str(uuid.uuid4())\n",
    "print(f\"Run ID: {run_id}\")\n",
    "# Something like: a38f981d-52da-47b1-818c-fbaa9ab56e0c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: collections -- Specialized Data Structures\n",
    "\n",
    "The `collections` module provides enhanced versions of dicts, lists, and tuples.\n",
    "\n",
    "Odibi's `graph.py` uses `defaultdict` and `deque` for dependency graph traversal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual: {'bronze': ['customers', 'orders'], 'silver': ['customers', 'orders']}\n",
      "defaultdict: {'bronze': ['customers', 'orders'], 'silver': ['customers', 'orders']}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter, deque\n",
    "\n",
    "# defaultdict - a dict that creates default values automatically\n",
    "# Remember the grouping exercise from Phase 2? defaultdict makes it easier.\n",
    "\n",
    "# Without defaultdict (what you did in Phase 2):\n",
    "grouped = {}\n",
    "items = [(\"bronze\", \"customers\"), (\"silver\", \"customers\"), (\"bronze\", \"orders\"), (\"silver\", \"orders\")]\n",
    "for layer, table in items:\n",
    "    if layer not in grouped:\n",
    "        grouped[layer] = []\n",
    "    grouped[layer].append(table)\n",
    "print(f\"Manual: {grouped}\")\n",
    "\n",
    "# With defaultdict (much cleaner):\n",
    "grouped = defaultdict(list)  # Missing keys automatically get an empty list\n",
    "for layer, table in items:\n",
    "    grouped[layer].append(table)  # No need to check if key exists!\n",
    "print(f\"defaultdict: {dict(grouped)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'SUCCESS': 4, 'FAILED': 2})\n",
      "4\n",
      "[('SUCCESS', 4)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Counter - count occurrences (the drill from Phase 2, done in one line)\n",
    "statuses = [\"SUCCESS\", \"SUCCESS\", \"FAILED\", \"SUCCESS\", \"FAILED\", \"SUCCESS\"]\n",
    "counts = Counter(statuses)\n",
    "print(counts)                # Counter({'SUCCESS': 4, 'FAILED': 2})\n",
    "print(counts[\"SUCCESS\"])     # 4\n",
    "print(counts.most_common(1)) # [('SUCCESS', 4)] - most common item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queue: ['setup', 'customers', 'orders']\n",
      "Processing: setup\n",
      "Remaining: ['customers', 'orders']\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "# deque (\"deck\") - double-ended queue\n",
    "# Efficient for adding/removing from both ends\n",
    "# Odibi's graph.py uses deque for BFS (breadth-first search) traversal\n",
    "\n",
    "queue = deque()\n",
    "queue.append(\"customers\")   # Add to right\n",
    "queue.append(\"orders\")      # Add to right\n",
    "queue.appendleft(\"setup\")   # Add to left\n",
    "print(f\"Queue: {list(queue)}\")\n",
    "\n",
    "# Process in order (FIFO - first in, first out)\n",
    "first = queue.popleft()     # Remove from left\n",
    "print(f\"Processing: {first}\")  # setup\n",
    "print(f\"Remaining: {list(queue)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 8: dataclasses -- Simple Classes for Data\n",
    "\n",
    "A **dataclass** is a shortcut for creating classes that mainly hold data. \n",
    "Instead of writing `__init__`, `__repr__`, and `__eq__` yourself, Python generates them.\n",
    "\n",
    "Odibi uses dataclasses in 12+ modules: `pandas_engine.py`, `pipeline.py`, `diagnostics/`, \n",
    "`validation/`, and more.\n",
    "\n",
    "We will cover full OOP (classes, inheritance) in Phase 4. This is just a preview of \n",
    "dataclasses because they are simpler and you will need them soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NodeResult(name='customers', success=True, rows=1542, duration=3.45)\n",
      "customers\n",
      "1542\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "# Without dataclass (lots of boilerplate)\n",
    "class NodeResultOld:\n",
    "    def __init__(self, name, success, rows, duration):\n",
    "        self.name = name\n",
    "        self.success = success\n",
    "        self.rows = rows\n",
    "        self.duration = duration\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"NodeResult(name={self.name}, success={self.success}, rows={self.rows})\"\n",
    "\n",
    "# With dataclass (Python generates __init__ and __repr__ for you)\n",
    "@dataclass\n",
    "class NodeResult:\n",
    "    name: str\n",
    "    success: bool\n",
    "    rows: int\n",
    "    duration: float\n",
    "\n",
    "# Both create the same thing, but dataclass is much shorter\n",
    "result = NodeResult(name=\"customers\", success=True, rows=1542, duration=3.45)\n",
    "print(result)  # NodeResult(name='customers', success=True, rows=1542, duration=3.45)\n",
    "print(result.name)  # customers\n",
    "print(result.rows)  # 1542"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineResult(name='sales_pipeline', success=True, duration=0.0, errors=[], metadata=None)\n",
      "PipelineResult(name='failed_pipeline', success=False, duration=0.0, errors=['Connection timeout'], metadata=None)\n",
      "['Connection timeout']\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional\n",
    "\n",
    "# Dataclass with defaults and complex fields\n",
    "@dataclass\n",
    "class PipelineResult:\n",
    "    name: str\n",
    "    success: bool = True              # Default value\n",
    "    duration: float = 0.0\n",
    "    errors: List[str] = field(default_factory=list)  # Mutable defaults need field()\n",
    "    metadata: Optional[dict] = None   # Optional means it can be None\n",
    "\n",
    "# Use with all defaults\n",
    "r1 = PipelineResult(name=\"sales_pipeline\")\n",
    "print(r1)\n",
    "\n",
    "# Override some defaults\n",
    "r2 = PipelineResult(name=\"failed_pipeline\", success=False, errors=[\"Connection timeout\"])\n",
    "print(r2)\n",
    "print(r2.errors)  # ['Connection timeout']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8.1: Create a data class\n",
    "\n",
    "Create a `@dataclass` called `ValidationResult` with:\n",
    "- `test_name` (str)\n",
    "- `passed` (bool)\n",
    "- `total_rows` (int)\n",
    "- `failed_rows` (int, default 0)\n",
    "- `message` (str, default \"\")\n",
    "\n",
    "Add a method called `pass_rate` that returns the pass rate as a float.\n",
    "\n",
    "Then create a list of 3 results and print which tests failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PASS] not_null: 100.0% pass rate\n",
      "[FAIL] unique: 97.7% pass rate\n",
      "[PASS] range_check: 99.5% pass rate\n"
     ]
    }
   ],
   "source": [
    "# Exercise 8.1\n",
    "# YOUR CODE HERE\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ValidationResult:\n",
    "    test_name: str\n",
    "    passed: bool\n",
    "    total_rows: int\n",
    "    failed_rows: int = field(default=0)\n",
    "    message: str = field(default=\"\")\n",
    "    \n",
    "    def pass_rate(self):\n",
    "        return float((self.total_rows - self.failed_rows)/self.total_rows)\n",
    "\n",
    "# Test:\n",
    "results = [\n",
    "    ValidationResult(\"not_null\", True, 1000, 0),\n",
    "    ValidationResult(\"unique\", False, 1000, 23, \"23 duplicate rows\"),\n",
    "    ValidationResult(\"range_check\", True, 1000, 5),\n",
    "]\n",
    "for r in results:\n",
    "    status = \"PASS\" if r.passed else \"FAIL\"\n",
    "    print(f\"[{status}] {r.test_name}: {r.pass_rate():.1%} pass rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 9: enum -- Named Constants\n",
    "\n",
    "An **Enum** (enumeration) is a set of named constants. Instead of using magic strings \n",
    "like `\"pandas\"` or `\"spark\"` scattered throughout your code, you define them once as an Enum.\n",
    "\n",
    "Odibi's `config.py` defines Enums for EngineType, ConnectionType, WriteMode, and more.\n",
    "This is what makes the YAML config validation work -- invalid values are caught automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EngineType.PANDAS\n",
      "pandas\n",
      "PANDAS\n",
      "True\n",
      "True\n",
      "  PANDAS = pandas\n",
      "  SPARK = spark\n",
      "  POLARS = polars\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "\n",
    "# Define an Enum\n",
    "class EngineType(str, Enum):\n",
    "    PANDAS = \"pandas\"\n",
    "    SPARK = \"spark\"\n",
    "    POLARS = \"polars\"\n",
    "\n",
    "# Using it\n",
    "engine = EngineType.PANDAS\n",
    "print(engine)          # EngineType.PANDAS\n",
    "print(engine.value)    # pandas\n",
    "print(engine.name)     # PANDAS\n",
    "\n",
    "# Comparison\n",
    "print(engine == EngineType.PANDAS)  # True\n",
    "print(engine == \"pandas\")           # True (because it inherits from str)\n",
    "\n",
    "# List all values\n",
    "for e in EngineType:\n",
    "    print(f\"  {e.name} = {e.value}\")\n",
    "\n",
    "# This is EXACTLY how odibi/config.py defines EngineType!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WriteMode.UPSERT\n",
      "Invalid mode: delete. Must be one of: ['overwrite', 'append', 'upsert', 'append_once', 'merge']\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "\n",
    "# Practical use: validation\n",
    "class WriteMode(str, Enum):\n",
    "    OVERWRITE = \"overwrite\"\n",
    "    APPEND = \"append\"\n",
    "    UPSERT = \"upsert\"\n",
    "    APPEND_ONCE = \"append_once\"\n",
    "    MERGE = \"merge\"\n",
    "\n",
    "# Validate input\n",
    "def validate_write_mode(mode_str):\n",
    "    try:\n",
    "        return WriteMode(mode_str)\n",
    "    except ValueError:\n",
    "        valid = [m.value for m in WriteMode]\n",
    "        raise ValueError(f\"Invalid mode: {mode_str}. Must be one of: {valid}\")\n",
    "\n",
    "print(validate_write_mode(\"upsert\"))  # WriteMode.UPSERT\n",
    "\n",
    "try:\n",
    "    validate_write_mode(\"delete\")\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 10: Quick Hits -- contextlib and functools\n",
    "\n",
    "These will be covered in depth in Phase 5. Here is a preview of the most common uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleep test: 0.50s\n"
     ]
    }
   ],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "# contextmanager lets you create your own 'with' blocks\n",
    "# Odibi's PhaseTimer in node.py uses this exact pattern\n",
    "\n",
    "import time\n",
    "\n",
    "@contextmanager\n",
    "def timer(label):\n",
    "    \"\"\"Time a block of code.\"\"\"\n",
    "    start = time.time()\n",
    "    yield  # This is where the 'with' block runs\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"{label}: {elapsed:.2f}s\")\n",
    "\n",
    "# Use it\n",
    "with timer(\"Sleep test\"):\n",
    "    time.sleep(0.5)  # Pause for half a second\n",
    "# Prints: Sleep test: 0.50s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling process_node\n",
      "Processed customers\n",
      "process_node\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "\n",
    "# wraps preserves function metadata when decorating\n",
    "# Odibi's registry.py uses @wraps in the @transform decorator\n",
    "# Full coverage in Phase 5\n",
    "\n",
    "def log_call(func):\n",
    "    \"\"\"Decorator that logs function calls.\"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        print(f\"Calling {func.__name__}\")\n",
    "        return func(*args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "@log_call\n",
    "def process_node(name):\n",
    "    \"\"\"Process a single node.\"\"\"\n",
    "    return f\"Processed {name}\"\n",
    "\n",
    "print(process_node(\"customers\"))\n",
    "print(process_node.__name__)  # \"process_node\" (preserved by @wraps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 11: Interview Drill\n",
    "\n",
    "These test your standard library knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drill 1: File operations\n",
    "\n",
    "Write a function that:\n",
    "1. Takes a directory path\n",
    "2. Lists all `.csv` files in it (using pathlib)\n",
    "3. Returns a list of their names (without the directory path)\n",
    "\n",
    "Test it on the current directory (it is fine if the list is empty)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drill 1\n",
    "# YOUR CODE HERE\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drill 2: JSON round-trip\n",
    "\n",
    "Given a list of dicts, convert them to a JSON string, then back to Python objects. \n",
    "Verify the round-trip was lossless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drill 2\n",
    "# YOUR CODE HERE\n",
    "import json\n",
    "\n",
    "data = [\n",
    "    {\"node\": \"customers\", \"rows\": 1542, \"success\": True},\n",
    "    {\"node\": \"orders\", \"rows\": 8930, \"success\": True},\n",
    "]\n",
    "\n",
    "# Convert to JSON string, then back. Print both and verify equality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drill 3: Date math\n",
    "\n",
    "Calculate how many days between January 15, 2024 and today. \n",
    "Print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drill 3\n",
    "# YOUR CODE HERE\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drill 4: Counter\n",
    "\n",
    "Given a list of log levels, use `Counter` to find the most common level \n",
    "and the least common level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drill 4\n",
    "# YOUR CODE HERE\n",
    "from collections import Counter\n",
    "\n",
    "log_levels = [\"INFO\", \"INFO\", \"WARNING\", \"INFO\", \"ERROR\", \"INFO\", \n",
    "              \"WARNING\", \"DEBUG\", \"INFO\", \"ERROR\", \"WARNING\", \"INFO\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Checkpoint\n",
    "\n",
    "You now know Python's standard library toolkit. Here is what you covered:\n",
    "\n",
    "- **pathlib / os** -- file paths, directories, environment variables\n",
    "- **json** -- reading and writing structured data, the `with` statement\n",
    "- **re** -- pattern matching with regular expressions\n",
    "- **logging** -- professional output with levels\n",
    "- **datetime** -- dates, times, durations, formatting\n",
    "- **hashlib / uuid** -- data fingerprints and unique IDs\n",
    "- **collections** -- `defaultdict`, `Counter`, `deque`\n",
    "- **dataclasses** -- simple data-holding classes\n",
    "- **enum** -- named constants for clean code\n",
    "- **contextlib / functools** -- context managers and decorators (preview)\n",
    "\n",
    "Every module above is used in Odibi. You are not learning theory -- you are learning \n",
    "the tools your framework is built with.\n",
    "\n",
    "**Next:** Notebook 04 -- Object-Oriented Programming (classes, inheritance, ABC, \n",
    "dunder methods, composition). This is where you start building mini-odibi's architecture."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
