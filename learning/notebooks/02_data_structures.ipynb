{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Data Structures and Comprehensions\n",
    "## The tools you reach for every day\n",
    "\n",
    "In Phase 1, you learned how to work with single values -- a string, a number, a boolean.\n",
    "But real programs work with **collections** of data. A list of node names. A dictionary of \n",
    "configuration settings. A set of unique column names.\n",
    "\n",
    "Python has four built-in collection types. By the end of this notebook, you will know:\n",
    "\n",
    "- **Lists** -- ordered collections you can change\n",
    "- **Dictionaries** -- key-value pairs (the most important data structure in Python)\n",
    "- **Sets** -- collections of unique values\n",
    "- **Tuples** -- ordered collections you cannot change\n",
    "\n",
    "You will also learn **comprehensions** -- a Python superpower that lets you build and transform \n",
    "collections in a single line. Odibi uses over 280 comprehensions across its codebase. \n",
    "By the end of this notebook, you will understand every single one of them.\n",
    "\n",
    "**Rules (same as Phase 1):**\n",
    "1. Type every line of code yourself.\n",
    "2. Run every cell.\n",
    "3. Complete every exercise before moving on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Lists\n",
    "\n",
    "A **list** is an ordered collection of items. You create one with square brackets `[]`.\n",
    "\n",
    "Think of a list like a numbered shelf. Each item has a position (called an **index**), \n",
    "starting at 0. You can add items, remove items, and rearrange them.\n",
    "\n",
    "Lists are the most common data structure in Python. In Odibi, lists are used for:\n",
    "- Column names\n",
    "- Node execution order\n",
    "- Validation test results\n",
    "- Error messages and suggestions\n",
    "\n",
    "### Creating lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['customers', 'orders', 'products']\n",
      "[1542, 8930, 234]\n",
      "['customers', 1542, True, None]\n",
      "[]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Creating lists\n",
    "nodes = [\"customers\", \"orders\", \"products\"]  # List of strings\n",
    "row_counts = [1542, 8930, 234]                # List of integers\n",
    "mixed = [\"customers\", 1542, True, None]       # Lists can hold any type\n",
    "empty = []                                     # Empty list\n",
    "\n",
    "print(nodes)\n",
    "print(row_counts)\n",
    "print(mixed)\n",
    "print(empty)\n",
    "print(type(nodes))  # <class 'list'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and slicing\n",
    "\n",
    "Every item in a list has an index. Remember: **indexing starts at 0**, not 1.\n",
    "\n",
    "```\n",
    "Index:     0           1          2\n",
    "List:  [\"customers\", \"orders\", \"products\"]\n",
    "```\n",
    "\n",
    "You can also use **negative indexing** to count from the end:\n",
    "```\n",
    "Index:    -3          -2         -1\n",
    "List:  [\"customers\", \"orders\", \"products\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing - accessing individual items\n",
    "nodes = [\"customers\", \"orders\", \"products\", \"inventory\", \"shipments\"]\n",
    "\n",
    "print(nodes[0])    # First item: customers\n",
    "print(nodes[1])    # Second item: orders\n",
    "print(nodes[-1])   # LAST item: shipments\n",
    "print(nodes[-2])   # Second to last: inventory\n",
    "\n",
    "# len() - how many items in the list\n",
    "print(len(nodes))  # 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['customers', 'orders', 'products']\n",
      "['orders', 'products', 'inventory']\n",
      "['customers', 'orders', 'products']\n",
      "['products', 'inventory', 'shipments']\n",
      "['customers', 'orders', 'products', 'inventory', 'shipments']\n",
      "['customers', 'products', 'shipments']\n",
      "['shipments', 'inventory', 'products', 'orders', 'customers']\n"
     ]
    }
   ],
   "source": [
    "# Slicing - getting a portion of the list\n",
    "# Syntax: list[start:stop]  (start is included, stop is NOT included)\n",
    "nodes = [\"customers\", \"orders\", \"products\", \"inventory\", \"shipments\"]\n",
    "\n",
    "print(nodes[0:3])   # First 3 items: ['customers', 'orders', 'products']\n",
    "print(nodes[1:4])   # Items at index 1, 2, 3: ['orders', 'products', 'inventory']\n",
    "print(nodes[:3])    # From start to index 3: ['customers', 'orders', 'products']\n",
    "print(nodes[2:])    # From index 2 to end: ['products', 'inventory', 'shipments']\n",
    "print(nodes[:])     # Copy of the entire list\n",
    "\n",
    "# Slicing with step\n",
    "print(nodes[::2])   # Every other item: ['customers', 'products', 'shipments']\n",
    "print(nodes[::-1])  # Reversed! ['shipments', 'inventory', 'products', 'orders', 'customers']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying lists\n",
    "\n",
    "Lists are **mutable** -- you can change them after creation. This is different from strings, \n",
    "which are immutable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['customers', 'orders', 'products', 'inventory']\n",
      "['customers', 'accounts', 'orders', 'products', 'inventory']\n",
      "['customers', 'orders', 'products', 'inventory']\n",
      "inventory\n",
      "['customers', 'orders', 'products']\n",
      "orders\n"
     ]
    }
   ],
   "source": [
    "# Modifying lists\n",
    "nodes = [\"customers\", \"orders\", \"products\"]\n",
    "\n",
    "# Add to the end\n",
    "nodes.append(\"inventory\")\n",
    "print(nodes)  # ['customers', 'orders', 'products', 'inventory']\n",
    "\n",
    "# Insert at a specific position\n",
    "nodes.insert(1, \"accounts\")  # Insert at index 1\n",
    "print(nodes)  # ['customers', 'accounts', 'orders', 'products', 'inventory']\n",
    "\n",
    "# Remove by value\n",
    "nodes.remove(\"accounts\")\n",
    "print(nodes)  # ['customers', 'orders', 'products', 'inventory']\n",
    "\n",
    "# Remove by index and get the value back\n",
    "last = nodes.pop()       # Removes and returns the last item\n",
    "print(last)              # inventory\n",
    "print(nodes)             # ['customers', 'orders', 'products']\n",
    "\n",
    "second = nodes.pop(1)    # Removes and returns item at index -1\n",
    "print(second)            # orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['customers', 'orders', 'products', 'inventory', 'shipments']\n",
      "['raw_sales', 'raw_returns', 'clean_sales', 'clean_returns']\n",
      "[1, 1, 2, 3, 4, 5, 6, 9]\n",
      "[9, 6, 5, 4, 3, 2, 1, 1]\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# More list operations\n",
    "nodes = [\"customers\", \"orders\", \"products\"]\n",
    "\n",
    "# Extend - add multiple items\n",
    "nodes.extend([\"inventory\", \"shipments\"])\n",
    "print(nodes)  # ['customers', 'orders', 'products', 'inventory', 'shipments']\n",
    "\n",
    "# + operator - combine lists (creates a new list)\n",
    "bronze = [\"raw_sales\", \"raw_returns\"]\n",
    "silver = [\"clean_sales\", \"clean_returns\"]\n",
    "all_nodes = bronze + silver\n",
    "print(all_nodes)\n",
    "\n",
    "# Sort\n",
    "numbers = [3, 1, 4, 1, 5, 9, 2, 6]\n",
    "numbers.sort()\n",
    "print(numbers)  # [1, 1, 2, 3, 4, 5, 6, 9]\n",
    "\n",
    "# Sort descending\n",
    "numbers.sort(reverse=True)\n",
    "print(numbers)  # [9, 6, 5, 4, 3, 2, 1, 1]\n",
    "\n",
    "# Check if item exists\n",
    "print(\"customers\" in nodes)   # True\n",
    "print(\"missing\" in nodes)     # False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT: .sort() vs sorted()\n",
    "\n",
    "This trips up many people and is an interview favorite:\n",
    "\n",
    "- `list.sort()` -- sorts the list **in place** (changes the original, returns `None`)\n",
    "- `sorted(list)` -- returns a **new sorted list** (original is unchanged)\n",
    "\n",
    "```python\n",
    "nums = [3, 1, 2]\n",
    "result = nums.sort()   # result is None! nums is now [1, 2, 3]\n",
    "\n",
    "nums = [3, 1, 2]\n",
    "result = sorted(nums)  # result is [1, 2, 3], nums is still [3, 1, 2]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nums.sort() returned: None\n",
      "nums is now: [1, 2, 3]\n",
      "sorted(nums) returned: [1, 2, 3]\n",
      "nums is still: [3, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# Demonstrating .sort() vs sorted()\n",
    "nums = [3, 1, 2]\n",
    "result = nums.sort()\n",
    "print(f\"nums.sort() returned: {result}\")  # None!\n",
    "print(f\"nums is now: {nums}\")              # [1, 2, 3]\n",
    "\n",
    "nums = [3, 1, 2]\n",
    "result = sorted(nums)\n",
    "print(f\"sorted(nums) returned: {result}\")  # [1, 2, 3]\n",
    "print(f\"nums is still: {nums}\")            # [3, 1, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Build a node execution report\n",
    "\n",
    "Given the list below:\n",
    "1. Add `\"shipments\"` to the end\n",
    "2. Insert `\"accounts\"` at index 2\n",
    "3. Remove `\"temp_table\"` (it should not be there)\n",
    "4. Print the final list and its length\n",
    "5. Print the first node and the last node\n",
    "6. Print the list in reverse order (without modifying the original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List: ['customers', 'orders', 'accounts', 'products', 'inventory', 'shipments'] | Length: 6\n",
      "First item: customers | Last item: shipments\n",
      "Reversed: ['shipments', 'inventory', 'products', 'accounts', 'orders', 'customers'] original: ['customers', 'orders', 'accounts', 'products', 'inventory', 'shipments']\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1.1\n",
    "# YOUR CODE HERE\n",
    "nodes = [\"customers\", \"orders\", \"temp_table\", \"products\", \"inventory\"]\n",
    "\n",
    "# 1. Add \"shipments\" to the end\n",
    "nodes.append(\"shipments\")\n",
    "\n",
    "# 2. Insert \"accounts\" at index 2\n",
    "nodes.insert(2,\"accounts\")\n",
    "\n",
    "# 3. Remove \"temp_table\"\n",
    "nodes.remove(\"temp_table\")\n",
    "\n",
    "# 4. Print the final list and its length\n",
    "print(f\"List: {nodes} | Length: {len(nodes)}\")\n",
    "# 5. Print first and last node\n",
    "print(f\"First item: {nodes[0]} | Last item: {nodes[-1]}\")\n",
    "# 6. Print in reverse (without modifying original)\n",
    "print(f\"Reversed: {(nodes[::-1])} original: {nodes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "['customers', 'orders', 'accounts', 'products', 'inventory', 'shipments']\n",
    "Length: 6\n",
    "First: customers\n",
    "Last: shipments\n",
    "Reversed: ['shipments', 'inventory', 'products', 'accounts', 'orders', 'customers']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Dictionaries\n",
    "\n",
    "A **dictionary** (dict) is a collection of **key-value pairs**. You create one with curly braces `{}`.\n",
    "\n",
    "If a list is like a numbered shelf, a dictionary is like a labeled filing cabinet. \n",
    "Each drawer has a label (the key) and contents (the value).\n",
    "\n",
    "Dictionaries are arguably the **most important** data structure in Python. They are used for:\n",
    "- Configuration (Odibi YAML configs become dicts)\n",
    "- Mapping names to values\n",
    "- JSON data (which is just dicts and lists)\n",
    "- Function keyword arguments\n",
    "- Counting occurrences\n",
    "\n",
    "In Odibi, dictionaries are everywhere: config settings, node metadata, column mappings, \n",
    "engine registries, validation results, and more.\n",
    "\n",
    "### Creating dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'customers', 'format': 'delta', 'write_mode': 'upsert', 'row_count': 1542, 'is_active': True}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Creating dictionaries\n",
    "# Syntax: {key: value, key: value, ...}\n",
    "node_config = {\n",
    "    \"name\": \"customers\",\n",
    "    \"format\": \"delta\",\n",
    "    \"write_mode\": \"upsert\",\n",
    "    \"row_count\": 1542,\n",
    "    \"is_active\": True,\n",
    "}\n",
    "\n",
    "print(node_config)\n",
    "print(type(node_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing values\n",
    "node_config = {\n",
    "    \"name\": \"customers\",\n",
    "    \"format\": \"delta\",\n",
    "    \"write_mode\": \"upsert\",\n",
    "    \"row_count\": 1542,\n",
    "}\n",
    "\n",
    "# Method 1: Square brackets (raises KeyError if key missing)\n",
    "print(node_config[\"name\"])       # customers\n",
    "print(node_config[\"row_count\"])  # 1542\n",
    "\n",
    "# Method 2: .get() (returns None or default if key missing -- SAFER)\n",
    "print(node_config.get(\"name\"))           # customers\n",
    "print(node_config.get(\"missing_key\"))    # None (no error!)\n",
    "print(node_config.get(\"missing_key\", \"default_value\"))  # default_value\n",
    "\n",
    "# IMPORTANT: Always use .get() when the key might not exist.\n",
    "# This is a common source of bugs -- KeyError crashes your program.\n",
    "# In an interview, using .get() shows you write defensive code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'customers', 'format': 'csv', 'write_mode': 'upsert'}\n",
      "{'name': 'customers', 'format': 'delta', 'write_mode': 'upsert'}\n",
      "{'name': 'customers', 'write_mode': 'upsert'}\n",
      "Removed: upsert\n",
      "{'name': 'customers'}\n"
     ]
    }
   ],
   "source": [
    "# Modifying dictionaries\n",
    "node_config = {\n",
    "    \"name\": \"customers\",\n",
    "    \"format\": \"csv\",\n",
    "}\n",
    "\n",
    "# Add a new key\n",
    "node_config[\"write_mode\"] = \"upsert\"\n",
    "print(node_config)\n",
    "\n",
    "# Update an existing key\n",
    "node_config[\"format\"] = \"delta\"\n",
    "print(node_config)\n",
    "\n",
    "# Delete a key\n",
    "del node_config[\"format\"]\n",
    "print(node_config)\n",
    "\n",
    "# .pop() -- remove and return the value\n",
    "mode = node_config.pop(\"write_mode\")\n",
    "print(f\"Removed: {mode}\")  # upsert\n",
    "print(node_config)         # Only 'name' left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating over dictionaries\n",
    "\n",
    "This is one of the most common things you will do in Python. There are three ways to loop \n",
    "over a dict, and you need to know all three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Keys ===\n",
      "name\n",
      "format\n",
      "write_mode\n",
      "row_count\n",
      "\n",
      "=== Values ===\n",
      "customers\n",
      "delta\n",
      "upsert\n",
      "1542\n",
      "\n",
      "=== Key-Value Pairs ===\n",
      "  name: customers\n",
      "  format: delta\n",
      "  write_mode: upsert\n",
      "  row_count: 1542\n"
     ]
    }
   ],
   "source": [
    "# Three ways to iterate over a dictionary\n",
    "node_config = {\n",
    "    \"name\": \"customers\",\n",
    "    \"format\": \"delta\",\n",
    "    \"write_mode\": \"upsert\",\n",
    "    \"row_count\": 1542,\n",
    "}\n",
    "\n",
    "# 1. Loop over KEYS (default behavior)\n",
    "print(\"=== Keys ===\")\n",
    "for key in node_config:\n",
    "    print(key)\n",
    "\n",
    "# 2. Loop over VALUES\n",
    "print(\"\\n=== Values ===\")\n",
    "for value in node_config.values():\n",
    "    print(value)\n",
    "\n",
    "# 3. Loop over KEY-VALUE PAIRS (most common and most useful)\n",
    "print(\"\\n=== Key-Value Pairs ===\")\n",
    "for key, value in node_config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested dictionaries\n",
    "\n",
    "Dictionaries can contain other dictionaries. This is exactly how Odibi's YAML configs work -- \n",
    "a pipeline config is a dictionary of dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_customers.csv\n",
      "append\n",
      "['customer_id']\n",
      "Node: customers, Source: raw_customers.csv, Mode: upsert\n",
      "Node: orders, Source: raw_orders.csv, Mode: append\n"
     ]
    }
   ],
   "source": [
    "# Nested dictionaries -- like an Odibi pipeline config\n",
    "pipeline = {\n",
    "    \"customers\": {\n",
    "        \"source\": \"raw_customers.csv\",\n",
    "        \"format\": \"csv\",\n",
    "        \"write_mode\": \"upsert\",\n",
    "        \"keys\": [\"customer_id\"],\n",
    "    },\n",
    "    \"orders\": {\n",
    "        \"source\": \"raw_orders.csv\",\n",
    "        \"format\": \"csv\",\n",
    "        \"write_mode\": \"append\",\n",
    "        \"keys\": [\"order_id\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Access nested values\n",
    "print(pipeline[\"customers\"][\"source\"])     # raw_customers.csv\n",
    "print(pipeline[\"orders\"][\"write_mode\"])     # append\n",
    "print(pipeline[\"customers\"][\"keys\"])        # [\"customer_id\"]\n",
    "\n",
    "# Loop through the pipeline\n",
    "for node_name, config in pipeline.items():\n",
    "    print(f\"Node: {node_name}, Source: {config['source']}, Mode: {config['write_mode']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if a key exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "No write mode specified, using default: overwrite\n",
      "Write mode: overwrite\n"
     ]
    }
   ],
   "source": [
    "# Checking for keys\n",
    "config = {\"name\": \"customers\", \"format\": \"delta\"}\n",
    "\n",
    "# Use \"in\" to check if a KEY exists (not a value!)\n",
    "print(\"name\" in config)        # True\n",
    "print(\"write_mode\" in config)  # False\n",
    "\n",
    "# Common pattern: check before accessing\n",
    "if \"write_mode\" in config:\n",
    "    print(f\"Write mode: {config['write_mode']}\")\n",
    "else:\n",
    "    print(\"No write mode specified, using default: overwrite\")\n",
    "\n",
    "# Even better: use .get() with a default\n",
    "write_mode = config.get(\"write_mode\", \"overwrite\")\n",
    "print(f\"Write mode: {write_mode}\")  # overwrite (the default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1: Node config builder\n",
    "\n",
    "Build a dictionary called `node_config` with these keys and values:\n",
    "- name: \"sales_fact\"\n",
    "- source_format: \"csv\"\n",
    "- write_mode: \"upsert\"\n",
    "- keys: [\"sale_id\", \"date\"]  (a list)\n",
    "- enabled: True\n",
    "\n",
    "Then:\n",
    "1. Print the value of `keys`\n",
    "2. Change `source_format` to `\"delta\"`\n",
    "3. Add a new key `row_count` with value `0`\n",
    "4. Loop through the config and print each key-value pair\n",
    "5. Use `.get()` to safely access a key called `\"description\"` with default `\"No description\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: name | Value: sales_fact\n",
      "Key: source_format | Value: delta\n",
      "Key: write_mode | Value: upsert\n",
      "Key: keys | Value: ['sale_id', 'date']\n",
      "Key: enabled | Value: True\n",
      "Key: row_count | Value: 0\n",
      "No description\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2.1\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Build the dictionary\n",
    "\n",
    "# 1. Print the value of keys\n",
    "node_config = {\n",
    "    \"name\": \"sales_fact\",\n",
    "    \"source_format\": \"csv\",\n",
    "    \"write_mode\": \"upsert\",\n",
    "    \"keys\": [\"sale_id\", \"date\"],\n",
    "    \"enabled\": True\n",
    "}\n",
    "\n",
    "# 2. Change source_format to \"delta\"\n",
    "node_config[\"source_format\"] = \"delta\"\n",
    "# 3. Add row_count\n",
    "node_config[\"row_count\"] = 0\n",
    "\n",
    "# 4. Loop through and print each key-value pair\n",
    "for name, value in node_config.items():\n",
    "    print(f\"Key: {name} | Value: {value}\")\n",
    "\n",
    "# 5. Safely get \"description\"\n",
    "desc = node_config.get(\"description\", \"No description\")\n",
    "print(desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2: Pipeline summary\n",
    "\n",
    "Given this nested pipeline dict, write code that:\n",
    "1. Prints the number of nodes\n",
    "2. Loops through each node and prints: `Node: {name} | Mode: {write_mode} | Keys: {keys}`\n",
    "3. Finds and prints which nodes use \"upsert\" write mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6eb3f3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['customers', 'orders', 'products', 'logs'])\n"
     ]
    }
   ],
   "source": [
    "print(pipeline.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 4\n",
      "Node: customers | Mode: upsert | Keys: ['customer_id']\n",
      "Node: orders | Mode: append | Keys: ['order_id']\n",
      "Node: products | Mode: upsert | Keys: ['product_id']\n",
      "Node: logs | Mode: append | Keys: ['log_id']\n",
      "Nodes using upsert: customers ,products\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2.2\n",
    "# YOUR CODE HERE\n",
    "pipeline = {\n",
    "    \"customers\": {\"write_mode\": \"upsert\", \"keys\": [\"customer_id\"]},\n",
    "    \"orders\": {\"write_mode\": \"append\", \"keys\": [\"order_id\"]},\n",
    "    \"products\": {\"write_mode\": \"upsert\", \"keys\": [\"product_id\"]},\n",
    "    \"logs\": {\"write_mode\": \"append\", \"keys\": [\"log_id\"]},\n",
    "}\n",
    "\n",
    "# 1. Print number of nodes\n",
    "print(f\"Number of nodes: {len(pipeline.values())}\")\n",
    "\n",
    "# 2. Print each node's details\n",
    "for node, values in pipeline.items():\n",
    "    print(f\"Node: {node} | Mode: {values['write_mode']} | Keys: {values['keys']}\")\n",
    "# 3. Find nodes using upsert\n",
    "upsert_nodes = ' ,'.join([node for node in pipeline.keys() if \"upsert\" in pipeline[node]['write_mode']])\n",
    "print(f'Nodes using upsert: {upsert_nodes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "Pipeline has 4 nodes\n",
    "\n",
    "Node: customers | Mode: upsert | Keys: ['customer_id']\n",
    "Node: orders | Mode: append | Keys: ['order_id']\n",
    "Node: products | Mode: upsert | Keys: ['product_id']\n",
    "Node: logs | Mode: append | Keys: ['log_id']\n",
    "\n",
    "Nodes using upsert: customers, products\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Sets\n",
    "\n",
    "A **set** is an unordered collection of **unique** values. No duplicates allowed.\n",
    "\n",
    "Sets are used when you need to:\n",
    "- Remove duplicates from a list\n",
    "- Check membership quickly (faster than lists)\n",
    "- Find what is in one collection but not another\n",
    "\n",
    "In Odibi, sets are used for things like finding unexpected parameters, checking which \n",
    "columns exist vs. which are expected, and deduplicating lists.\n",
    "\n",
    "Look at this line from `odibi/registry.py`:\n",
    "```python\n",
    "unexpected = set(params.keys()) - set(func_params.keys())\n",
    "```\n",
    "This finds parameters that were passed but are not expected. That is a set operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'spark', 'polars', 'pandas'}\n",
      "<class 'set'>\n",
      "{'bronze', 'silver', 'gold'}\n",
      "{'name', 'email', 'id'}\n",
      "<class 'set'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Creating sets\n",
    "engines = {\"pandas\", \"spark\", \"polars\"}  # Curly braces, but no key:value\n",
    "print(engines)\n",
    "print(type(engines))\n",
    "\n",
    "# Duplicates are automatically removed\n",
    "tags = {\"bronze\", \"silver\", \"gold\", \"bronze\", \"silver\"}\n",
    "print(tags)  # Only 3 items, duplicates removed\n",
    "\n",
    "# Create a set from a list (common way to deduplicate)\n",
    "columns = [\"id\", \"name\", \"email\", \"name\", \"id\"]\n",
    "unique_columns = set(columns)\n",
    "print(unique_columns)  # Duplicates removed\n",
    "\n",
    "# IMPORTANT: Empty set is set(), NOT {}\n",
    "# {} creates an empty DICTIONARY\n",
    "empty_set = set()\n",
    "empty_dict = {}\n",
    "print(type(empty_set))   # <class 'set'>\n",
    "print(type(empty_dict))  # <class 'dict'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Union: {'address', 'phone', 'name', 'email', 'id', 'created_at'}\n",
      "Common: {'name', 'email', 'id'}\n",
      "Only in source: {'address', 'phone'}\n",
      "Only in target: {'created_at'}\n",
      "Different: {'address', 'phone', 'created_at'}\n"
     ]
    }
   ],
   "source": [
    "# Set operations -- this is what makes sets powerful\n",
    "source_columns = {\"id\", \"name\", \"email\", \"phone\", \"address\"}\n",
    "target_columns = {\"id\", \"name\", \"email\", \"created_at\"}\n",
    "\n",
    "# Union: everything in EITHER set (OR)\n",
    "all_columns = source_columns | target_columns\n",
    "print(f\"Union: {all_columns}\")\n",
    "\n",
    "# Intersection: only what is in BOTH sets (AND)\n",
    "common = source_columns & target_columns\n",
    "print(f\"Common: {common}\")\n",
    "\n",
    "# Difference: what is in source but NOT in target\n",
    "only_in_source = source_columns - target_columns\n",
    "print(f\"Only in source: {only_in_source}\")\n",
    "\n",
    "# What is in target but NOT in source\n",
    "only_in_target = target_columns - source_columns\n",
    "print(f\"Only in target: {only_in_target}\")\n",
    "\n",
    "# Symmetric difference: in one OR the other, but NOT both\n",
    "different = source_columns ^ target_columns\n",
    "print(f\"Different: {different}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Column validation\n",
    "\n",
    "You are building a validation check (like Odibi's validation engine). Given:\n",
    "- `required_columns` -- columns that MUST exist in the data\n",
    "- `actual_columns` -- columns that actually exist\n",
    "\n",
    "Write code that:\n",
    "1. Finds missing columns (required but not in actual)\n",
    "2. Finds extra columns (in actual but not required)\n",
    "3. Prints whether validation passed or failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns: {'created_at'}\n",
      "Extra columns: {'address', 'phone'}\n",
      "Validation FAILED: missing required columns: {'created_at'}\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.1\n",
    "# YOUR CODE HERE\n",
    "required_columns = {\"customer_id\", \"name\", \"email\", \"created_at\"}\n",
    "actual_columns = {\"customer_id\", \"name\", \"phone\", \"address\", \"email\"}\n",
    "\n",
    "# Find missing columns\n",
    "missing_columns = set(required_columns) - set(actual_columns)\n",
    "print(f'Missing columns: {missing_columns}')\n",
    "# Find extra columns\n",
    "extra_columns = set(actual_columns) - set(required_columns)\n",
    "print(f'Extra columns: {extra_columns}')\n",
    "\n",
    "# Print results\n",
    "print(f\"Validation FAILED: missing required columns: {missing_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "Missing columns: {'created_at'}\n",
    "Extra columns: {'phone', 'address'}\n",
    "Validation FAILED: missing required columns\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Tuples\n",
    "\n",
    "A **tuple** is like a list, but **immutable** -- once created, you cannot change it.\n",
    "\n",
    "Use tuples when:\n",
    "- You want to return multiple values from a function\n",
    "- The data should not be modified (coordinates, database rows, config constants)\n",
    "- You need a hashable key for a dictionary (lists cannot be dict keys, but tuples can)\n",
    "\n",
    "### Creating tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20)\n",
      "<class 'tuple'>\n",
      "customers\n",
      "1542\n"
     ]
    }
   ],
   "source": [
    "# Creating tuples\n",
    "position = (10, 20)              # Parentheses (but actually the comma makes it a tuple)\n",
    "node_info = (\"customers\", 1542, True)\n",
    "single = (\"only_one\",)           # Note the comma! Without it, this is just a string in parens\n",
    "\n",
    "print(position)\n",
    "print(type(position))\n",
    "\n",
    "# Accessing (same as lists)\n",
    "print(node_info[0])   # customers\n",
    "print(node_info[1])   # 1542\n",
    "\n",
    "# But you CANNOT modify\n",
    "# node_info[0] = \"orders\"  # TypeError: 'tuple' object does not support item assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuple unpacking\n",
    "\n",
    "This is extremely common in Python. When a function returns multiple values, \n",
    "it actually returns a tuple, and you **unpack** it into separate variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: customers, Count: 1542, Active: True\n",
      "customers: 1542 rows in 3.45s\n",
      "a=2, b=1\n"
     ]
    }
   ],
   "source": [
    "# Tuple unpacking\n",
    "node_info = (\"customers\", 1542, True)\n",
    "\n",
    "# Unpack into separate variables\n",
    "name, count, active = node_info\n",
    "print(f\"Name: {name}, Count: {count}, Active: {active}\")\n",
    "\n",
    "# This is what happens when a function returns multiple values\n",
    "def get_node_stats():\n",
    "    return \"customers\", 1542, 3.45  # Actually returns a tuple\n",
    "\n",
    "name, rows, duration = get_node_stats()\n",
    "print(f\"{name}: {rows} rows in {duration}s\")\n",
    "\n",
    "# Swapping variables (Python trick using tuple unpacking)\n",
    "a = 1\n",
    "b = 2\n",
    "a, b = b, a  # Swap!\n",
    "print(f\"a={a}, b={b}\")  # a=2, b=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Essential Built-in Functions\n",
    "\n",
    "Python has several built-in functions that work with collections. These come up constantly \n",
    "in both real code and interviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### enumerate()\n",
    "\n",
    "When you need both the index AND the value while looping, use `enumerate()`.\n",
    "\n",
    "The wrong way (but common for beginners):\n",
    "```python\n",
    "for i in range(len(my_list)):  # Do NOT do this\n",
    "    print(i, my_list[i])\n",
    "```\n",
    "\n",
    "The Pythonic way:\n",
    "```python\n",
    "for i, item in enumerate(my_list):  # Do THIS\n",
    "    print(i, item)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Processing customers\n",
      "Step 2: Processing orders\n",
      "Step 3: Processing products\n",
      "Step 1: Processing customers\n",
      "Step 2: Processing orders\n",
      "Step 3: Processing products\n"
     ]
    }
   ],
   "source": [
    "# enumerate() - index AND value\n",
    "nodes = [\"customers\", \"orders\", \"products\"]\n",
    "\n",
    "for i, node in enumerate(nodes):\n",
    "    print(f\"Step {i + 1}: Processing {node}\")\n",
    "\n",
    "# You can start the count at a different number\n",
    "for i, node in enumerate(nodes, start=1):\n",
    "    print(f\"Step {i}: Processing {node}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zip()\n",
    "\n",
    "`zip()` combines two or more lists element by element, like a zipper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customers: 1,542 rows\n",
      "orders: 8,930 rows\n",
      "products: 234 rows\n",
      "---\n",
      "[SUCCESS] customers: 1,542 rows\n",
      "[SUCCESS] orders: 8,930 rows\n",
      "[FAILED] products: 234 rows\n",
      "{'customers': 1542, 'orders': 8930, 'products': 234}\n"
     ]
    }
   ],
   "source": [
    "# zip() - combine lists element by element\n",
    "nodes = [\"customers\", \"orders\", \"products\"]\n",
    "row_counts = [1542, 8930, 234]\n",
    "statuses = [\"SUCCESS\", \"SUCCESS\", \"FAILED\"]\n",
    "\n",
    "# Combine two lists\n",
    "for node, count in zip(nodes, row_counts):\n",
    "    print(f\"{node}: {count:,} rows\")\n",
    "\n",
    "print(\"---\")\n",
    "\n",
    "# Combine three lists\n",
    "for node, count, status in zip(nodes, row_counts, statuses):\n",
    "    print(f\"[{status}] {node}: {count:,} rows\")\n",
    "\n",
    "# USEFUL: Create a dict from two lists\n",
    "node_counts = dict(zip(nodes, row_counts))\n",
    "print(node_counts)  # {'customers': 1542, 'orders': 8930, 'products': 234}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sorted() with key=lambda\n",
    "\n",
    "You already know `sorted()` returns a new sorted list. But what if you want to sort by \n",
    "something other than the default order?\n",
    "\n",
    "The `key` parameter takes a function that extracts the value to sort by. \n",
    "`lambda` is a way to write a tiny function in one line.\n",
    "\n",
    "```python\n",
    "lambda x: x[\"name\"]   # Same as: def get_name(x): return x[\"name\"]\n",
    "```\n",
    "\n",
    "We will cover `lambda` in depth in Phase 5. For now, just understand the `sorted()` pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  customers: 1542\n",
      "  orders: 8930\n",
      "  products: 234\n",
      "---\n",
      "  orders: 8930\n",
      "  customers: 1542\n",
      "  products: 234\n"
     ]
    }
   ],
   "source": [
    "# Sorting with key=lambda\n",
    "nodes = [\n",
    "    {\"name\": \"customers\", \"rows\": 1542},\n",
    "    {\"name\": \"orders\", \"rows\": 8930},\n",
    "    {\"name\": \"products\", \"rows\": 234},\n",
    "]\n",
    "\n",
    "# Sort by name (alphabetical)\n",
    "by_name = sorted(nodes, key=lambda x: x[\"name\"])\n",
    "for n in by_name:\n",
    "    print(f\"  {n['name']}: {n['rows']}\")\n",
    "\n",
    "print(\"---\")\n",
    "\n",
    "# Sort by row count (descending)\n",
    "by_rows = sorted(nodes, key=lambda x: x[\"rows\"], reverse=True)\n",
    "for n in by_rows:\n",
    "    print(f\"  {n['name']}: {n['rows']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### any() and all()\n",
    "\n",
    "These check conditions across a collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any: True\n",
      "all: False\n",
      "Has failures: True\n",
      "All passed: False\n"
     ]
    }
   ],
   "source": [
    "# any() - True if ANY item is True\n",
    "# all() - True if ALL items are True\n",
    "\n",
    "results = [True, True, False, True]\n",
    "print(f\"any: {any(results)}\")  # True (at least one is True)\n",
    "print(f\"all: {all(results)}\")  # False (not ALL are True)\n",
    "\n",
    "# Practical use: check if any validation tests failed\n",
    "statuses = [\"PASS\", \"PASS\", \"FAIL\", \"PASS\"]\n",
    "has_failures = any(s == \"FAIL\" for s in statuses)\n",
    "all_passed = all(s == \"PASS\" for s in statuses)\n",
    "print(f\"Has failures: {has_failures}\")  # True\n",
    "print(f\"All passed: {all_passed}\")      # False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.1: Build execution report\n",
    "\n",
    "Using `zip()` and `enumerate()`, build a formatted execution report from these parallel lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCCESS] customers - 1542 rows in 3.45s\n",
      "[SUCCESS] orders - 8930 rows in 12.8s\n",
      "[FAILED] products - 234 rows in 1.2s\n",
      "[SUCCESS] inventory - 4521 rows in 7.65s\n",
      "Total rows processed: 15227\n",
      "All nodes succeeded: False\n",
      "Any node failed: False\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5.1\n",
    "# YOUR CODE HERE\n",
    "nodes = [\"customers\", \"orders\", \"products\", \"inventory\"]\n",
    "durations = [3.45, 12.8, 1.2, 7.65]\n",
    "statuses = [\"SUCCESS\", \"SUCCESS\", \"FAILED\", \"SUCCESS\"]\n",
    "row_counts = [1542, 8930, 234, 4521]\n",
    "\n",
    "# Print a report like:\n",
    "# Step 1: [SUCCESS] customers - 1,542 rows in 3.45s\n",
    "# Step 2: [SUCCESS] orders - 8,930 rows in 12.80s\n",
    "# ...\n",
    "# \n",
    "# Then print:\n",
    "# - Total rows processed\n",
    "# - Whether all nodes succeeded (use all())\n",
    "# - Whether any node failed (use any())\n",
    "total_row_count = 0\n",
    "for statuse, node, row_count, duration in zip(statuses, nodes, row_counts, durations):\n",
    "    print(f\"[{statuse}] {node} - {row_count} rows in {duration}s\")\n",
    "    total_row_count += row_count\n",
    "\n",
    "print(f'Total rows processed: {total_row_count}')\n",
    "all_succeeded = all( f == \"SUCCESS\" for f in statuses)\n",
    "has_failed = all( f == \"FAILED\" for f in statuses)\n",
    "\n",
    "print(f\"All nodes succeeded: {all_succeeded}\")\n",
    "print(f\"Any node failed: {has_failed}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: List Comprehensions\n",
    "\n",
    "This is where Python becomes powerful. A **list comprehension** creates a new list by \n",
    "transforming or filtering an existing one -- in a single line.\n",
    "\n",
    "Odibi uses over 280 comprehensions. Once you understand them, you will read Odibi code \n",
    "fluently.\n",
    "\n",
    "### The basic pattern\n",
    "\n",
    "```python\n",
    "new_list = [expression for item in iterable]\n",
    "```\n",
    "\n",
    "This is equivalent to:\n",
    "```python\n",
    "new_list = []\n",
    "for item in iterable:\n",
    "    new_list.append(expression)\n",
    "```\n",
    "\n",
    "The comprehension version is shorter, faster, and more Pythonic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop: [2, 4, 6, 8, 10]\n",
      "Comprehension: [2, 4, 6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "# List comprehension - basic\n",
    "\n",
    "# Long way (loop)\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "doubled = []\n",
    "for n in numbers:\n",
    "    doubled.append(n * 2)\n",
    "print(f\"Loop: {doubled}\")\n",
    "\n",
    "# Short way (comprehension)\n",
    "doubled = [n * 2 for n in numbers]\n",
    "print(f\"Comprehension: {doubled}\")\n",
    "\n",
    "# They produce the same result, but the comprehension is one line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['missing column', 'null values found', 'type mismatch']\n",
      "['id', 'name']\n",
      "['customer_id', 'first_name', 'email']\n"
     ]
    }
   ],
   "source": [
    "# Real Odibi examples\n",
    "\n",
    "# From odibi/validation/engine.py:\n",
    "# \"Return only failures that are not empty\"\n",
    "failures = [\"missing column\", \"\", \"null values found\", \"\", \"type mismatch\"]\n",
    "real_failures = [f for f in failures if f]  # Filter out empty strings\n",
    "print(real_failures)\n",
    "\n",
    "# From odibi/validation/engine.py:\n",
    "# \"Get only columns that exist in the dataframe\"\n",
    "test_columns = [\"id\", \"name\", \"email\", \"phone\"]\n",
    "df_columns = [\"id\", \"name\", \"created_at\"]\n",
    "valid_cols = [c for c in test_columns if c in df_columns]\n",
    "print(valid_cols)  # Only columns that actually exist\n",
    "\n",
    "# From odibi/transformers/delete_detection.py:\n",
    "# \"Lowercase all column names for comparison\"\n",
    "columns = [\"Customer_ID\", \"First_Name\", \"EMAIL\"]\n",
    "lower_cols = [c.lower() for c in columns]\n",
    "print(lower_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension with condition (filtering)\n",
    "\n",
    "```python\n",
    "new_list = [expression for item in iterable if condition]\n",
    "```\n",
    "\n",
    "This only includes items where the condition is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5, 7]\n",
      "[-2, -4, -6]\n",
      "Failed nodes: ['orders']\n"
     ]
    }
   ],
   "source": [
    "# Comprehension with condition\n",
    "numbers = [1, -2, 3, -4, 5, -6, 7]\n",
    "\n",
    "# Only positive numbers\n",
    "positives = [n for n in numbers if n > 0]\n",
    "print(positives)  # [1, 3, 5, 7]\n",
    "\n",
    "# Only even numbers\n",
    "evens = [n for n in numbers if n % 2 == 0]\n",
    "print(evens)  # [-2, -4, -6]\n",
    "\n",
    "# Real Odibi pattern: filter nodes by status\n",
    "nodes = [\n",
    "    {\"name\": \"customers\", \"success\": True},\n",
    "    {\"name\": \"orders\", \"success\": False},\n",
    "    {\"name\": \"products\", \"success\": True},\n",
    "]\n",
    "failed = [n[\"name\"] for n in nodes if not n[\"success\"]]\n",
    "print(f\"Failed nodes: {failed}\")  # [\"orders\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension with if/else (transform)\n",
    "\n",
    "When you want to transform ALL items but differently based on a condition, \n",
    "put the if/else BEFORE the `for`:\n",
    "\n",
    "```python\n",
    "# if/else BEFORE for = transform every item\n",
    "new_list = [x if condition else y for item in iterable]\n",
    "\n",
    "# if AFTER for = filter items\n",
    "new_list = [x for item in iterable if condition]\n",
    "```\n",
    "\n",
    "This distinction is important and commonly tested in interviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 3, 0, 5]\n",
      "['positive', 'negative', 'positive', 'negative', 'positive']\n",
      "['PASS', 'FAIL', 'PASS', 'PASS', 'FAIL']\n"
     ]
    }
   ],
   "source": [
    "# if/else in comprehension (transform, not filter)\n",
    "numbers = [1, -2, 3, -4, 5]\n",
    "\n",
    "# Replace negatives with 0\n",
    "cleaned = [n if n > 0 else 0 for n in numbers]\n",
    "print(cleaned)  # [1, 0, 3, 0, 5]\n",
    "\n",
    "# Label each number\n",
    "labels = [\"positive\" if n > 0 else \"negative\" for n in numbers]\n",
    "print(labels)\n",
    "\n",
    "# Real Odibi pattern: status labels\n",
    "results = [True, False, True, True, False]\n",
    "labels = [\"PASS\" if r else \"FAIL\" for r in results]\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.1: Comprehension practice\n",
    "\n",
    "Write list comprehensions for each task (one line each):\n",
    "\n",
    "1. Given `numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]`, create a list of squares: `[1, 4, 9, 16, ...]`\n",
    "2. Given the same list, create a list of only even numbers\n",
    "3. Given `names = [\"  customers \", \"ORDERS\", \" Products \"]`, create a list of cleaned names (strip + lower)\n",
    "4. Given `columns = [\"id\", \"name\", \"_temp\", \"email\", \"_internal\"]`, create a list excluding columns that start with `_`\n",
    "5. Given `counts = [1542, 0, 8930, 0, 234]`, create a list where 0s are replaced with `\"EMPTY\"` and non-zeros stay as numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
      "[2, 4, 6, 8, 10]\n",
      "['customers', 'orders', 'products']\n",
      "['id', 'name', 'email']\n",
      "[1542, 'Empty', 8930, 'Empty', 234]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 6.1\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# 1. Squares\n",
    "numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "squares = [x**2 for x in numbers]\n",
    "print(squares)\n",
    "\n",
    "# 2. Even numbers only\n",
    "even = [x for x in numbers if x % 2 ==0]\n",
    "print(even)\n",
    "# 3. Clean names\n",
    "names = [\"  customers \", \"ORDERS\", \" Products \"]\n",
    "\n",
    "clean_names = [x.strip().lower() for x in names]\n",
    "print(clean_names)\n",
    "# 4. Exclude columns starting with _\n",
    "columns = [\"id\", \"name\", \"_temp\", \"email\", \"_internal\"]\n",
    "excluded = [x for x in columns if x.startswith('_') != True]\n",
    "print(excluded)\n",
    "\n",
    "# 5. Replace 0s with \"EMPTY\"\n",
    "counts = [1542, 0, 8930, 0, 234]\n",
    "replaced = [\"Empty\" if not x else x for x in counts]\n",
    "print(replaced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
    "[2, 4, 6, 8, 10]\n",
    "['customers', 'orders', 'products']\n",
    "['id', 'name', 'email']\n",
    "[1542, 'EMPTY', 8930, 'EMPTY', 234]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Dictionary Comprehensions\n",
    "\n",
    "Same idea as list comprehensions, but creates dictionaries:\n",
    "\n",
    "```python\n",
    "new_dict = {key_expr: value_expr for item in iterable}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'customers': 1542, 'orders': 8930, 'products': 234}\n",
      "{'customers': 1542, 'orders': 8930}\n",
      "{'customers': 'big', 'orders': 'big', 'products': 'small'}\n",
      "{'name': 'customers', 'format': 'delta', 'mode': 'upsert'}\n"
     ]
    }
   ],
   "source": [
    "# Dictionary comprehension\n",
    "nodes = [\"customers\", \"orders\", \"products\"]\n",
    "row_counts = [1542, 8930, 234]\n",
    "\n",
    "# Create a dict from two lists\n",
    "node_counts = {name: count for name, count in zip(nodes, row_counts)}\n",
    "print(node_counts)\n",
    "\n",
    "# With a condition: only nodes with > 1000 rows\n",
    "big_nodes = {name: count for name, count in zip(nodes, row_counts) if count > 1000}\n",
    "print(big_nodes)\n",
    "\n",
    "# Transform values\n",
    "node_status = {name: \"big\" if count > 1000 else \"small\" for name, count in zip(nodes, row_counts)}\n",
    "print(node_status)\n",
    "\n",
    "# From odibi/utils/config_loader.py:\n",
    "# Recursive substitution on dict values\n",
    "data = {\"name\": \"  customers  \", \"format\": \"  delta  \", \"mode\": \"  upsert  \"}\n",
    "cleaned = {k: v.strip() for k, v in data.items()}\n",
    "print(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Odibi dict comprehensions\n",
    "\n",
    "These are actual patterns from the Odibi codebase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From odibi/registry.py line 100:\n",
    "# Filter function parameters, excluding 'context' and 'current'\n",
    "import inspect\n",
    "\n",
    "def example_transform(context, current, column_name, default_value=None):\n",
    "    \"\"\"Example transform function.\"\"\"\n",
    "    pass\n",
    "\n",
    "sig = inspect.signature(example_transform)\n",
    "func_params = {k: v for k, v in sig.parameters.items() if k not in [\"context\", \"current\"]}\n",
    "print(f\"User-facing params: {list(func_params.keys())}\")\n",
    "# Output: ['column_name', 'default_value']\n",
    "# This is exactly how Odibi's FunctionRegistry.validate_params() works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.1: Dict comprehensions\n",
    "\n",
    "1. Given a list of column names, create a dict mapping each name to its length\n",
    "2. Given a dict of node->row_count, create a new dict with only nodes that have > 0 rows\n",
    "3. Given a dict of node->row_count, create a new dict with values formatted as strings with commas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'customer_id': 11, 'name': 4, 'email': 5, 'created_at': 10}\n",
      "{'customers': 1542, 'orders': 8930}\n",
      "{'customers': '1,542', 'orders': '8,930', 'products': '234'}\n"
     ]
    }
   ],
   "source": [
    "# Exercise 7.1\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# 1. Column name -> length\n",
    "columns = [\"customer_id\", \"name\", \"email\", \"created_at\"]\n",
    "\n",
    "dict_1 = {x: len(x) for x in columns}\n",
    "print(dict_1)\n",
    "# 2. Only nodes with rows > 0\n",
    "node_counts = {\"customers\": 1542, \"temp\": 0, \"orders\": 8930, \"empty\": 0}\n",
    "dict_2 = {x : y for x,y in node_counts.items() if y}\n",
    "print(dict_2)\n",
    "# 3. Format values with commas\n",
    "node_counts = {\"customers\": 1542, \"orders\": 8930, \"products\": 234}\n",
    "dict_3 = {x: f'{y:,}' for x, y in node_counts.items()}\n",
    "print(dict_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "{'customer_id': 11, 'name': 4, 'email': 5, 'created_at': 10}\n",
    "{'customers': 1542, 'orders': 8930}\n",
    "{'customers': '1,542', 'orders': '8,930', 'products': '234'}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 8: Putting It All Together\n",
    "\n",
    "Now let us combine everything you have learned. These exercises reflect real patterns \n",
    "you will encounter in Odibi and in interviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested data structures\n",
    "\n",
    "In the real world, data is nested. A pipeline config has nodes, each node has transforms, \n",
    "each transform has parameters. You need to navigate these structures confidently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: sales_pipeline\n",
      "Engine: pandas\n",
      "Number of nodes: 2\n",
      "\n",
      "  Node: customers\n",
      "  Source: raw_customers.csv\n",
      "  Write mode: upsert\n",
      "  Transforms: 2\n",
      "    - rename_columns: {'old': 'cust_id', 'new': 'customer_id'}\n",
      "    - cast_types: {'columns': {'created_at': 'datetime'}}\n",
      "\n",
      "  Node: orders\n",
      "  Source: raw_orders.csv\n",
      "  Write mode: append\n",
      "  Transforms: 1\n",
      "    - filter_rows: {'condition': 'amount > 0'}\n"
     ]
    }
   ],
   "source": [
    "# Working with nested data (like Odibi pipeline configs)\n",
    "pipeline = {\n",
    "    \"name\": \"sales_pipeline\",\n",
    "    \"engine\": \"pandas\",\n",
    "    \"nodes\": [\n",
    "        {\n",
    "            \"name\": \"customers\",\n",
    "            \"source\": \"raw_customers.csv\",\n",
    "            \"transforms\": [\n",
    "                {\"type\": \"rename_columns\", \"params\": {\"old\": \"cust_id\", \"new\": \"customer_id\"}},\n",
    "                {\"type\": \"cast_types\", \"params\": {\"columns\": {\"created_at\": \"datetime\"}}},\n",
    "            ],\n",
    "            \"write_mode\": \"upsert\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"orders\",\n",
    "            \"source\": \"raw_orders.csv\",\n",
    "            \"transforms\": [\n",
    "                {\"type\": \"filter_rows\", \"params\": {\"condition\": \"amount > 0\"}},\n",
    "            ],\n",
    "            \"write_mode\": \"append\",\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Navigate the nested structure\n",
    "print(f\"Pipeline: {pipeline['name']}\")\n",
    "print(f\"Engine: {pipeline['engine']}\")\n",
    "print(f\"Number of nodes: {len(pipeline['nodes'])}\")\n",
    "\n",
    "# Loop through nodes\n",
    "for node in pipeline[\"nodes\"]:\n",
    "    print(f\"\\n  Node: {node['name']}\")\n",
    "    print(f\"  Source: {node['source']}\")\n",
    "    print(f\"  Write mode: {node['write_mode']}\")\n",
    "    print(f\"  Transforms: {len(node['transforms'])}\")\n",
    "    for t in node[\"transforms\"]:\n",
    "        print(f\"    - {t['type']}: {t['params']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8.1: Pipeline analyzer\n",
    "\n",
    "Using the `pipeline` dict above, write code that:\n",
    "1. Extracts a list of all node names using a list comprehension\n",
    "2. Extracts a list of all transform types across ALL nodes (flatten the nested lists)\n",
    "3. Creates a dict mapping node name -> number of transforms\n",
    "4. Finds which nodes use \"upsert\" write mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node names: ['customers', 'orders']\n",
      "['rename_columns', 'cast_types', 'filter_rows']\n",
      "Transform counts: {'customers': 2, 'orders': 1}\n",
      "Upsert nodes: ['customers']\n"
     ]
    }
   ],
   "source": [
    "# Exercise 8.1\n",
    "# YOUR CODE HERE\n",
    "# (Use the pipeline dict defined in the cell above)\n",
    "pipeline = {\n",
    "    \"name\": \"sales_pipeline\",\n",
    "    \"engine\": \"pandas\",\n",
    "    \"nodes\": [\n",
    "        {\n",
    "            \"name\": \"customers\",\n",
    "            \"source\": \"raw_customers.csv\",\n",
    "            \"transforms\": [\n",
    "                {\"type\": \"rename_columns\", \"params\": {\"old\": \"cust_id\", \"new\": \"customer_id\"}},\n",
    "                {\"type\": \"cast_types\", \"params\": {\"columns\": {\"created_at\": \"datetime\"}}},\n",
    "            ],\n",
    "            \"write_mode\": \"upsert\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"orders\",\n",
    "            \"source\": \"raw_orders.csv\",\n",
    "            \"transforms\": [\n",
    "                {\"type\": \"filter_rows\", \"params\": {\"condition\": \"amount > 0\"}},\n",
    "            ],\n",
    "            \"write_mode\": \"append\",\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "# 1. List of all node names\n",
    "\n",
    "node_names = [x['name'] for x in pipeline[\"nodes\"]]\n",
    "print(f'Node names: {node_names}')\n",
    "\n",
    "# 2. List of all transform types (across all nodes)\n",
    "transform_types = [y['type'] for x in pipeline['nodes'] for y in x['transforms']]\n",
    "print(transform_types)\n",
    "# 3. Dict: node name -> number of transforms\n",
    "dict_4 = { x['name']: len(x['transforms']) for x in pipeline['nodes']}\n",
    "print(f'Transform counts: {dict_4}')\n",
    "\n",
    "# 4. Nodes using upsert\n",
    "upserts = [x['name'] for x in pipeline[\"nodes\"] if x['write_mode'] == 'upsert']\n",
    "print(f'Upsert nodes: {upserts}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "Node names: ['customers', 'orders']\n",
    "All transforms: ['rename_columns', 'cast_types', 'filter_rows']\n",
    "Transform counts: {'customers': 2, 'orders': 1}\n",
    "Upsert nodes: ['customers']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8.2: Data grouping (interview classic)\n",
    "\n",
    "Given a list of records, group them by a key. This is the manual version of what \n",
    "Pandas `groupby()` does, and it is a very common interview question.\n",
    "\n",
    "Group these orders by customer_id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C001: 3 orders, total $275.00\n",
      "C002: 2 orders, total $325.00\n",
      "C003: 1 orders, total $300.00\n"
     ]
    }
   ],
   "source": [
    "# Exercise 8.2\n",
    "# YOUR CODE HERE\n",
    "orders = [\n",
    "    {\"order_id\": 1, \"customer_id\": \"C001\", \"amount\": 150.00},\n",
    "    {\"order_id\": 2, \"customer_id\": \"C002\", \"amount\": 200.00},\n",
    "    {\"order_id\": 3, \"customer_id\": \"C001\", \"amount\": 75.00},\n",
    "    {\"order_id\": 4, \"customer_id\": \"C003\", \"amount\": 300.00},\n",
    "    {\"order_id\": 5, \"customer_id\": \"C001\", \"amount\": 50.00},\n",
    "    {\"order_id\": 6, \"customer_id\": \"C002\", \"amount\": 125.00},\n",
    "]\n",
    "\n",
    "# Group by customer_id\n",
    "# Result should be a dict where:\n",
    "#   key = customer_id\n",
    "#   value = list of orders for that customer\n",
    "#\n",
    "# Hint: Start with an empty dict. Loop through orders.\n",
    "# For each order, check if the customer_id is already a key.\n",
    "# If not, create it with an empty list. Then append the order.\n",
    "\n",
    "grouped = {}\n",
    "\n",
    "for order in orders:\n",
    "    customer_id = order['customer_id']\n",
    "    if not grouped.get(customer_id):\n",
    "        grouped[customer_id] = []\n",
    "\n",
    "    grouped[customer_id].append(order)\n",
    "\n",
    "\n",
    "\n",
    "# Print the result\n",
    "for customer_id, customer_orders in grouped.items():\n",
    "    total = sum(o[\"amount\"] for o in customer_orders)\n",
    "    print(f\"{customer_id}: {len(customer_orders)} orders, total ${total:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "C001: 3 orders, total $275.00\n",
    "C002: 2 orders, total $325.00\n",
    "C003: 1 orders, total $300.00\n",
    "```\n",
    "\n",
    "Bonus: In Phase 3, you will learn about `collections.defaultdict` which makes this pattern \n",
    "even easier. For now, the manual approach teaches you the logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 9: Interview Drill\n",
    "\n",
    "These are common Python interview questions about data structures. \n",
    "Write your answers in the code cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drill 1: Remove duplicates from a list while preserving order\n",
    "\n",
    "Input: `[1, 3, 2, 3, 1, 4, 2, 5]`\n",
    "Output: `[1, 3, 2, 4, 5]`\n",
    "\n",
    "Note: `set()` removes duplicates but does NOT preserve order. You need a different approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 2, 4, 5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 3, 2, 4, 5]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drill 1\n",
    "# YOUR CODE HERE\n",
    "items = [1, 3, 2, 3, 1, 4, 2, 5]\n",
    "# Hint: Use a set to track what you've seen, and a list to build the result\n",
    "seen = set()\n",
    "result = []\n",
    "for item in items:\n",
    "    if item not in seen:\n",
    "        seen.add(item)\n",
    "        result.append(item)\n",
    "print(result)\n",
    "\n",
    "result2 = list(dict.fromkeys(items))\n",
    "result2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drill 2: Flatten a list of lists\n",
    "\n",
    "Input: `[[1, 2], [3, 4], [5, 6]]`\n",
    "Output: `[1, 2, 3, 4, 5, 6]`\n",
    "\n",
    "Do it with a comprehension (one line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "# Drill 2\n",
    "# YOUR CODE HERE\n",
    "nested = [[1, 2], [3, 4], [5, 6]]\n",
    "\n",
    "# Hint: [item for sublist in nested for item in sublist]\n",
    "new_list = []\n",
    "for item in nested:\n",
    "    new_list.extend(item)\n",
    "print(new_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drill 3: Count occurrences\n",
    "\n",
    "Given a list of words, create a dictionary counting how many times each word appears.\n",
    "\n",
    "Input: `[\"apple\", \"banana\", \"apple\", \"cherry\", \"banana\", \"apple\"]`\n",
    "Output: `{\"apple\": 3, \"banana\": 2, \"cherry\": 1}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'apple': 3, 'banana': 2, 'cherry': 1}\n"
     ]
    }
   ],
   "source": [
    "# Drill 3\n",
    "# YOUR CODE HERE\n",
    "words = [\"apple\", \"banana\", \"apple\", \"cherry\", \"banana\", \"apple\"]\n",
    "\n",
    "# Hint: Start with empty dict. For each word, use .get(word, 0) + 1\n",
    "words_dict = dict()\n",
    "\n",
    "for word in words:\n",
    "    words_dict[word] = words_dict.get(word,0) + 1\n",
    "print(words_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drill 4: Invert a dictionary\n",
    "\n",
    "Swap keys and values.\n",
    "\n",
    "Input: `{\"a\": 1, \"b\": 2, \"c\": 3}`\n",
    "Output: `{1: \"a\", 2: \"b\", 3: \"c\"}`\n",
    "\n",
    "Do it with a dict comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c'}\n"
     ]
    }
   ],
   "source": [
    "# Drill 4\n",
    "# YOUR CODE HERE\n",
    "original = {\"a\": 1, \"b\": 2, \"c\": 3}\n",
    "\n",
    "invered = { y: x for x, y in original.items()}\n",
    "print(invered)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drill 5: Two-sum problem (simplified)\n",
    "\n",
    "Given a list of numbers and a target, find two numbers that add up to the target. \n",
    "Return them as a tuple.\n",
    "\n",
    "Input: `nums = [2, 7, 11, 15]`, `target = 9`\n",
    "Output: `(2, 7)`\n",
    "\n",
    "This is one of the most famous interview questions. There is a solution using a set/dict \n",
    "that runs in O(n) time, but a simple nested loop solution is fine for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 7\n",
      "2 7\n"
     ]
    }
   ],
   "source": [
    "# Drill 5\n",
    "# YOUR CODE HERE\n",
    "nums = [2, 7, 11, 15]\n",
    "target = 9\n",
    "\n",
    "# Simple approach: try every pair\n",
    "for i in range(len(nums)):\n",
    "    for j in range(i+1, len(nums)):\n",
    "        if nums[i] + nums[j] == target:\n",
    "            print (nums[i], nums[j])\n",
    "            break\n",
    "        \n",
    "\n",
    "# Better approach: use a set to track complements\n",
    "seen = set()\n",
    "for x in nums:\n",
    "    complement = target - x\n",
    "    if complement in seen:\n",
    "        print(complement,x)\n",
    "        break\n",
    "    seen.add(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drill 6: Merge two dictionaries\n",
    "\n",
    "Given two dicts, create a new dict with all keys. If a key exists in both, \n",
    "use the value from the second dict (it overrides).\n",
    "\n",
    "Do it THREE ways:\n",
    "1. Using a loop\n",
    "2. Using `{**dict1, **dict2}` (unpacking)\n",
    "3. Using `dict1 | dict2` (Python 3.9+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "17e1e60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'engine': 'pandas', 'format': 'csv', 'write_mode': 'overwrite'}"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{**defaults}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "0b92b5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'engine': 'pandas', 'format': 'csv', 'write_mode': 'overwrite'},\n",
       " {'format': 'delta', 'write_mode': 'upsert', 'keys': ['id']})"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(defaults, overrides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'engine': 'pandas', 'format': 'delta', 'write_mode': 'upsert', 'keys': ['id']}\n",
      "{'engine': 'pandas', 'format': 'delta', 'write_mode': 'upsert', 'keys': ['id']}\n",
      "{'engine': 'pandas', 'format': 'delta', 'write_mode': 'upsert', 'keys': ['id']}\n"
     ]
    }
   ],
   "source": [
    "# Drill 6\n",
    "# YOUR CODE HERE\n",
    "defaults = {\"engine\": \"pandas\", \"format\": \"csv\", \"write_mode\": \"overwrite\"}\n",
    "overrides = {\"format\": \"delta\", \"write_mode\": \"upsert\", \"keys\": [\"id\"]}\n",
    "\n",
    "# Method 1: Loop\n",
    "new_dict_1 = dict()\n",
    "for d in (defaults, overrides):\n",
    "    for k,v in d.items():\n",
    "        new_dict_1[k] = v\n",
    "\n",
    "print(new_dict_1)\n",
    "# Method 2: Unpacking\n",
    "new_dict_2 = {**defaults, **overrides}\n",
    "print(new_dict_2)\n",
    "# Method 3: Union operator (Python 3.9+)\n",
    "new_dict_3 = defaults | overrides\n",
    "print(new_dict_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output (all three should produce):**\n",
    "```\n",
    "{'engine': 'pandas', 'format': 'delta', 'write_mode': 'upsert', 'keys': ['id']}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Checkpoint\n",
    "\n",
    "You now have a solid foundation in Python's data structures. Here is what you learned:\n",
    "\n",
    "- **Lists** -- ordered, mutable, indexed collections\n",
    "- **Dictionaries** -- key-value pairs, the backbone of Python programs\n",
    "- **Sets** -- unique values, set operations (union, intersection, difference)\n",
    "- **Tuples** -- immutable sequences, unpacking, multiple return values\n",
    "- **Built-in functions** -- `enumerate`, `zip`, `sorted` with `key`, `any`, `all`\n",
    "- **List comprehensions** -- transforming and filtering in one line\n",
    "- **Dict comprehensions** -- building dicts from iterables\n",
    "\n",
    "These are not just academic concepts. Every piece of Odibi code uses these patterns.\n",
    "When you read `odibi/validation/engine.py` and see:\n",
    "```python\n",
    "cols = [c for c in test.columns if c in df.columns]\n",
    "```\n",
    "You now understand exactly what that does -- filter test columns to only those present in the DataFrame.\n",
    "\n",
    "**Next:** Notebook 03 -- Standard Library Deep Dive (os, pathlib, json, re, logging, datetime, \n",
    "hashlib, uuid, collections, dataclasses, enum, contextlib, functools)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
